openstack debug

1. Host is not mapped to any cell
在控制节点执行nova-manage cell_v2 discover_hosts --verbose对自动匹配上


2.missing required parameter 'source_id'
原来是没有选择镜像


3. VNC登不上去

正确

[vnc]
server_proxyclient_address = 192.168.10.8
server_listen = 0.0.0.0
novncproxy_base_url = http://192.168.10.8:6080/vnc_lite.html

[spice]
html5proxy_base_url = http://192.168.10.8:6081/spice_auto.html

错误

[vnc]
server_proxyclient_address = 192.168.10.9
server_listen = 192.168.10.9
novncproxy_base_url = http://192.168.10.8:6080/vnc_auto.html

[spice]
html5proxy_base_url = http://192.168.10.8:6081/spice_auto.html


May 11 14:17:56 devstack-controller nova-compute[417688]:  {{(pid=417688) _update_vif_xml /opt/stack/nova/nova/virt/libvirt/migration.py:375}}
May 11 14:17:56 devstack-controller nova-compute[417688]: DEBUG nova.virt.libvirt.driver [-] [instance: 799d6be3-8259-45d1-992e-d8485957f30b] About to invoke the migrate API {{(pid=417688) _live_migration_operation /opt/stack/nova/nova/virt/libvirt/driver.py:9678}}
May 11 14:17:56 devstack-controller nova-compute[417688]: ERROR nova.virt.libvirt.driver [-] [instance: 799d6be3-8259-45d1-992e-d8485957f30b] Live Migration failure: operation failed: Failed to connect to remote libvirt URI qemu+ssh://stack@devstack-compute/system: Cannot recv data: Host key verification failed.: Connection reset by peer: libvirt.libvirtError: operation failed: Failed to connect to remote libvirt URI qemu+ssh://stack@devstack-compute/system: Cannot recv data: Host key verification failed.: Connection reset by peer
May 11 14:17:56 devstack-controller nova-compute[417688]: DEBUG nova.virt.libvirt.driver [-] [instance: 799d6be3-8259-45d1-992e-d8485957f30b] Migration operation thread notification {{(pid=417688) thread_finished /opt/stack/nova/nova/virt/libvirt/driver.py:10036}}
May 11 14:17:56 devstack-controller nova-compute[417688]: Traceback (most recent call last):
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/hubs/hub.py", line 476, in fire_timers
May 11 14:17:56 devstack-controller nova-compute[417688]:     timer()
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/hubs/timer.py", line 59, in __call__
May 11 14:17:56 devstack-controller nova-compute[417688]:     cb(*args, **kw)
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/event.py", line 175, in _do_send
May 11 14:17:56 devstack-controller nova-compute[417688]:     waiter.switch(result)
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/greenthread.py", line 221, in main
May 11 14:17:56 devstack-controller nova-compute[417688]:     result = function(*args, **kwargs)
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/opt/stack/nova/nova/utils.py", line 660, in context_wrapper
May 11 14:17:56 devstack-controller nova-compute[417688]:     return func(*args, **kwargs)
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/opt/stack/nova/nova/virt/libvirt/driver.py", line 9691, in _live_migration_operation
May 11 14:17:56 devstack-controller nova-compute[417688]:     LOG.error("Live Migration failure: %s", e, instance=instance)
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/oslo_utils/excutils.py", line 227, in __exit__
May 11 14:17:56 devstack-controller nova-compute[417688]:     self.force_reraise()
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/oslo_utils/excutils.py", line 200, in force_reraise
May 11 14:17:56 devstack-controller nova-compute[417688]:     raise self.value
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/opt/stack/nova/nova/virt/libvirt/driver.py", line 9679, in _live_migration_operation
May 11 14:17:56 devstack-controller nova-compute[417688]:     guest.migrate(self._live_migration_uri(dest),
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/opt/stack/nova/nova/virt/libvirt/guest.py", line 623, in migrate
May 11 14:17:56 devstack-controller nova-compute[417688]:     self._domain.migrateToURI3(
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/tpool.py", line 190, in doit
May 11 14:17:56 devstack-controller nova-compute[417688]:     result = proxy_call(self._autowrap, f, *args, **kwargs)
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/tpool.py", line 148, in proxy_call
May 11 14:17:56 devstack-controller nova-compute[417688]:     rv = execute(f, *args, **kwargs)
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/tpool.py", line 129, in execute
May 11 14:17:56 devstack-controller nova-compute[417688]:     six.reraise(c, e, tb)
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/six.py", line 703, in reraise
May 11 14:17:56 devstack-controller nova-compute[417688]:     raise value
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/tpool.py", line 83, in tworker
May 11 14:17:56 devstack-controller nova-compute[417688]:     rv = meth(*args, **kwargs)
May 11 14:17:56 devstack-controller nova-compute[417688]:   File "/usr/lib/python3/dist-packages/libvirt.py", line 1943, in migrateToURI3
May 11 14:17:56 devstack-controller nova-compute[417688]:     if ret == -1: raise libvirtError ('virDomainMigrateToURI3() failed', dom=self)
May 11 14:17:56 devstack-controller nova-compute[417688]: libvirt.libvirtError: operation failed: Failed to connect to remote libvirt URI qemu+ssh://stack@devstack-compute/system: Cannot recv data: Host key verification failed.: Connection reset by peer


stack@devstack-controller:~$ virsh list qemu+ssh://stack@devstack-compute/
error: unexpected data 'qemu+ssh://stack@devstack-compute/'
stack@devstack-controller:~$ virsh -c qemu+ssh://stack@devstack-compute/ list
The authenticity of host 'devstack-compute (192.168.10.9)' can't be established.
ECDSA key fingerprint is SHA256:2pQphoPW/Go8XnLOhBslD1LO6NG+s26OgZ3qo3yWYpY.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
stack@devstack-compute's password:


没有配置两台机器免密登录

  209  ssh-keygen -t rsa

PS C:\Users\liuchao> scp root@192.168.10.8:/opt/stack/.ssh/* ./
root@192.168.10.8's password:
authorized_keys                                                     100%  579   525.0KB/s   00:00
id_rsa                                                              100% 2610     4.8MB/s   00:00
id_rsa.pub                                                          100%  579     1.1MB/s   00:00
known_hosts                                                         100%  444     0.4KB/s   00:00
PS C:\Users\liuchao> scp .\id_rsa .\Desktop\noVNC root@192.168.10.8:/opt/stack/.ssh/
root@192.168.10.8's password:
id_rsa                                                              100% 2610     1.6MB/s   00:00
./Desktop/noVNC: not a regular file
PS C:\Users\liuchao> scp .\id_rsa.pub root@192.168.10.8:/opt/stack/.ssh/
root@192.168.10.8's password:
id_rsa.pub                                                          100%  579   539.5KB/s   00:00
PS C:\Users\liuchao>
PS C:\Users\liuchao> scp .\authorized_keys root@192.168.10.8:/opt/stack/.ssh/
root@192.168.10.8's password:
authorized_keys                                                     100%  579   544.7KB/s   00:00
PS C:\Users\liuchao>
PS C:\Users\liuchao>
PS C:\Users\liuchao> scp .\id_rsa .\Desktop\noVNC root@192.168.10.9:/opt/stack/.ssh/
The authenticity of host '192.168.10.9 (192.168.10.9)' can't be established.
ECDSA key fingerprint is SHA256:2pQphoPW/Go8XnLOhBslD1LO6NG+s26OgZ3qo3yWYpY.
Are you sure you want to continue connecting (yes/no/[fingerprint])?
Warning: Permanently added '192.168.10.9' (ECDSA) to the list of known hosts.
root@192.168.10.9's password:
id_rsa                                                              100% 2610     2.4MB/s   00:00
./Desktop/noVNC: not a regular file
PS C:\Users\liuchao> scp .\id_rsa.pub root@192.168.10.9:/opt/stack/.ssh/
root@192.168.10.9's password:
id_rsa.pub                                                          100%  579   536.4KB/s   00:00
PS C:\Users\liuchao> scp .\authorized_keys root@192.168.10.9:/opt/stack/.ssh/
root@192.168.10.9's password:
authorized_keys                                                     100%  579   534.5KB/s   00:00
PS C:\Users\liuchao>

第一台机器
  210  cd .ssh/
  211  ls
  212  pwd
  213  ls
  214  cp id_rsa.pub authorized_keys
  215  ls
  216  ssh localhost
  223  ssh stack@devstack-compute

第二台机器
  146  mkdir .ssh
  147  cd .ssh/
  148  ls
  149  ls -l
  150  sudo chown -R stack:stack *
  151  ls -l
  152  ssh stack@devstack-controller
  153  ls
  154  sudo chmod 600 id_rsa
  155  sudo chmod 644 id_rsa.pub
  156  ls
  157  sudo chmod 644 authorized_keys
  158  ssh stack@devstack-controller

stack@devstack-controller:~/.ssh$ virsh -c qemu+ssh://stack@devstack-compute/system list
 Id   Name                State
-----------------------------------
 2    instance-00000003   running


May 11 14:46:12 devstack-controller nova-compute[417688]:  {{(pid=417688) _update_vif_xml /opt/stack/nova/nova/virt/libvirt/migration.py:375}}
May 11 14:46:12 devstack-controller nova-compute[417688]: DEBUG nova.virt.libvirt.driver [-] [instance: 799d6be3-8259-45d1-992e-d8485957f30b] About to invoke the migrate API {{(pid=417688) _live_migration_operation /opt/stack/nova/nova/virt/libvirt/driver.py:9678}}
May 11 14:46:12 devstack-controller nova-compute[417688]: ERROR nova.virt.libvirt.driver [-] [instance: 799d6be3-8259-45d1-992e-d8485957f30b] Live Migration failure: operation failed: Failed to connect to remote libvirt URI qemu+ssh://stack@devstack-compute/system: Cannot recv data: Host key verification failed.: Connection reset by peer: libvirt.libvirtError: operation failed: Failed to connect to remote libvirt URI qemu+ssh://stack@devstack-compute/system: Cannot recv data: Host key verification failed.: Connection reset by peer
May 11 14:46:12 devstack-controller nova-compute[417688]: DEBUG nova.virt.libvirt.driver [-] [instance: 799d6be3-8259-45d1-992e-d8485957f30b] Migration operation thread notification {{(pid=417688) thread_finished /opt/stack/nova/nova/virt/libvirt/driver.py:10036}}
May 11 14:46:12 devstack-controller nova-compute[417688]: Traceback (most recent call last):
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/hubs/hub.py", line 476, in fire_timers
May 11 14:46:12 devstack-controller nova-compute[417688]:     timer()
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/hubs/timer.py", line 59, in __call__
May 11 14:46:12 devstack-controller nova-compute[417688]:     cb(*args, **kw)
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/event.py", line 175, in _do_send
May 11 14:46:12 devstack-controller nova-compute[417688]:     waiter.switch(result)
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/greenthread.py", line 221, in main
May 11 14:46:12 devstack-controller nova-compute[417688]:     result = function(*args, **kwargs)
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/opt/stack/nova/nova/utils.py", line 660, in context_wrapper
May 11 14:46:12 devstack-controller nova-compute[417688]:     return func(*args, **kwargs)
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/opt/stack/nova/nova/virt/libvirt/driver.py", line 9691, in _live_migration_operation
May 11 14:46:12 devstack-controller nova-compute[417688]:     LOG.error("Live Migration failure: %s", e, instance=instance)
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/oslo_utils/excutils.py", line 227, in __exit__
May 11 14:46:12 devstack-controller nova-compute[417688]:     self.force_reraise()
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/oslo_utils/excutils.py", line 200, in force_reraise
May 11 14:46:12 devstack-controller nova-compute[417688]:     raise self.value
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/opt/stack/nova/nova/virt/libvirt/driver.py", line 9679, in _live_migration_operation
May 11 14:46:12 devstack-controller nova-compute[417688]:     guest.migrate(self._live_migration_uri(dest),
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/opt/stack/nova/nova/virt/libvirt/guest.py", line 623, in migrate
May 11 14:46:12 devstack-controller nova-compute[417688]:     self._domain.migrateToURI3(
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/tpool.py", line 190, in doit
May 11 14:46:12 devstack-controller nova-compute[417688]:     result = proxy_call(self._autowrap, f, *args, **kwargs)
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/tpool.py", line 148, in proxy_call
May 11 14:46:12 devstack-controller nova-compute[417688]:     rv = execute(f, *args, **kwargs)
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/tpool.py", line 129, in execute
May 11 14:46:12 devstack-controller nova-compute[417688]:     six.reraise(c, e, tb)
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/six.py", line 703, in reraise
May 11 14:46:12 devstack-controller nova-compute[417688]:     raise value
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/local/lib/python3.8/dist-packages/eventlet/tpool.py", line 83, in tworker
May 11 14:46:12 devstack-controller nova-compute[417688]:     rv = meth(*args, **kwargs)
May 11 14:46:12 devstack-controller nova-compute[417688]:   File "/usr/lib/python3/dist-packages/libvirt.py", line 1943, in migrateToURI3
May 11 14:46:12 devstack-controller nova-compute[417688]:     if ret == -1: raise libvirtError ('virDomainMigrateToURI3() failed', dom=self)
May 11 14:46:12 devstack-controller nova-compute[417688]: libvirt.libvirtError: operation failed: Failed to connect to remote libvirt URI qemu+ssh://stack@devstack-compute/system: Cannot recv data: Host key verification failed.: Connection reset by peer

https://blog.csdn.net/SpiritedAway1106/article/details/120939053

root@devstack-controller:~# systemctl status libvirtd.service
● libvirtd.service - Virtualization daemon
     Loaded: loaded (/lib/systemd/system/libvirtd.service; enabled; vendor preset: enabled)
     Active: failed (Result: exit-code) since Sat 2024-05-11 15:13:13 CST; 4h 2min ago
TriggeredBy: ● libvirtd-admin.socket
             ● libvirtd.socket
             ● libvirtd-ro.socket
       Docs: man:libvirtd(8)
             https://libvirt.org
    Process: 539547 ExecStart=/usr/sbin/libvirtd --listen --config /etc/libvirt/libvirtd.conf (code=exited, status=6)
   Main PID: 539547 (code=exited, status=6)
      Tasks: 2 (limit: 32768)
     Memory: 10.4M
     CGroup: /system.slice/libvirtd.service
             ├─537565 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvirt_leaseshelper
             └─537566 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvirt_leaseshelper

May 11 15:13:12 devstack-controller systemd[1]: libvirtd.service: Main process exited, code=exited, status=6/NOTCONFIGURED
May 11 15:13:12 devstack-controller systemd[1]: libvirtd.service: Failed with result 'exit-code'.
May 11 15:13:12 devstack-controller systemd[1]: Failed to start Virtualization daemon.
May 11 15:13:13 devstack-controller systemd[1]: libvirtd.service: Scheduled restart job, restart counter is at 5.
May 11 15:13:13 devstack-controller systemd[1]: Stopped Virtualization daemon.
May 11 15:13:13 devstack-controller systemd[1]: libvirtd.service: Start request repeated too quickly.
May 11 15:13:13 devstack-controller systemd[1]: libvirtd.service: Failed with result 'exit-code'.
May 11 15:13:13 devstack-controller systemd[1]: Failed to start Virtualization daemon.

root@devstack-controller:~# cat /lib/systemd/system/libvirtd.service
[Unit]
Description=Virtualization daemon
Requires=virtlogd.socket
Requires=virtlockd.socket
# Use Wants instead of Requires so that users
# can disable these three .socket units to revert
# to a traditional non-activation deployment setup
Wants=libvirtd.socket
Wants=libvirtd-ro.socket
Wants=libvirtd-admin.socket
Wants=systemd-machined.service
Before=libvirt-guests.service
After=network.target
After=dbus.service
After=iscsid.service
After=apparmor.service
After=local-fs.target
After=remote-fs.target
After=systemd-logind.service
After=systemd-machined.service
After=xencommons.service
Conflicts=xendomains.service
Documentation=man:libvirtd(8)
Documentation=https://libvirt.org

[Service]
Type=notify
EnvironmentFile=-/etc/default/libvirtd
ExecStart=/usr/sbin/libvirtd --listen --config /etc/libvirt/libvirtd.conf
ExecReload=/bin/kill -HUP $MAINPID
KillMode=process
Restart=on-failure
# At least 1 FD per guest, often 2 (eg qemu monitor + qemu agent).
# eg if we want to support 4096 guests, we'll typically need 8192 FDs
# If changing this, also consider virtlogd.service & virtlockd.service
# limits which are also related to number of guests
LimitNOFILE=8192
# The cgroups pids controller can limit the number of tasks started by
# the daemon, which can limit the number of domains for some hypervisors.
# A conservative default of 8 tasks per guest results in a TasksMax of
# 32k to support 4096 guests.
TasksMax=32768
# With cgroups v2 there is no devices controller anymore, we have to use
# eBPF to control access to devices.  In order to do that we create a eBPF
# hash MAP which locks memory.  The default map size for 64 devices together
# with program takes 12k per guest.  After rounding up we will get 64M to
# support 4096 guests.
LimitMEMLOCK=64M

[Install]
WantedBy=multi-user.target
Also=virtlockd.socket
Also=virtlogd.socket
Also=libvirtd.socket
Also=libvirtd-ro.socket

root@devstack-controller:~# cat /etc/default/libvirtd
# Defaults for libvirtd initscript (/etc/init.d/libvirtd)
# This is a POSIX shell fragment

# Start libvirtd to handle qemu/kvm:
start_libvirtd="yes"

# options passed to libvirtd, see man libvirtd for details.
# For example to enable listening on tcp add -l here
# and set up the TLS Certificates that libvirtd will need.
#libvirtd_opts=""

# pass in location of kerberos keytab
#export KRB5_KTNAME=/etc/libvirt/libvirt.keytab

# Whether to mount a systemd like cgroup layout (only
# useful when not running systemd)
#mount_cgroups=yes
# Which cgroups to mount
#cgroups="memory devices"

 virPidFileAcquirePath:367 : Failed to acquire pid file '/run/libvirtd.pid': Resource temporarily unavailable

 daemonSetupNetworking:421 : --listen parameter not permitted with systemd activation sockets, see 'man libvirtd' for further guidance

 stack@devstack-controller:~$ history
    1  cd devstack/
    2  ls
    3  vim inc/python
    4  vim lib/tempest
    5  grep -r "ENABLED_SERVICES"
    6  vim stackrc
    7  vim local.conf
    8  ip addr
    9  cd /opt/stack/devstack/files/
   10  ls
   11  wget https://github.com/etcd-io/etcd/releases/download/v3.3.12/etcd-v3.3.12-linux-amd64.tar.gz
   12  ls
   13  rm etcd-v3.3.12-linux-amd64.tar.gz
   14  ls
   15  mv /opt/stack/etcd-v3.3.12-linux-amd64.tar.gz ./
   16  ls
   17  cd ..
   18  ls
   19  cat stackrc
   20  ls
   21  vim stackrc
   22  ./stack.sh
   23  curl -f --retry 6 --retry-delay 5 -o /opt/stack/devstack/files/get-pip.py https://bootstrap.pypa.io/get-pip.py
   24  ./stack.sh
   25  sudo -H -E python3.8 /opt/stack/devstack/files/get-pip.py
   26  ./stack.sh
   27  git clone https://github.com/novnc/noVNC.git /opt/stack/noVNC --branch v1.1.0
   28  ls
   29  cd ..
   30  ls
   31  pwd
   32  unzip noVNC-1.1.0.zip
   33  ls
   34  cd noVNC-1.1.0/
   35  ls
   36  cd ..
   37  ls
   38  mv noVNC-1.1.0 noVNC
   39  ls
   40  rm -rf noVNC
   41  ls
   42  cd noVNC/
   43  ls
   44  git status
   45  ls -l
   46  cd ..
   47  ls -l
   48  sudo chown -R stack:stack noVNC
   49  sudo chown -R stack:stack cirros-0.5.2-x86_64-disk.img
   50  ls
   51  cd noVNC/
   52  ls
   53  git status
   54  ls
   55  cd ..
   56  ls
   57  cd devstack/
   58  ls
   59  ./stack.sh
   60  history
   61  exit
   62  ls
   63  cd devstack/
   64  ls
   65  grep -r "OS_IDENTITY_API_VERSION"
   66  ls
   67  cd ..
   68  ls
   69  cd logs/
   70  ls
   71  grep -r "Keystone is serving at"
   72  cd ~
   73  netstat -napl | grep 80
   74  netstat -napl | grep keystone
   75  netstat -nap | grep keystone
   76  netstat -nap | grep 80
   77  sudo systemctl restart devstack@*
   78  ps aux | grep nova
   79  ps aux | grep keystone/
   80  ps aux | grep keystone
   81  netstat -nap | grep 80
   82  netstat -ntlp
   83  cd /var/log/
   84  ls
   85  journalctl -f --unit devstack@keystone.service
   86  sudo journalctl -f --unit devstack@keystone.service
   87  cd ~
   88  ls
   89  export OS_IDENTITY_API_VERSION=3
   90  export OS_AUTH_URL=http://192.168.10.8/identity/
   91  export OS_USERNAME=admin
   92  export OS_USER_DOMAIN_ID=default
   93  export OS_PASSWORD=secret
   94  export OS_PROJECT_NAME=admin
   95  export OS_PROJECT_DOMAIN_ID=default
   96  export OS_REGION_NAME=RegionOne
   97  openstack --debug --os-cloud devstack-admin --os-region RegionOne compute service list
   98  ls
   99  cd devstack/
  100  ls
  101  cat /etc/hosts
  102  ls
  103  ./stack.sh
  104  exit
  105  cd devstack/
  106  ls
  107  ./stack.sh
  108  ./unstack.sh
  109  ./stack.sh
  110  vim lib/tempest:configure_tempest
  111  vim lib/tempest
  112  ./stack.sh
  113  ./unstack.sh
  114  ./stack.sh
  115  openstack --debug --os-cloud devstack-admin --os-region RegionOne compute service list
  116  netstat -naptl
  117  netstat -naptl | grep 80
  118  nc -l -p 11011
  119  nc -h
  120  nc -l -p 80
  121  sudo nc -l -p 80
  122  sudo nc -l -p 81
  123  cat local.conf
  124  ls
  125  pip install keystoneauth1
  126  vim /usr/local/lib/python3.8/dist-packages/keystoneauth1/session.py
  127  cat /etc/nova/nova-cpu.conf
  128  vim /usr/local/lib/python3.8/dist-packages/keystoneauth1/adapter.py
  129  ps aux | grep nova
  130  ps aux | grep cinder
  131  ls
  132  sudo journalctl -f --unit devstack@n-cpu.service
  133  sudo journalctl -f --unit devstack@c-vol.service
  134  ps aux | grep etcd
  135  date
  136  sudo journalctl -f --unit devstack@c-vol.service
  137  sudo journalctl --unit devstack@c-vol.service
  138  sudo systemctl restart devstack@c-vol.service
  139  sudo journalctl -f --unit devstack@c-vol.service
  140  sudo systemctl stop devstack@c-vol.service
  141  sudo journalctl --unit devstack@c-vol.service | grep req-ca933115-7c29-4d3d-b8a0-796cecf36d12
  142  sudo journalctl --unit devstack@* | grep req-ca933115-7c29-4d3d-b8a0-796cecf36d12
  143  sudo journalctl --unit devstack@n-api.service
  144  sudo openstack endpoint list
  145  ls
  146  vim openstackrc
  147  source openstackrc
  148  sudo openstack endpoint list
  149  cat openstackrc ]
  150  cat openstackrc
  151  cd ..
  152  ls
  153  cd logs/
  154  ls
  155  grep -r "endpoint list"
  156  grep -r "openstack"
  157  openstack --os-cloud devstack-admin --os-region RegionOne compute service list
  158  cd ~
  159  openstack --os-cloud devstack-admin --os-region RegionOne compute service list
  160  sudo openstack --os-cloud devstack-admin --os-region RegionOne compute service list
  161  sudo openstack --os-cloud devstack-admin --os-region RegionOne service list
  162  sudo openstack --os-cloud devstack-admin --os-region RegionOne compute cell
  163  sudo journalctl --unit devstack@n-api.service
  164  nova-manage cell_v2 discover_hosts --verbose
  165  nova-manage cell_v2
  166  nova-manage cell_v2 list_cells
  167  nova-manage cell_v2 list_hosts
  168  nova-manage cell_v2 map_cell_and_hosts
  169  nova-manage cell_v2 map_cell_and_hosts
  170  nova-manage cell_v2 discover_hosts --verbose
  171  cinder-manage --h
  172  sudo journalctl --unit devstack@* | grep missing required parameter 'source_id'
  173  sudo journalctl --unit devstack@* | grep 'missing required parameter'
  174  cat /etc/systemd/journald.conf
  175  cd /var/log/journal/
  176  ls
  177  ls -l
  178  cd 05d38496f22af8b0bf8877e719388b9d/
  179  ls
  180  vim system@de375e6aef894d4e8aa646d66cff039f-0000000000000001-00061803a7684dd1.journal
  181  cd ~
  182  sudo journalctl --unit devstack@* | grep 'missing required parameter'
  183  sudo journalctl --unit devstack@* | grep ERROR
  184  sudo journalctl -f --unit devstack@* | grep ERROR
  185  sudo journalctl -f --unit devstack@*
  186  ls
  187  cd devstack/
  188  ls
  189  cat local.conf
  190  cat /etc/nova/nova-cpu.conf
  191  cd /etc/
  192  ls
  193  sudo grep -r "vnc"
  194  cd ~
  195  ls
  196  sudo journalctl -f --unit devstack@n-cpu.service
  197  virsh list
  198  sudo journalctl -f --unit devstack@n-cpu.service
  199  ping devstack-compute
  200  virsh list qemu+ssh://stack@devstack-compute/
  201  virsh -c qemu+ssh://stack@devstack-compute/ list
  202  ls
  203  cd devstack/
  204  ls
  205  cd tools/
  206  ls
  207  cat create-stack-user.sh
  208  cd ~
  209  ssh-keygen -t rsa
  210  cd .ssh/
  211  ls
  212  pwd
  213  ls
  214  cp id_rsa.pub authorized_keys
  215  ls
  216  ssh localhost
  217  ls -l
  218  cd ~
  219  ls
  220  virsh -c qemu+ssh://stack@devstack-compute/ list
  221  virsh -c qemu+ssh://stack@devstack-compute list
  222  virsh list
  223  ssh stack@devstack-compute
  224  cd .ssh/
  225  ls -l
  226  virsh -c qemu+ssh://stack@devstack-compute list
  227  virsh -c qemu+ssh://stack@devstack-compute/ list
  228  virsh -c qemu+tls://stack@devstack-compute/ list
  229  virsh -c qemu+ssh://stack@devstack-compute/ list
  230  virsh -c qemu+ssh://stack@devstack-compute/system list
  231  cd ~
  232  ls
  233  history
  234  sudo journalctl -f --unit devstack@n-cpu.service
  235  virsh -c qemu+ssh://stack@devstack-compute/system list
  236  systemctl restart devstack@n-cpu.service
  237  sudo systemctl restart devstack@n-cpu.service
  238  sudo journalctl -f --unit devstack@n-cpu.service
  239  vim /etc/libvirt/libvirtd.conf
  240  sudo vim /etc/libvirt/libvirtd.conf
  241  whereis libvirtd
  242  sudo systemctl show libvirtd.service
  243  sudo systemctl -h
  244  sudo systemctl status libvirtd.service
  245  sudo vim /lib/systemd/system/libvirtd.service
  246  sudo systemctl restart libvirtd.service
  247  ps aux | grep libvirt
  248  sudo netstat napl | grep libvirt
  249  sudo netstat -napl
  250  sudo netstat -napl  | grep libvirt
  251  sudo vim /lib/systemd/system/libvirtd.service
  252  sudo systemctl restart libvirtd.service
  253  systemctl daemon-reload
  254  sudo systemctl restart libvirtd.service
  255  sudo systemctl -xe libvirtd.service
  256  sudo journalctl -xe libvirtd.service
  257  sudo systemctl status libvirtd.service
  258  /usr/sbin/libvirtd --listen
  259  vim /etc/libvirt/libvirtd.conf
  260  /usr/sbin/libvirtd -
  261  /usr/sbin/libvirtd --listen --config /etc/libvirt/libvirtd.conf
  262  sudo /usr/sbin/libvirtd --listen --config /etc/libvirt/libvirtd.conf
  263  sudo vim /lib/systemd/system/libvirtd.service
  264  systemctl daemon-reload
  265  sudo systemctl daemon-reload
  266  sudo systemctl restart libvirtd.service
  267  sudo systemctl status libvirtd.service
  268  sudo systemctl start libvirtd.service
  269  ps aux | grep libvirt
  270  journalctl -xe
  271  sudo systemctl start libvirtd.service
  272  sudo vim /lib/systemd/system/libvirtd.service
  273  sudo /usr/sbin/libvirtd --listen --config /etc/libvirt/libvirtd.conf
  274  sudo systemctl start libvirtd.service
  275  exit
  276  history

不用修改libvirt的配置，仍然按libvirtd启动

不但要配置stack用户直接免密登录，root之间，root和stack直接，都要免密登录，可以热迁移了。

https://www.server-world.info/en/note?os=Ubuntu_22.04&p=kvm&f=5

Unable to complete install: 'Cannot access storage file '/path/to/vms' (as uid:64055, gid:108): Permission denied'

To do that....

Edit...

sudo vi /etc/libvirt/qemu.conf
And set...

user = "root"
group = "root"
And then...

sudo systemctl restart libvirtd

https://www.server-world.info/en/note?os=Ubuntu_22.04&p=kvm&f=5

https://zhuanlan.zhihu.com/p/61584503/

https://blog.csdn.net/weixin_43863487/article/details/104939023

https://www.vinchin.cn/blog/vinchin-technique-share-details.html?id=10939

root@devstack-controller:~# virsh qemu-agent-command 1 '{"execute":"guest-exec","arguments":{"path":"mkdir","arg":["-p","/root/test/"],"capture-output":true}}'
{"return":{"pid":3922}}

root@devstack-controller:~# virsh qemu-agent-command 1 '{"execute":"guest-exec-status","arguments":{"pid":3922}}'
{"return":{"exitcode":0,"exited":true}}

qemu-guest-agent功能异常
Linux:
虚机修改密码或主机名失败

原因1：

使用的不是定制化的qemu-ga

解决方法：

替换成定制化的qemu-ga（详细步骤见附录）。

原因2：

查看相关状态、日志信息，权限问题导致修改失败;



解决方法：

关闭虚机的selinux服务

# setenforce 0
# vim /etc/selinux/config

SELINUX=disabled

https://www.qemu.org/docs/master/interop/qemu-ga-ref.html

virsh migrate --verbose --live --copy-storage-all --persistent instance-200-new qemu+ssh://root@devstack-compute/system

root@devstack-controller:/opt/stack/devstack# openstack --verbose --debug project show admin
/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead
  from cryptography.utils import int_from_bytes
/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead
  from cryptography.utils import int_from_bytes
START with options: --verbose --debug project show admin
options: Namespace(access_key='', access_secret='***', access_token='***', access_token_endpoint='', access_token_type='', application_credential_id='', application_credential_name='', application_credential_secret='***', auth_methods='', auth_type='', auth_url='http://192.168.10.8/identity/', cacert=None, cert='', client_id='', client_secret='***', cloud='', code='', consumer_key='', consumer_secret='***', debug=True, default_domain='default', default_domain_id='', default_domain_name='', deferred_help=False, discovery_endpoint='', domain_id='', domain_name='', endpoint='', identity_provider='', identity_provider_url='', insecure=None, interface='public', key='', log_file=None, openid_scope='', os_beta_command=False, os_compute_api_version='', os_dns_api_version='2', os_identity_api_version='3', os_image_api_version='', os_key_manager_api_version='1', os_network_api_version='', os_object_api_version='', os_placement_api_version='1.0', os_project_id=None, os_project_name=None, os_volume_api_version='', passcode='', password='***', profile='', project_domain_id='default', project_domain_name='', project_id='', project_name='admin', protocol='', redirect_uri='', region_name='RegionOne', remote_project_domain_id='', remote_project_domain_name='', remote_project_id='', remote_project_name='', service_provider='', service_provider_endpoint='', service_provider_entity_id='', system_scope='', timing=False, token='***', trust_id='', user_domain_id='default', user_domain_name='', user_id='', username='admin', verbose_level=3, verify=None)
Auth plugin password selected
auth_config_hook(): {'api_timeout': None, 'verify': True, 'cacert': None, 'cert': None, 'key': None, 'baremetal_status_code_retries': '5', 'baremetal_introspection_status_code_retries': '5', 'image_status_code_retries': '5', 'disable_vendor_agent': {}, 'interface': 'public', 'floating_ip_source': 'neutron', 'image_api_use_tasks': False, 'image_format': 'qcow2', 'message': '', 'network_api_version': '2', 'object_store_api_version': '1', 'secgroup_source': 'neutron', 'status': 'active', 'auth': {'user_domain_id': 'default', 'project_domain_id': 'default', 'project_name': 'admin'}, 'verbose_level': 3, 'deferred_help': False, 'debug': True, 'region_name': 'RegionOne', 'default_domain': 'default', 'timing': False, 'username': 'admin', 'password': '***', 'auth_url': 'http://192.168.10.8/identity/', 'beta_command': False, 'identity_api_version': '3', 'dns_api_version': '2', 'key_manager_api_version': '1', 'placement_api_version': '1.0', 'auth_type': 'password', ': []}
defaults: {'api_timeout': None, 'verify': True, 'cacert': None, 'cert': None, 'key': None, 'auth_type': 'password', 'baremetal_status_code_retries': 5, 'baremetal_introspection_status_code_retries': 5, 'image_status_code_retries': 5, 'disable_vendor_agent': {}, 'interface': None, 'floating_ip_source': 'neutron', 'image_api_use_tasks': False, 'image_format': 'qcow2', 'message': '', 'network_api_version': '2', 'object_store_api_version': '1', 'secgroup_source': 'neutron', 'status': 'active'}
cloud cfg: {'api_timeout': None, 'verify': True, 'cacert': None, 'cert': None, 'key': None, 'baremetal_status_code_retries': '5', 'baremetal_introspection_status_code_retries': '5', 'image_status_code_retries': '5', 'disable_vendor_agent': {}, 'interface': 'public', 'floating_ip_source': 'neutron', 'image_api_use_tasks': False, 'image_format': 'qcow2', 'message': '', 'network_api_version': '2', 'object_store_api_version': '1', 'secgroup_source': 'neutron', 'status': 'active', 'auth': {'user_domain_id': 'default', 'project_domain_id': 'default', 'project_name': 'admin'}, 'verbose_level': 3, 'deferred_help': False, 'debug': True, 'region_name': 'RegionOne', 'default_domain': 'default', 'timing': False, 'username': 'admin', 'password': '***', 'auth_url': 'http://192.168.10.8/identity/', 'beta_command': False, 'identity_api_version': '3', 'dns_api_version': '2', 'key_manager_api_version': '1', 'placement_api_version': '1.0', 'auth_type': 'password', ': []}
compute API version 2.1, cmd group openstack.compute.v2
identity API version 3, cmd group openstack.identity.v3
image API version 2, cmd group openstack.image.v2
network API version 2, cmd group openstack.network.v2
object_store API version 1, cmd group openstack.object_store.v1
volume API version 3, cmd group openstack.volume.v3
dns API version 2, cmd group openstack.dns.v2
neutronclient API version 2, cmd group openstack.neutronclient.v2
/usr/local/lib/python3.8/dist-packages/barbicanclient/__init__.py:57: UserWarning: The secrets module is moved to barbicanclient/v1 directory, direct import of barbicanclient.secrets will be deprecated. Please import barbicanclient.v1.secrets instead.
  warnings.warn("The %s module is moved to barbicanclient/v1 "
key_manager API version 1, cmd group openstack.key_manager.v1
placement API version 1.0, cmd group openstack.placement.v1
command: project show -> openstackclient.identity.v3.project.ShowProject (auth=True)
Auth plugin password selected
auth_config_hook(): {'api_timeout': None, 'verify': True, 'cacert': None, 'cert': None, 'key': None, 'baremetal_status_code_retries': '5', 'baremetal_introspection_status_code_retries': '5', 'image_status_code_retries': '5', 'disable_vendor_agent': {}, 'interface': 'public', 'floating_ip_source': 'neutron', 'image_api_use_tasks': False, 'image_format': 'qcow2', 'message': '', 'network_api_version': '2', 'object_store_api_version': '1', 'secgroup_source': 'neutron', 'status': 'active', 'auth': {'user_domain_id': 'default', 'project_domain_id': 'default', 'project_name': 'admin'}, 'additional_user_agent': [('osc-lib', '2.3.1')], 'verbose_level': 3, 'deferred_help': False, 'debug': True, 'region_name': 'RegionOne', 'default_domain': 'default', 'timing': False, 'username': 'admin', 'password': '***', 'auth_url': 'http://192.168.10.8/identity/', 'beta_command': False, 'identity_api_version': '3', 'dns_api_version': '2', 'key_manager_api_version': '1', 'placement_api_version': '1.0', 'auth_type': 'password', ': []}
Using auth plugin: password
Using parameters {'auth_url': 'http://192.168.10.8/identity/', 'project_name': 'admin', 'project_domain_id': 'default', 'username': 'admin', 'user_domain_id': 'default', 'password': '***'}
Get auth_ref
REQ: curl -g -i -X GET http://192.168.10.8/identity/ -H "Accept: application/json" -H "User-Agent: openstacksdk/0.55.1 keystoneauth1/4.3.1 python-requests/2.25.1 CPython/3.8.10"
Starting new HTTP connection (1): 192.168.10.8:80
http://192.168.10.8:80 "GET /identity/ HTTP/1.1" 300 271
RESP: [300] Connection: close Content-Length: 271 Content-Type: application/json Date: Mon, 20 May 2024 02:00:03 GMT Location: http://192.168.10.8/identity/v3/ Server: Apache/2.4.41 (Ubuntu) Vary: X-Auth-Token x-openstack-request-id: req-9ec53e9f-ea2e-4d79-986a-d6dbf8ec1190
RESP BODY: {"versions": {"values": [{"id": "v3.14", "status": "stable", "updated": "2020-04-07T00:00:00Z", "links": [{"rel": "self", "href": "http://192.168.10.8/identity/v3/"}], "media-types": [{"base": "application/json", "type": "application/vnd.openstack.identity-v3+json"}]}]}}
GET call to http://192.168.10.8/identity/ used request id req-9ec53e9f-ea2e-4d79-986a-d6dbf8ec1190
Making authentication request to http://192.168.10.8/identity/v3/auth/tokens
Resetting dropped connection: 192.168.10.8
http://192.168.10.8:80 "POST /identity/v3/auth/tokens HTTP/1.1" 201 3239
{"token": {"methods": ["password"], "user": {"domain": {"id": "default", "name": "Default"}, "id": "9a5394d21895400eb233e109f7f0e7ab", "name": "admin", "password_expires_at": null}, "audit_ids": ["Dyn0f-h8Qgu85N3GhMYw2A"], "expires_at": "2024-05-20T03:00:03.000000Z", "issued_at": "2024-05-20T02:00:03.000000Z", "project": {"domain": {"id": "default", "name": "Default"}, "id": "313cf8edcbac4631a15ed781ffdfd275", "name": "admin"}, "is_domain": false, "roles": [{"id": "16603f05bf314b9da21a9264d87ceab0", "name": "member"}, {"id": "31015780f3e04c5eb4e1145e4ed984af", "name": "admin"}, {"id": "8554678f9d8e491ba379dabe6aabc478", "name": "reader"}], "catalog": [{"endpoints": [{"id": "5536e8a7bcaf4e4f85d0e646879b10f4", "interface": "public", "region_id": "RegionOne", "url": "http://192.168.10.8/identity", "region": "RegionOne"}, {"id": "e1860a15571e430cba3dc134f5def947", "interface": "admin", "region_id": "RegionOne", "url": "http://192.168.10.8/identity", "region": "RegionOne"}], "id": "0c08bb5598c94464be611114df84e8f2", "type": "identity", "name": "keystone"}, {"endpoints": [{"id": "751d02cabcc54540bc0721098eed0107", "interface": "public", "region_id": "RegionOne", "url": "http://192.168.10.8/volume/v2/313cf8edcbac4631a15ed781ffdfd275", "region": "RegionOne"}], "id": "12774bafe9ff459d8041ee780f2ccb77", "type": "volumev2", "name": "cinderv2"}, {"endpoints": [{"id": "489f5f0033cf489f8aff418594d2961a", "interface": "public", "region_id": "RegionOne", "url": "http://192.168.10.8/volume/v3/313cf8edcbac4631a15ed781ffdfd275", "region": "RegionOne"}], "id": "151a8ec5af6b429093458fa32c1b2b23", "type": "block-storage", "name": "cinder"}, {"endpoints": [{"id": "af88cf31ff89422280ba55167ff4fbd5", "interface": "public", "region_id": "RegionOne", "url": "http://192.168.10.8/placement", "region": "RegionOne"}], "id": "2c6cbdac04754feba7cd8181f6c46658", "type": "placement", "name": "placement"}, {"endpoints": [{"id": "8f59aa36416b49808ec5e5c4017931f4", "interface": "public", "region_id": "RegionOne", "url": "http://192.168.10.8/volume/v3/313cf8edcbac4631a15ed781ffdfd275", "region": "RegionOne"}], "id": "33b73e1464504fab902e23d3253221c5", "type": "volumev3", "name": "cinderv3"}, {"endpoints": [{"id": "1cbfa86690ef46c0988679ce96efda2f", "interface": "public", "region_id": "RegionOne", "url": "http://192.168.10.8/compute/v2.1", "region": "RegionOne"}], "id": "4c1042ab367043508f3fee84282ba262", "type": "compute", "name": "nova"}, {"endpoints": [{"id": "665ff0b325f34c448633a833ae743961", "interface": "public", "region_id": "RegionOne", "url": "http://192.168.10.8:9696/", "region": "RegionOne"}], "id": "82cd6b2260284144b0072fda34a2601e", "type": "network", "name": "neutron"}, {"endpoints": [{"id": "32db4240d94f477faf16ffb0ca8acb98", "interface": "public", "region_id": "RegionOne", "url": "http://192.168.10.8/compute/v2/313cf8edcbac4631a15ed781ffdfd275", "region": "RegionOne"}], "id": "bf825e66812846f3988ce33487ac304e", "type": "compute_legacy", "name": "nova_legacy"}, {"endpoints": [{"id": "d4af469c05d54a82af2d8bfa840790e8", "interface": "public", "region_id": "RegionOne", "url": "http://192.168.10.8/image", "region": "RegionOne"}], "id": "e38d4b265f8e4456a082a13a0104c338", "type": "image", "name": "glance"}]}}
run(Namespace(children=False, columns=[], domain=None, fit_width=False, formatter='table', max_width=0, noindent=False, parents=False, prefix='', print_empty=False, project='admin', variables=[]))
Instantiating identity client: <class 'keystoneclient.v3.client.Client'>
REQ: curl -g -i -X GET http://192.168.10.8/identity -H "Accept: application/json" -H "User-Agent: openstacksdk/0.55.1 keystoneauth1/4.3.1 python-requests/2.25.1 CPython/3.8.10"
Resetting dropped connection: 192.168.10.8
http://192.168.10.8:80 "GET /identity HTTP/1.1" 300 271
RESP: [300] Connection: close Content-Length: 271 Content-Type: application/json Date: Mon, 20 May 2024 02:00:03 GMT Location: http://192.168.10.8/identity/v3/ Server: Apache/2.4.41 (Ubuntu) Vary: X-Auth-Token x-openstack-request-id: req-92f1e686-f4e1-4a6a-a257-fecf528d8bce
RESP BODY: {"versions": {"values": [{"id": "v3.14", "status": "stable", "updated": "2020-04-07T00:00:00Z", "links": [{"rel": "self", "href": "http://192.168.10.8/identity/v3/"}], "media-types": [{"base": "application/json", "type": "application/vnd.openstack.identity-v3+json"}]}]}}
GET call to http://192.168.10.8/identity used request id req-92f1e686-f4e1-4a6a-a257-fecf528d8bce
REQ: curl -g -i -X GET http://192.168.10.8/identity/v3/auth/tokens -H "Accept: application/json" -H "User-Agent: python-keystoneclient" -H "X-Auth-Token: {SHA256}c65c3ec17dd7253736ede4ad202eab3af352f3ea27115cca5d3d8e7a98a03558" -H "X-Subject-Token: {SHA256}c65c3ec17dd7253736ede4ad202eab3af352f3ea27115cca5d3d8e7a98a03558"
Resetting dropped connection: 192.168.10.8
http://192.168.10.8:80 "GET /identity/v3/auth/tokens HTTP/1.1" 200 3239
RESP: [200] Connection: close Content-Length: 3239 Content-Type: application/json Date: Mon, 20 May 2024 02:00:03 GMT Server: Apache/2.4.41 (Ubuntu) Vary: X-Auth-Token X-Subject-Token: {SHA256}c65c3ec17dd7253736ede4ad202eab3af352f3ea27115cca5d3d8e7a98a03558 x-openstack-request-id: req-76c9cb5f-d600-45ac-be3a-df62b12e3b2d
RESP BODY: {"token": {"methods": ["password"], "user": {"domain": {"id": "default", "name": "Default"}, "id": "9a5394d21895400eb233e109f7f0e7ab", "name": "admin", "password_expires_at": null}, "audit_ids": ["Dyn0f-h8Qgu85N3GhMYw2A"], "expires_at": "2024-05-20T03:00:03.000000Z", "issued_at": "2024-05-20T02:00:03.000000Z", "project": {"domain": {"id": "default", "name": "Default"}, "id": "313cf8edcbac4631a15ed781ffdfd275", "name": "admin"}, "is_domain": false, "roles": [{"id": "16603f05bf314b9da21a9264d87ceab0", "name": "member"}, {"id": "31015780f3e04c5eb4e1145e4ed984af", "name": "admin"}, {"id": "8554678f9d8e491ba379dabe6aabc478", "name": "reader"}], "catalog": "<removed>"}}
GET call to identity for http://192.168.10.8/identity/v3/auth/tokens used request id req-76c9cb5f-d600-45ac-be3a-df62b12e3b2d
REQ: curl -g -i -X GET http://192.168.10.8/identity/v3/projects/313cf8edcbac4631a15ed781ffdfd275 -H "Accept: application/json" -H "User-Agent: python-keystoneclient" -H "X-Auth-Token: {SHA256}c65c3ec17dd7253736ede4ad202eab3af352f3ea27115cca5d3d8e7a98a03558"

Resetting dropped connection: 192.168.10.8
http://192.168.10.8:80 "GET /identity/v3/projects/313cf8edcbac4631a15ed781ffdfd275 HTTP/1.1" 200 345
RESP: [200] Connection: close Content-Length: 345 Content-Type: application/json Date: Mon, 20 May 2024 02:00:03 GMT Server: Apache/2.4.41 (Ubuntu) Vary: X-Auth-Token x-openstack-request-id: req-520edb3e-500c-484c-989c-102ef0454cc1
RESP BODY: {"project": {"id": "313cf8edcbac4631a15ed781ffdfd275", "name": "admin", "domain_id": "default", "description": "Bootstrap project for initializing the cloud.", "enabled": true, "parent_id": "default", "is_domain": false, "tags": [], "options": {}, "links": {"self": "http://192.168.10.8/identity/v3/projects/313cf8edcbac4631a15ed781ffdfd275"}}}

GET call to identity for http://192.168.10.8/identity/v3/projects/313cf8edcbac4631a15ed781ffdfd275 used request id req-520edb3e-500c-484c-989c-102ef0454cc1
+-------------+-----------------------------------------------+
| Field       | Value                                         |
+-------------+-----------------------------------------------+
| description | Bootstrap project for initializing the cloud. |
| domain_id   | default                                       |
| enabled     | True                                          |
| id          | 313cf8edcbac4631a15ed781ffdfd275              |
| is_domain   | False                                         |
| name        | admin                                         |
| options     | {}                                            |
| parent_id   | default                                       |
| tags        | []                                            |
+-------------+-----------------------------------------------+
clean_up ShowProject:
END return value: 0


curl -i -H "Content-Type: application/json" -d '{ "auth": { "identity": { "methods": ["password"], "password": { "user": { "name": "admin", "domain": { "id": "default" }, "password": "admin" } } } } }' "http://192.168.10.8/identity/v3/auth/tokens"


root@devstack-controller:/opt/stack/devstack# curl -i -H "Content-Type: application/json" -d '{ "auth": { "identity": { "methods": ["password"], "password": { "user": { "name": "admin", "domain": { "id": "default" }, "password": "admin" } } } } }' "http://192.168.10.8/identity/v3/auth/tokens"
HTTP/1.1 201 CREATED
Date: Mon, 20 May 2024 04:27:15 GMT
Server: Apache/2.4.41 (Ubuntu)
Content-Type: application/json
Content-Length: 312
X-Subject-Token: gAAAAABmStEjODaboZo4Zc3KfbzfaFsIgNsl9-7d6-EHaRm_5Lhr7RXzkarr9-1dFDRlFPOrlwIgMIQ5tVhGlpx_x7WJMhJKHjZSNLy3WENrLU3jMfzFbYcnm0HoXoiyFvy2F2s4xd4fbw1aGirYAOyQh6BJzUwLUg
Vary: X-Auth-Token
x-openstack-request-id: req-f0385056-0820-4d79-a207-125fe3f898e3
Connection: close

{"token": {"methods": ["password"], "user": {"domain": {"id": "default", "name": "Default"}, "id": "9a5394d21895400eb233e109f7f0e7ab", "name": "admin", "password_expires_at": null}, "audit_ids": ["iLxMrrvNTkWTNYz-p5r2iw"], "expires_at": "2024-05-20T05:27:15.000000Z", "issued_at": "2024-05-20T04:27:15.000000Z"}}


root@devstack-controller:/usr/local/lib/python3.8/dist-packages# grep -r "RESP:"
keystoneauth1/session.py:            string_parts.append('RESP:')
Binary file keystoneauth1/__pycache__/session.cpython-38.pyc matches
neutronclient/common/utils.py:    _logger.debug("RESP: %(code)s %(headers)s %(body)s",
Binary file neutronclient/common/__pycache__/utils.cpython-38.pyc matches
cinderclient/client.py:            "RESP: [%s] %s\nRESP BODY: %s\n",
Binary file cinderclient/__pycache__/client.cpython-38.pyc matches
keystoneclient/session.py:            'RESP:',
Binary file keystoneclient/__pycache__/session.cpython-38.pyc matches

root@devstack-controller:/usr/local/lib/python3.8/dist-packages# grep -r "{SHA256}"
keystoneauth1/session.py:            return (header[0], '{SHA256}%s' % token_hash)
keystoneauth1/tests/unit/test_session.py:            self.assertIn('%s: {SHA256}' % k, self.logger.output)
Binary file keystoneauth1/tests/unit/__pycache__/test_session.cpython-38.pyc matches
Binary file keystoneauth1/__pycache__/session.cpython-38.pyc matches
neutronclient/common/utils.py:            value = "{SHA256}%s" % d
Binary file neutronclient/common/__pycache__/utils.cpython-38.pyc matches

root@devstack-controller:/usr/local/lib/python3.8/dist-packages/keystoneauth1# grep -r "Making authentication request"
identity/v3/base.py:        _logger.debug('Making authentication request to %s', token_url)
Binary file identity/v3/__pycache__/base.cpython-38.pyc matches
identity/v2.py:        _logger.debug('Making authentication request to %s', url)
