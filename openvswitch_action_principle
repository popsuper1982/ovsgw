openvswitch dpdk gateway 添加operation及action

///////////////

git clone git@github.com:popsuper1982/ovsgw.git
wget https://fast.dpdk.org/rel/dpdk-19.11.2.tar.xz
yum install wget git gcc autoconf automake libtool make pkg-config uuid kernel-devel
yum install numactl-devel
yum install openssl-devel.x86_64
yum install libcap-ng-devel.x86_64

openvswitch-2.14.1.tar.gz
dpdk-19.11.2.tar.xz

tar xvzf openvswitch-2.14.1.tar.gz
tar vxf dpdk-19.11.2.tar.xz

///////////////先不修改编译一遍

创建common文件

export DPDK_DIR=/root/OVSGW/dpdk-stable-19.11.2
export DPDK_TARGET=x86_64-native-linuxapp-gcc
export RTE_SDK=/root/OVSGW/dpdk-stable-19.11.2
export RTE_TARGET=x86_64-native-linuxapp-gcc
export DPDK_BUILD=$DPDK_DIR/x86_64-native-linuxapp-gcc
export LD_LIBRARY_PATH=$DPDK_DIR/x86_64-native-linuxapp-gcc/lib

. common

cd dpdk-stable-19.11.2/

make install T=$DPDK_TARGET DESTDIR=install

cd openvswitch-2.14.1

./configure --with-dpdk=$DPDK_BUILD

make

make install

-----------make install输出-----------------

[root@localhost openvswitch-2.14.1]# make install
make  install-recursive
make[1]: Entering directory `/root/OVSGW/openvswitch-2.14.1'
Making install in datapath
make[2]: Entering directory `/root/OVSGW/openvswitch-2.14.1/datapath'
make[3]: Entering directory `/root/OVSGW/openvswitch-2.14.1/datapath'
make[4]: Entering directory `/root/OVSGW/openvswitch-2.14.1/datapath'
make[4]: Nothing to be done for `install-exec-am'.
make[4]: Nothing to be done for `install-data-am'.
make[4]: Leaving directory `/root/OVSGW/openvswitch-2.14.1/datapath'
make[3]: Leaving directory `/root/OVSGW/openvswitch-2.14.1/datapath'
make[2]: Leaving directory `/root/OVSGW/openvswitch-2.14.1/datapath'
make[2]: Entering directory `/root/OVSGW/openvswitch-2.14.1'
make[3]: Entering directory `/root/OVSGW/openvswitch-2.14.1'
 /usr/bin/mkdir -p '/usr/local/lib'
 /bin/sh ./libtool   --mode=install /usr/bin/install -c   lib/libopenvswitch.la lib/libsflow.la ofproto/libofproto.la ovsdb/libovsdb.la vtep/libvtep.la '/usr/local/lib'
libtool: install: /usr/bin/install -c lib/.libs/libopenvswitch.lai /usr/local/lib/libopenvswitch.la
libtool: install: /usr/bin/install -c lib/.libs/libsflow.lai /usr/local/lib/libsflow.la
libtool: install: /usr/bin/install -c ofproto/.libs/libofproto.lai /usr/local/lib/libofproto.la
libtool: install: /usr/bin/install -c ovsdb/.libs/libovsdb.lai /usr/local/lib/libovsdb.la
libtool: install: /usr/bin/install -c vtep/.libs/libvtep.lai /usr/local/lib/libvtep.la
libtool: install: /usr/bin/install -c lib/.libs/libopenvswitch.a /usr/local/lib/libopenvswitch.a
libtool: install: chmod 644 /usr/local/lib/libopenvswitch.a
libtool: install: ranlib /usr/local/lib/libopenvswitch.a
libtool: install: /usr/bin/install -c lib/.libs/libsflow.a /usr/local/lib/libsflow.a
libtool: install: chmod 644 /usr/local/lib/libsflow.a
libtool: install: ranlib /usr/local/lib/libsflow.a
libtool: install: /usr/bin/install -c ofproto/.libs/libofproto.a /usr/local/lib/libofproto.a
libtool: install: chmod 644 /usr/local/lib/libofproto.a
libtool: install: ranlib /usr/local/lib/libofproto.a
libtool: install: /usr/bin/install -c ovsdb/.libs/libovsdb.a /usr/local/lib/libovsdb.a
libtool: install: chmod 644 /usr/local/lib/libovsdb.a
libtool: install: ranlib /usr/local/lib/libovsdb.a
libtool: install: /usr/bin/install -c vtep/.libs/libvtep.a /usr/local/lib/libvtep.a
libtool: install: chmod 644 /usr/local/lib/libvtep.a
libtool: install: ranlib /usr/local/lib/libvtep.a
libtool: finish: PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/sbin" ldconfig -n /usr/local/lib
----------------------------------------------------------------------
Libraries have been installed in:
   /usr/local/lib

If you ever happen to want to link against installed libraries
in a given directory, LIBDIR, you must either use libtool, and
specify the full pathname of the library, or use the '-LLIBDIR'
flag during linking and do at least one of the following:
   - add LIBDIR to the 'LD_LIBRARY_PATH' environment variable
     during execution
   - add LIBDIR to the 'LD_RUN_PATH' environment variable
     during linking
   - use the '-Wl,-rpath -Wl,LIBDIR' linker flag
   - have your system administrator add LIBDIR to '/etc/ld.so.conf'

See any operating system documentation about shared libraries for
more information, such as the ld(1) and ld.so(8) manual pages.
----------------------------------------------------------------------
 /usr/bin/mkdir -p '/usr/local/bin'
  /bin/sh ./libtool   --mode=install /usr/bin/install -c utilities/ovs-appctl utilities/ovs-testcontroller utilities/ovs-dpctl utilities/ovs-ofctl utilities/ovs-vsctl ovsdb/ovsdb-tool ovsdb/ovsdb-client vtep/vtep-ctl '/usr/local/bin'
libtool: install: /usr/bin/install -c utilities/ovs-appctl /usr/local/bin/ovs-appctl
libtool: install: /usr/bin/install -c utilities/ovs-testcontroller /usr/local/bin/ovs-testcontroller
libtool: install: /usr/bin/install -c utilities/ovs-dpctl /usr/local/bin/ovs-dpctl
libtool: install: /usr/bin/install -c utilities/ovs-ofctl /usr/local/bin/ovs-ofctl
libtool: install: /usr/bin/install -c utilities/ovs-vsctl /usr/local/bin/ovs-vsctl
libtool: install: /usr/bin/install -c ovsdb/ovsdb-tool /usr/local/bin/ovsdb-tool
libtool: install: /usr/bin/install -c ovsdb/ovsdb-client /usr/local/bin/ovsdb-client
libtool: install: /usr/bin/install -c vtep/vtep-ctl /usr/local/bin/vtep-ctl
 /usr/bin/mkdir -p '/usr/local/bin'
 /usr/bin/install -c utilities/ovs-docker utilities/ovs-pki utilities/ovs-pcap utilities/ovs-tcpdump utilities/ovs-tcpundump utilities/ovs-dpctl-top utilities/ovs-l3ping utilities/ovs-parse-backtrace utilities/ovs-test utilities/ovs-vlan-test '/usr/local/bin'
 /usr/bin/mkdir -p '/usr/local/sbin'
  /bin/sh ./libtool   --mode=install /usr/bin/install -c vswitchd/ovs-vswitchd ovsdb/ovsdb-server '/usr/local/sbin'
libtool: install: /usr/bin/install -c vswitchd/ovs-vswitchd /usr/local/sbin/ovs-vswitchd
libtool: install: /usr/bin/install -c ovsdb/ovsdb-server /usr/local/sbin/ovsdb-server
 /usr/bin/mkdir -p '/usr/local/sbin'
 /usr/bin/install -c utilities/bugtool/ovs-bugtool '/usr/local/sbin'
 /usr/bin/mkdir -p '/usr/local/etc/bash_completion.d'
 /usr/bin/install -c utilities/ovs-appctl-bashcomp.bash utilities/ovs-vsctl-bashcomp.bash '/usr/local/etc/bash_completion.d'
/usr/bin/mkdir -p /usr/local/var/lib/openvswitch/pki
/usr/bin/mkdir -p /usr/local/etc/openvswitch
for plugin in utilities/bugtool/plugins/kernel-info/openvswitch.xml utilities/bugtool/plugins/network-status/openvswitch.xml utilities/bugtool/plugins/system-configuration.xml utilities/bugtool/plugins/system-logs/openvswitch.xml utilities/bugtool/plugins/system-configuration/openvswitch.xml; do \
  stem=`echo "$plugin" | sed 's,utilities/bugtool/plugins/,,'`; \
  dir=`expr "$stem" : '\(.*\)/[^/]*$'`; \
  /usr/bin/mkdir -p "/usr/local/share/openvswitch/bugtool-plugins/$dir"; \
  /usr/bin/install -c -m 644 "./$plugin" "/usr/local/share/openvswitch/bugtool-plugins/$stem"; \
done
/usr/bin/mkdir -p python/ovs
sed \
        -e '/^##/d' \
        -e 's,[@]pkgdatadir[@],/usr/local/share/openvswitch,g' \
        -e 's,[@]RUNDIR[@],/usr/local/var/run/openvswitch,g' \
        -e 's,[@]LOGDIR[@],/usr/local/var/log/openvswitch,g' \
        -e 's,[@]bindir[@],/usr/local/bin,g' \
        -e 's,[@]sysconfdir[@],/usr/local/etc,g' \
        -e 's,[@]DBDIR[@],/usr/local/etc/openvswitch,g' \
        < ./python/ovs/dirs.py.template \
        > python/ovs/dirs.py.tmp
/usr/bin/mkdir -p /usr/local/share/openvswitch/python/ovs
/usr/bin/install -c -m 644 python/ovs/dirs.py.tmp /usr/local/share/openvswitch/python/ovs/dirs.py
rm python/ovs/dirs.py.tmp
 /usr/bin/mkdir -p '/usr/local/share/man/man1'
 /usr/bin/install -c -m 644 utilities/ovs-pcap.1 ovsdb/ovsdb-tool.1 ovsdb/ovsdb-client.1 ovsdb/ovsdb-server.1 '/usr/local/share/man/man1'
 /usr/bin/mkdir -p '/usr/local/share/man/man5'
 /usr/bin/install -c -m 644 vswitchd/ovs-vswitchd.conf.db.5 ovsdb/ovsdb-server.5 vtep/vtep.5 '/usr/local/share/man/man5'
 /usr/bin/mkdir -p '/usr/local/share/man/man7'
 /usr/bin/install -c -m 644 lib/ovs-fields.7 lib/ovs-actions.7 '/usr/local/share/man/man7'
 /usr/bin/mkdir -p '/usr/local/share/man/man8'
 /usr/bin/install -c -m 644 utilities/ovs-testcontroller.8 utilities/ovs-dpctl.8 utilities/ovs-dpctl-top.8 utilities/ovs-kmod-ctl.8 utilities/ovs-ofctl.8 utilities/ovs-vsctl.8 utilities/bugtool/ovs-bugtool.8 vswitchd/ovs-vswitchd.8 vtep/vtep-ctl.8 '/usr/local/share/man/man8'
 /usr/bin/mkdir -p '/usr/local/share/openvswitch'
 /usr/bin/mkdir -p '/usr/local/share/openvswitch/python/ovs/unixctl'
 /usr/bin/install -c -m 644  python/ovs/unixctl/__init__.py python/ovs/unixctl/client.py python/ovs/unixctl/server.py '/usr/local/share/openvswitch/python/ovs/unixctl'
 /usr/bin/mkdir -p '/usr/local/share/openvswitch/python/ovs/compat'
 /usr/bin/install -c -m 644  python/ovs/compat/__init__.py '/usr/local/share/openvswitch/python/ovs/compat'
 /usr/bin/mkdir -p '/usr/local/share/openvswitch/python/ovs/db'
 /usr/bin/install -c -m 644  python/ovs/db/__init__.py python/ovs/db/custom_index.py python/ovs/db/data.py python/ovs/db/error.py python/ovs/db/idl.py python/ovs/db/parser.py python/ovs/db/schema.py python/ovs/db/types.py '/usr/local/share/openvswitch/python/ovs/db'
 /usr/bin/mkdir -p '/usr/local/share/openvswitch/python/ovs'
 /usr/bin/install -c -m 644  python/ovs/__init__.py python/ovs/daemon.py python/ovs/fcntl_win.py python/ovs/fatal_signal.py python/ovs/json.py python/ovs/jsonrpc.py python/ovs/ovsuuid.py python/ovs/poller.py python/ovs/process.py python/ovs/reconnect.py python/ovs/socket_util.py python/ovs/stream.py python/ovs/timeval.py python/ovs/util.py python/ovs/version.py python/ovs/vlog.py python/ovs/winutils.py '/usr/local/share/openvswitch/python/ovs'
 /usr/bin/mkdir -p '/usr/local/share/openvswitch/python/ovs/compat/sortedcontainers'
 /usr/bin/install -c -m 644  python/ovs/compat/sortedcontainers/__init__.py python/ovs/compat/sortedcontainers/sortedlist.py python/ovs/compat/sortedcontainers/sorteddict.py python/ovs/compat/sortedcontainers/sortedset.py '/usr/local/share/openvswitch/python/ovs/compat/sortedcontainers'
 /usr/bin/mkdir -p '/usr/local/share/openvswitch/python/ovstest'
 /usr/bin/install -c -m 644  python/ovstest/__init__.py python/ovstest/args.py python/ovstest/rpcserver.py python/ovstest/tcp.py python/ovstest/tests.py python/ovstest/udp.py python/ovstest/util.py python/ovstest/vswitch.py '/usr/local/share/openvswitch/python/ovstest'
 /usr/bin/mkdir -p '/usr/local/include/openflow'
 /usr/bin/install -c -m 644 include/openflow/intel-ext.h include/openflow/netronome-ext.h include/openflow/nicira-ext.h include/openflow/openflow-1.0.h include/openflow/openflow-1.1.h include/openflow/openflow-1.2.h include/openflow/openflow-1.3.h include/openflow/openflow-1.4.h include/openflow/openflow-1.5.h include/openflow/openflow-common.h include/openflow/openflow.h '/usr/local/include/openflow'
 /usr/bin/mkdir -p '/usr/local/include/openvswitch'
 /usr/bin/install -c -m 644 include/openvswitch/compiler.h include/openvswitch/dynamic-string.h include/openvswitch/hmap.h include/openvswitch/flow.h include/openvswitch/geneve.h include/openvswitch/json.h include/openvswitch/list.h include/openvswitch/netdev.h include/openvswitch/match.h include/openvswitch/meta-flow.h include/openvswitch/namemap.h include/openvswitch/ofpbuf.h include/openvswitch/ofp-actions.h include/openvswitch/ofp-bundle.h include/openvswitch/ofp-connection.h include/openvswitch/ofp-ed-props.h include/openvswitch/ofp-errors.h include/openvswitch/ofp-flow.h include/openvswitch/ofp-group.h include/openvswitch/ofp-ipfix.h include/openvswitch/ofp-match.h include/openvswitch/ofp-meter.h include/openvswitch/ofp-monitor.h include/openvswitch/ofp-msgs.h include/openvswitch/ofp-packet.h include/openvswitch/ofp-parse.h include/openvswitch/ofp-port.h include/openvswitch/ofp-print.h include/openvswitch/ofp-prop.h include/openvswitch/ofp-protocol.h include/openvswitch/ofp-queue.h include/openvswitch/ofp-switch.h include/openvswitch/ofp-table.h include/openvswitch/ofp-util.h include/openvswitch/packets.h include/openvswitch/poll-loop.h include/openvswitch/rconn.h include/openvswitch/shash.h include/openvswitch/thread.h include/openvswitch/token-bucket.h '/usr/local/include/openvswitch'
 /usr/bin/install -c -m 644 include/openvswitch/tun-metadata.h include/openvswitch/type-props.h include/openvswitch/types.h include/openvswitch/util.h include/openvswitch/uuid.h include/openvswitch/version.h include/openvswitch/vconn.h include/openvswitch/vlog.h include/openvswitch/nsh.h '/usr/local/include/openvswitch'
 /usr/bin/mkdir -p '/usr/local/lib/pkgconfig'
 /usr/bin/install -c -m 644 lib/libopenvswitch.pc lib/libsflow.pc ofproto/libofproto.pc ovsdb/libovsdb.pc '/usr/local/lib/pkgconfig'
 /usr/bin/mkdir -p '/usr/local/share/openvswitch'
 /usr/bin/install -c -m 644 vswitchd/vswitch.ovsschema vtep/vtep.ovsschema '/usr/local/share/openvswitch'
 /usr/bin/mkdir -p '/usr/local/share/openvswitch/scripts'
 /usr/bin/install -c -m 644 utilities/ovs-lib '/usr/local/share/openvswitch/scripts'
 /usr/bin/mkdir -p '/usr/local/share/openvswitch/scripts'
 /usr/bin/install -c utilities/ovs-check-dead-ifs utilities/ovs-ctl utilities/ovs-kmod-ctl utilities/ovs-save utilities/bugtool/ovs-bugtool-fdb-show utilities/bugtool/ovs-bugtool-tc-class-show utilities/bugtool/ovs-bugtool-daemons-ver utilities/bugtool/ovs-bugtool-ovs-ofctl-loop-over-bridges utilities/bugtool/ovs-bugtool-ovs-appctl-dpif utilities/bugtool/ovs-bugtool-ovs-bridge-datapath-type utilities/bugtool/ovs-bugtool-ovs-vswitchd-threads-affinity utilities/bugtool/ovs-bugtool-qos-configs utilities/bugtool/ovs-bugtool-get-dpdk-nic-numa utilities/bugtool/ovs-bugtool-get-port-stats ipsec/ovs-monitor-ipsec vtep/ovs-vtep '/usr/local/share/openvswitch/scripts'
make[3]: Leaving directory `/root/OVSGW/openvswitch-2.14.1'
make[2]: Leaving directory `/root/OVSGW/openvswitch-2.14.1'
make[1]: Leaving directory `/root/OVSGW/openvswitch-2.14.1'
------------------------------------


//////// 1. 定义openflow action

所有action定义在lib/ofp-actions.c

在enum ofp_raw_action_type {中添加

    /* OF1.0+(28): struct ofp_action_config_gw. */
    OFPAT_RAW_CONFIG_GW,

    /* OF1.0+(29): struct ofp_action_handle_gw. */
    OFPAT_RAW_HANDLE_GW,

注：注释非常重要，说明了协议版本，序号，构造openflow消息所需参数
有些函数头是根据协议版本、代码和操作所需的参数类型自动生成的。 后面的序号是独一无二的，不能在同一协议版本中出现两个一样的序号

    /* OF1.0+(29): uint32_t. */
　　OFPAT_RAW_PROBDROP,

配置了上述后，编译过程会自动生成函数
put_OFPAT_action构造openflow消息
put_OFPAT_PROBDROP: 根据 uint32_t构造出openflow消息

定义openflow action
+ /* OF1.0(28): ovs_be32. */
+ OFPAT_RAW10_HANDLE_EXAMPLE,
+ /* OF1.1(28): ovs_be32. */
+ OFPAT_RAW11_HANDLE_EXAMPLE,
+ /* OF1.2-1.4(28): ovs_be32. */
+ OFPAT_RAW12_HANDLE_EXAMPLE,

构造出
put_OFPATx_HANDLE_EXAMPLE: 根据ovs_be32构造出openflow消息
put_OFPAT10_HANDLE_EXAMPLE(out);
put_OFPAT11_HANDLE_EXAMPLE(out);
put_OFPAT12_HANDLE_EXAMPLE(out);

    /* NX1.0+(10): struct nx_action_multipath. VLMFF */
    NXAST_RAW_MULTIPATH,

    /* NX1.0+(34): struct nx_action_conjunction. */
    NXAST_RAW_CONJUNCTION,

    /* NX1.0+(16): struct nx_action_learn, ... VLMFF */
    NXAST_RAW_LEARN,

所以上述我们的两个定义也会生成两个函数
put_OFPAT_CONFIG_GW 根据ofp_action_config_gw构造出openflow消息
put_OFPAT_HANDLE_GW 根据ofp_action_handle_gw构造出openflow消息

接下来定义struct ofp_action_config_gw和struct ofp_action_handle_gw

这里的参数类型有以下几种，可以给我们参考
uint16_t —————— 普通16位
uint8_t —————— 普通8位
uint32_t
uint64_t
ovs_be16 —————— big endian 16位
ovs_be32 —————— big endian 32位
struct ofp_action_dl_addr { —————— MAC地址
    ovs_be16 type;                  /* Type. */
    ovs_be16 len;                   /* Length is 16. */
    struct eth_addr dl_addr;        /* Ethernet address. */
    uint8_t pad[6];
};
OFP_ASSERT(sizeof(struct ofp_action_dl_addr) == 16);
struct nx_action_cnt_ids {
    ovs_be16 type;              /* OFPAT_VENDOR. */
    ovs_be16 len;               /* Length including slaves. */
    ovs_be32 vendor;            /* NX_VENDOR_ID. */
    ovs_be16 subtype;           /* NXAST_DEC_TTL_CNT_IDS. */

    ovs_be16 n_controllers;     /* Number of controllers. */
    uint8_t zeros[4];           /* Must be zero. */

    /* Followed by 1 or more controller ids:
     *
     * uint16_t cnt_ids[];      -- Controller ids.
     * uint8_t pad[];           -- Must be 0 to 8-byte align cnt_ids[].
     */
};
OFP_ASSERT(sizeof(struct nx_action_cnt_ids) == 16);
struct ofp15_action_copy_field {
    ovs_be16 type;              /* OFPAT_COPY_FIELD. */
    ovs_be16 len;               /* Length is padded to 64 bits. */
    ovs_be16 n_bits;            /* Number of bits to copy. */
    ovs_be16 src_offset;        /* Starting bit offset in source. */
    ovs_be16 dst_offset;        /* Starting bit offset in destination. */
    uint8_t pad[2];
    /* Followed by:
     * - OXM header for source field.
     * - OXM header for destination field.
     * - Padding with 0-bytes to a multiple of 8 bytes.
     * The "pad2" member is the beginning of the above. */
    uint8_t pad2[4];
};
OFP_ASSERT(sizeof(struct ofp15_action_copy_field) == 16);
struct nx_action_reg_load {
    ovs_be16 type;                  /* OFPAT_VENDOR. */
    ovs_be16 len;                   /* Length is 24. */
    ovs_be32 vendor;                /* NX_VENDOR_ID. */
    ovs_be16 subtype;               /* NXAST_REG_LOAD. */
    ovs_be16 ofs_nbits;             /* (ofs << 6) | (n_bits - 1). */
    ovs_be32 dst;                   /* Destination register. */
    ovs_be64 value;                 /* Immediate value. */
};
OFP_ASSERT(sizeof(struct nx_action_reg_load) == 24);
struct onf_action_copy_field {
    ovs_be16 type;              /* OFPAT_EXPERIMENTER. */
    ovs_be16 len;               /* Length is padded to 64 bits. */
    ovs_be32 experimenter;      /* ONF_VENDOR_ID. */
    ovs_be16 exp_type;          /* 3200. */
    uint8_t pad[2];             /* Not used. */
    ovs_be16 n_bits;            /* Number of bits to copy. */
    ovs_be16 src_offset;        /* Starting bit offset in source. */
    ovs_be16 dst_offset;        /* Starting bit offset in destination. */
    uint8_t pad2[2];            /* Not used. */
    /* Followed by:
     * - OXM header for source field.
     * - OXM header for destination field.
     * - Padding with 0-bytes (either 0 or 4 of them) to a multiple of 8 bytes.
     * The "pad3" member is the beginning of the above. */
    uint8_t pad3[4];            /* Not used. */
};
OFP_ASSERT(sizeof(struct onf_action_copy_field) == 24);
struct nx_action_conntrack {
    ovs_be16 type;              /* OFPAT_VENDOR. */
    ovs_be16 len;               /* At least 24. */
    ovs_be32 vendor;            /* NX_VENDOR_ID. */
    ovs_be16 subtype;           /* NXAST_CT. */
    ovs_be16 flags;             /* Zero or more NX_CT_F_* flags.
                                 * Unspecified flag bits must be zero. */
    ovs_be32 zone_src;          /* Connection tracking context. */
    union {
        ovs_be16 zone_ofs_nbits;/* Range to use from source field. */
        ovs_be16 zone_imm;      /* Immediate value for zone. */
    };
    uint8_t recirc_table;       /* Recirculate to a specific table, or
                                   NX_CT_RECIRC_NONE for no recirculation. */
    uint8_t pad[3];             /* Zeroes */
    ovs_be16 alg;               /* Well-known port number for the protocol.
                                 * 0 indicates no ALG is required. */
    /* Followed by a sequence of zero or more OpenFlow actions. The length of
     * these is included in 'len'. */
};
OFP_ASSERT(sizeof(struct nx_action_conntrack) == 24);
struct nx_action_learn {
    ovs_be16 type;              /* OFPAT_VENDOR. */
    ovs_be16 len;               /* At least 24. */
    ovs_be32 vendor;            /* NX_VENDOR_ID. */
    ovs_be16 subtype;           /* NXAST_LEARN. */
    ovs_be16 idle_timeout;      /* Idle time before discarding (seconds). */
    ovs_be16 hard_timeout;      /* Max time before discarding (seconds). */
    ovs_be16 priority;          /* Priority level of flow entry. */
    ovs_be64 cookie;            /* Cookie for new flow. */
    ovs_be16 flags;             /* NX_LEARN_F_*. */
    uint8_t table_id;           /* Table to insert flow entry. */
    uint8_t pad;                /* Must be zero. */
    ovs_be16 fin_idle_timeout;  /* Idle timeout after FIN, if nonzero. */
    ovs_be16 fin_hard_timeout;  /* Hard timeout after FIN, if nonzero. */
    /* Followed by a sequence of flow_mod_spec elements, as described above,
     * until the end of the action is reached. */
};
OFP_ASSERT(sizeof(struct nx_action_learn) == 32);
struct nx_action_learn2 {
    struct nx_action_learn up;  /* The wire format includes nx_action_learn. */
    ovs_be32 limit;             /* Maximum number of learned flows.
                                 * 0 indicates unlimited. */

    /* Where to store the result. */
    ovs_be16 result_dst_ofs;    /* Starting bit offset in destination. */

    ovs_be16 pad2;              /* Must be zero. */
    /* Followed by:
     * - OXM/NXM header for destination field (4 or 8 bytes),
     *   if NX_LEARN_F_WRITE_RESULT is set in 'flags'
     * - a sequence of flow_mod_spec elements, as described above,
     *   until the end of the action is reached. */
};
OFP_ASSERT(sizeof(struct nx_action_learn2) == 40);

struct nx_action_multipath {
    ovs_be16 type;              /* OFPAT_VENDOR. */
    ovs_be16 len;               /* Length is 32. */
    ovs_be32 vendor;            /* NX_VENDOR_ID. */
    ovs_be16 subtype;           /* NXAST_MULTIPATH. */

    /* What fields to hash and how. */
    ovs_be16 fields;            /* One of NX_HASH_FIELDS_*. */
    ovs_be16 basis;             /* Universal hash parameter. */
    ovs_be16 pad0;

    /* Multipath link choice algorithm to apply to hash value. */
    ovs_be16 algorithm;         /* One of NX_MP_ALG_*. */
    ovs_be16 max_link;          /* Number of output links, minus 1. */
    ovs_be32 arg;               /* Algorithm-specific argument. */
    ovs_be16 pad1;

    /* Where to store the result. */
    ovs_be16 ofs_nbits;         /* (ofs << 6) | (n_bits - 1). */
    ovs_be32 dst;               /* Destination. */
};
OFP_ASSERT(sizeof(struct nx_action_multipath) == 32);

struct nx_action_conjunction {
    ovs_be16 type;                  /* OFPAT_VENDOR. */
    ovs_be16 len;                   /* At least 16. */
    ovs_be32 vendor;                /* NX_VENDOR_ID. */
    ovs_be16 subtype;               /* See enum ofp_raw_action_type. */
    uint8_t clause;
    uint8_t n_clauses;
    ovs_be32 id;
};
OFP_ASSERT(sizeof(struct nx_action_conjunction) == 16);

我们添加两个struct的定义，并且设置cache对齐

struct ofp_action_config_gw {
    ovs_be16 type;
    ovs_be16 len;
    uint32_t param1;
    ovs_be32 param2;
    struct eth_addr param3;
    uint32_t param4;
    ovs_be32 param5;
    struct eth_addr param6;
    uint32_t param7;
    ovs_be32 param8;
    struct eth_addr param9;
    uint8_t pad[2];
};
OFP_ASSERT(sizeof(struct ofp_action_config_gw) == 48);

struct ofp_action_handle_gw {
    ovs_be16 type;
    ovs_be16 len;
    uint32_t pipeline1;
    uint32_t pipeline2;
    uint32_t pipeline3;
    uint32_t pipeline4;
    uint32_t pipeline5;
};
OFP_ASSERT(sizeof(struct ofp_action_handle_gw) == 24);

///////////////////2. 定义openvswitch action

所有action定义在include/openvswitch/ofp-actions.h中

OFPACT(HANDLE_EXAMPLE, ofpact_handle_example, ofpact, "handle_example") \

构造出

OFPACT_HANDLE_EXAMPLE

ofpact_put_HANDLE_EXAMPLE: 将ofpbuf转化为struct ofpact_handle_example: openflow消息转化openvswitch action

ofpact_get_HANDLE_EXAMPLE: 从ofpact获取为struct ofpact_handle_example: 获取openvswitch action

struct ofpact_handle_example {
struct ofpact ofpact;
uint32_t data;
};

#define OFPACTS                                                         \
    /* Output. */                                                       \
    OFPACT(OUTPUT,          ofpact_output,      ofpact, "output")       \
    OFPACT(GROUP,           ofpact_group,       ofpact, "group")        \
    OFPACT(CONTROLLER,      ofpact_controller,  ofpact, "controller")   \
    OFPACT(ENQUEUE,         ofpact_enqueue,     ofpact, "enqueue")      \
    OFPACT(OUTPUT_REG,      ofpact_output_reg,  ofpact, "output_reg")   \
    OFPACT(BUNDLE,          ofpact_bundle,      slaves, "bundle")       \
                                                                        \
    /* Header changes. */                                               \
    OFPACT(SET_FIELD,       ofpact_set_field,   ofpact, "set_field")    \
    OFPACT(HANDLE_GTP,      ofpact_null,        ofpact, "handle_gtp")    \
    OFPACT(HANDLE_PGW_SGI,  ofpact_null,        ofpact, "handle_pgw_sgi")    \
    OFPACT(OPERATE_GTP,     ofpact_operate_gtp, ofpact, "operate_gtp")    \
    OFPACT(GTP_TEID,        ofpact_gtp_teid,    ofpact, "gtp_teid")    \
    OFPACT(GTP_PGW_IP,      ofpact_gtp_pgw_ip,  ofpact, "gtp_pgw_ip")    \
    OFPACT(OVS_ID,          ofpact_ovs_id,      ofpact, "ovs_id")    \
    OFPACT(OVS_TOTAL,       ofpact_ovs_total,   ofpact, "ovs_total")    \
    OFPACT(GTP_PGW_PORT,    ofpact_gtp_pgw_port,ofpact, "gtp_pgw_port")    \
    OFPACT(OVS_PHY_PORT,    ofpact_ovs_phy_port,ofpact, "ovs_phy_port")    \
    OFPACT(PGW_SGI_PORT,    ofpact_pgw_sgi_port,ofpact, "pgw_sgi_port")    \
    OFPACT(PGW_FASTPATH,    ofpact_pgw_fastpath,ofpact, "pgw_fastpath")    \
    OFPACT(GTP_PGW_ETH,     ofpact_mac,         ofpact, "gtp_pgw_eth")   \
    OFPACT(PGW_SGI_ETH,     ofpact_mac,         ofpact, "pgw_sgi_eth")   \
    OFPACT(SET_VLAN_VID,    ofpact_vlan_vid,    ofpact, "set_vlan_vid") \
    OFPACT(SET_VLAN_PCP,    ofpact_vlan_pcp,    ofpact, "set_vlan_pcp") \
    OFPACT(STRIP_VLAN,      ofpact_null,        ofpact, "strip_vlan")   \
    OFPACT(PUSH_VLAN,       ofpact_null,        ofpact, "push_vlan")    \
    OFPACT(SET_ETH_SRC,     ofpact_mac,         ofpact, "mod_dl_src")   \
    OFPACT(SET_ETH_DST,     ofpact_mac,         ofpact, "mod_dl_dst")   \
    OFPACT(SET_IPV4_SRC,    ofpact_ipv4,        ofpact, "mod_nw_src")   \
    OFPACT(SET_IPV4_DST,    ofpact_ipv4,        ofpact, "mod_nw_dst")   \
    OFPACT(SET_IP_DSCP,     ofpact_dscp,        ofpact, "mod_nw_tos")   \
    OFPACT(SET_IP_ECN,      ofpact_ecn,         ofpact, "mod_nw_ecn")   \
    OFPACT(SET_IP_TTL,      ofpact_ip_ttl,      ofpact, "mod_nw_ttl")   \
    OFPACT(SET_L4_SRC_PORT, ofpact_l4_port,     ofpact, "mod_tp_src")   \
    OFPACT(SET_L4_DST_PORT, ofpact_l4_port,     ofpact, "mod_tp_dst")   \
    OFPACT(REG_MOVE,        ofpact_reg_move,    ofpact, "move")         \
    OFPACT(STACK_PUSH,      ofpact_stack,       ofpact, "push")         \
    OFPACT(STACK_POP,       ofpact_stack,       ofpact, "pop")          \
    OFPACT(DEC_TTL,         ofpact_cnt_ids,     cnt_ids, "dec_ttl")     \
    OFPACT(SET_MPLS_LABEL,  ofpact_mpls_label,  ofpact, "set_mpls_label") \
    OFPACT(SET_MPLS_TC,     ofpact_mpls_tc,     ofpact, "set_mpls_tc")  \
    OFPACT(SET_MPLS_TTL,    ofpact_mpls_ttl,    ofpact, "set_mpls_ttl") \
    OFPACT(DEC_MPLS_TTL,    ofpact_null,        ofpact, "dec_mpls_ttl") \
    OFPACT(PUSH_MPLS,       ofpact_push_mpls,   ofpact, "push_mpls")    \
    OFPACT(POP_MPLS,        ofpact_pop_mpls,    ofpact, "pop_mpls")     \

    OFPACT(CONJUNCTION,     ofpact_conjunction, ofpact, "conjunction")  \
    OFPACT(MULTIPATH,       ofpact_multipath,   ofpact, "multipath")    \

ofpact_null表示这个action没有参数
ofpact_gtp_pgw_ip表示这个action是有参数的

/* OFPACT_GTP_PGW_IP.
 * Used for OFPAT10_GTP_PGW_IP, OFPAT11_GTP_PGW_IP, OFPAT12_GTP_PGW_IP */
struct ofpact_gtp_pgw_ip {
    struct ofpact ofpact;
    ovs_be32 gtp_pgw_ip;
};

/usr/local/bin/ovs-ofctl add-flow sdmn_br "ip,nw_src=192.168.200.104 actions=operate_gtp:1,gtp_pgw_ip:${DOCKER_IP},gtp_pgw_port:${DOCKER_ETH1_PORT},gtp_pgw_eth:${DOCKER_ETH1_MAC},pgw_sgi_port:${DOCKER_ETH2_PORT},pgw_sgi_eth:${DOCKER_ETH2_MAC}"

/* OFPACT_CONJUNCTION.
 *
 * Used for NXAST_CONJUNCTION. */
struct ofpact_conjunction {
    struct ofpact ofpact;
    uint8_t clause;
    uint8_t n_clauses;
    uint32_t id;
};

/* OFPACT_MULTIPATH.
 *
 * Used for NXAST_MULTIPATH. */
struct ofpact_multipath {
    struct ofpact ofpact;

    /* What fields to hash and how. */
    enum nx_hash_fields fields;
    uint16_t basis;             /* Universal hash parameter. */

    /* Multipath link choice algorithm to apply to hash value. */
    enum nx_mp_algorithm algorithm;
    uint16_t max_link;          /* Number of output links, minus 1. */
    uint32_t arg;               /* Algorithm-specific argument. */

    /* Where to store the result. */
    struct mf_subfield dst;
};

struct ofpact_stack {
    OFPACT_PADDED_MEMBERS(
        struct ofpact ofpact;
        struct mf_subfield subfield;
    );
};

对于我们来说，添加这两个

    OFPACT(CONFIG_GW,       ofpact_config_gw,   ofpact, "config_gw")  \
    OFPACT(HANDLE_GW,       ofpact_handle_gw,   ofpact, "handle_gw") \

这里相当于定义两个openvswitch action
OFPACT_CONFIG_GW
OFPACT_HANDLE_GW

还需要定义两个参数的结构

struct ofpact_config_gw {
    OFPACT_PADDED_MEMBERS(
        struct ofpact ofpact;
        uint32_t param1;
        ovs_be32 param2;
        struct eth_addr param3;
        uint32_t param4;
        ovs_be32 param5;
        struct eth_addr param6;
        uint32_t param7;
        ovs_be32 param8;
        struct eth_addr param9;
    );
};

struct ofpact_handle_gw {
    OFPACT_PADDED_MEMBERS(
        struct ofpact ofpact;
        uint32_t pipeline1;
        uint32_t pipeline2;
        uint32_t pipeline3;
        uint32_t pipeline4;
        uint32_t pipeline5;
    );
};

定义openvswitch action会生成一些列函数

/* For each OFPACT_<ENUM> with a corresponding struct <STRUCT>, this defines
 * the following commonly useful functions:
 *
 *   struct <STRUCT> *ofpact_put_<ENUM>(struct ofpbuf *ofpacts);
 *
 *     Appends a new 'ofpact', of length OFPACT_<ENUM>_SIZE, to 'ofpacts',
 *     initializes it with ofpact_init_<ENUM>(), and returns it.  Also sets
 *     'ofpacts->header' to the returned action.
 *
 *     After using this function to add a variable-length action, add the
 *     elements of the flexible array (e.g. with ofpbuf_put()), then use
 *     ofpact_finish() to pad the action to a multiple of OFPACT_ALIGNTO bytes
 *     and update its embedded length field.  (Keep in mind the need to refresh
 *     the structure from 'ofpacts->header' after adding data to 'ofpacts'.)
 *
 *   struct <STRUCT> *ofpact_get_<ENUM>(const struct ofpact *ofpact);
 *
 *     Returns 'ofpact' cast to "struct <STRUCT> *".  'ofpact->type' must be
 *     OFPACT_<ENUM>.
 *
 *   void ofpact_finish_<ENUM>(struct ofpbuf *ofpacts, struct <STRUCT> **ap);
 *
 *     Finishes composing variable-length action '*ap' (begun using
 *     ofpact_put_<NAME>() on 'ofpacts'), by padding the action to a multiple
 *     of OFPACT_ALIGNTO bytes and updating its embedded length field.
 *
 *     May reallocate 'ofpacts', and so as a convenience automatically updates
 *     '*ap' to point to the new location.  If the caller has other pointers
 *     within 'ap' or 'ofpacts', it needs to update them manually.
 *
 * as well as the following more rarely useful definitions:
 *
 *   void ofpact_init_<ENUM>(struct <STRUCT> *ofpact);
 *
 *     Initializes the parts of 'ofpact' that identify it as having type
 *     OFPACT_<ENUM> and length OFPACT_<ENUM>_SIZE and zeros the rest.
 */

ofpact_put_HANDLE_EXAMPLE: 将ofpbuf转化为struct ofpact_handle_example: openflow消息转化openvswitch action

ofpact_get_HANDLE_EXAMPLE: 从ofpact获取为struct ofpact_handle_example: 获取openvswitch action

ofpact_put_MULTIPATH是自动生成的，如何使用见如下代码

    struct ofpbuf *out;
    struct ofpact_multipath *mp;
    mp = ofpact_put_MULTIPATH(out);
    mp->fields = ntohs(nam->fields);
    mp->basis = ntohs(nam->basis);
    mp->algorithm = ntohs(nam->algorithm);
    mp->max_link = ntohs(nam->max_link);
    mp->arg = ntohl(nam->arg);
    mp->dst.ofs = nxm_decode_ofs(nam->ofs_nbits);
    mp->dst.n_bits = nxm_decode_n_bits(nam->ofs_nbits);

ofpact_put_CONJUNCTION是自动生成的，如何使用见如下代码

    struct ofpbuf *out;
    struct ofpact_conjunction *oc;
    oc = ofpact_put_CONJUNCTION(out);
    oc->id = id;
    oc->clause = clause;
    oc->n_clauses = n_clauses;

//////////////3. openflow action与openvswitch action转化


openflow action 与openvswitch action 有对应关系在ofpact_map中, 可以理解为多个版本openflow对应一个openvswitch action

 { OFPACT_HANDLE_EXAMPLE, 28 },
 { OFPACT_HANDLE_EXAMPLE, 28 },
 { OFPACT_HANDLE_EXAMPLE, 28 },

我们修改static const struct ofpact_map * get_ofpact_map(enum ofp_version version)

做了一个映射OFPACT_CONFIG_GW是openvswitch的action，28是openflow的action

static const struct ofpact_map *
get_ofpact_map(enum ofp_version version)
{
    /* OpenFlow 1.0 actions. */
    static const struct ofpact_map of10[] = {
        { OFPACT_OUTPUT, 0 },
        { OFPACT_SET_VLAN_VID, 1 },
        { OFPACT_SET_VLAN_PCP, 2 },
        { OFPACT_STRIP_VLAN, 3 },
        { OFPACT_SET_ETH_SRC, 4 },
        { OFPACT_SET_ETH_DST, 5 },
        { OFPACT_SET_IPV4_SRC, 6 },
        { OFPACT_SET_IPV4_DST, 7 },
        { OFPACT_SET_IP_DSCP, 8 },
        { OFPACT_SET_L4_SRC_PORT, 9 },
        { OFPACT_SET_L4_DST_PORT, 10 },
        { OFPACT_ENQUEUE, 11 },
        { OFPACT_CONFIG_GW, 28},
        { OFPACT_HANDLE_GW, 29},
        { 0, -1 },
    };

    /* OpenFlow 1.1 actions. */
    static const struct ofpact_map of11[] = {
        { OFPACT_OUTPUT, 0 },
        { OFPACT_SET_VLAN_VID, 1 },
        { OFPACT_SET_VLAN_PCP, 2 },
        { OFPACT_SET_ETH_SRC, 3 },
        { OFPACT_SET_ETH_DST, 4 },
        { OFPACT_SET_IPV4_SRC, 5 },
        { OFPACT_SET_IPV4_DST, 6 },
        { OFPACT_SET_IP_DSCP, 7 },
        { OFPACT_SET_IP_ECN, 8 },
        { OFPACT_SET_L4_SRC_PORT, 9 },
        { OFPACT_SET_L4_DST_PORT, 10 },
        /* OFPAT_COPY_TTL_OUT (11) not supported. */
        /* OFPAT_COPY_TTL_IN (12) not supported. */
        { OFPACT_SET_MPLS_LABEL, 13 },
        { OFPACT_SET_MPLS_TC, 14 },
        { OFPACT_SET_MPLS_TTL, 15 },
        { OFPACT_DEC_MPLS_TTL, 16 },
        { OFPACT_PUSH_VLAN, 17 },
        { OFPACT_STRIP_VLAN, 18 },
        { OFPACT_PUSH_MPLS, 19 },
        { OFPACT_POP_MPLS, 20 },
        { OFPACT_SET_QUEUE, 21 },
        { OFPACT_GROUP, 22 },
        { OFPACT_SET_IP_TTL, 23 },
        { OFPACT_DEC_TTL, 24 },
        { OFPACT_CONFIG_GW, 28},
        { OFPACT_HANDLE_GW, 29},
        { 0, -1 },
    };

    /* OpenFlow 1.2, 1.3, and 1.4 actions. */
    static const struct ofpact_map of12[] = {
        { OFPACT_OUTPUT, 0 },
        /* OFPAT_COPY_TTL_OUT (11) not supported. */
        /* OFPAT_COPY_TTL_IN (12) not supported. */
        { OFPACT_SET_MPLS_TTL, 15 },
        { OFPACT_DEC_MPLS_TTL, 16 },
        { OFPACT_PUSH_VLAN, 17 },
        { OFPACT_STRIP_VLAN, 18 },
        { OFPACT_PUSH_MPLS, 19 },
        { OFPACT_POP_MPLS, 20 },
        { OFPACT_SET_QUEUE, 21 },
        { OFPACT_GROUP, 22 },
        { OFPACT_SET_IP_TTL, 23 },
        { OFPACT_DEC_TTL, 24 },
        { OFPACT_SET_FIELD, 25 },
        /* OF1.3+ OFPAT_PUSH_PBB (26) not supported. */
        /* OF1.3+ OFPAT_POP_PBB (27) not supported. */
        { OFPACT_CONFIG_GW, 28},
        { OFPACT_HANDLE_GW, 29},
        { 0, -1 },
    };

    switch (version) {
    case OFP10_VERSION:
        return of10;

    case OFP11_VERSION:
        return of11;

    case OFP12_VERSION:
    case OFP13_VERSION:
    case OFP14_VERSION:
    case OFP15_VERSION:
    default:
        return of12;
    }
}





openflow action与openvswitch action转化
ofpact_decode---->decode_OFPAT_RAW_PROBDROP: 解openflow消息生成openvswitch action
ofpact_encode---->encode_PROBDROP: 从ofpact_type构造openflow消息
ofpact_parse---->parse_PROBDROP: 从字符串解析构造openvswitch action
ofpact_format---->format_PROBDROP: 将openvswitch action转化为string
ofpact_format---->check_PROBDROP:校验openvswitch action


我们参考一个结构稍微复杂的decode和encode方法

    openflow action的相关定义
    /* OF1.0(4), OF1.1(3), OF1.2+(3) is deprecated (use Set-Field): struct
     * ofp_action_dl_addr. */
    OFPAT_RAW_SET_DL_SRC,

    /* OF1.0(5), OF1.1(4), OF1.2+(4) is deprecated (use Set-Field): struct
     * ofp_action_dl_addr. */
    OFPAT_RAW_SET_DL_DST,

    struct ofp_action_dl_addr {
        ovs_be16 type;                  /* Type. */
        ovs_be16 len;                   /* Length is 16. */
        struct eth_addr dl_addr;        /* Ethernet address. */
        uint8_t pad[6];
    };
    OFP_ASSERT(sizeof(struct ofp_action_dl_addr) == 16);

    openvswitch action的相关定义
    OFPACT(SET_ETH_SRC,     ofpact_mac,         ofpact, "mod_dl_src")   \
    OFPACT(SET_ETH_DST,     ofpact_mac,         ofpact, "mod_dl_dst")   \

    struct ofpact_mac {
        OFPACT_PADDED_MEMBERS(
            struct ofpact ofpact;
            struct eth_addr mac;
        );
    };

static enum ofperr
decode_OFPAT_RAW_SET_DL_SRC(const struct ofp_action_dl_addr *a,
                            enum ofp_version ofp_version OVS_UNUSED,
                            struct ofpbuf *out)
{
/*
ofpact_put_SET_ETH_SRC(out)将struct ofpbuf转换为struct ofpact_mac，是openvswitch action
struct ofp_action_dl_addr是openflow action

将openflow action赋值给openvswitch action
*/
    ofpact_put_SET_ETH_SRC(out)->mac = a->dl_addr;
    return 0;
}

static enum ofperr
decode_OFPAT_RAW_SET_DL_DST(const struct ofp_action_dl_addr *a,
                            enum ofp_version ofp_version OVS_UNUSED,
                            struct ofpbuf *out)
{
    ofpact_put_SET_ETH_DST(out)->mac = a->dl_addr;
    return 0;
}

static void
encode_SET_ETH_addr(const struct ofpact_mac *mac, enum ofp_version ofp_version,
                    enum ofp_raw_action_type raw, enum mf_field_id field,
                    struct ofpbuf *out)
{
    if (ofp_version < OFP12_VERSION) {
        struct ofp_action_dl_addr *oada;

        oada = ofpact_put_raw(out, ofp_version, raw, 0);
        oada->dl_addr = mac->mac;
    } else {
        put_set_field(out, ofp_version, field, eth_addr_to_uint64(mac->mac));
    }
}

static void
encode_SET_ETH_SRC(const struct ofpact_mac *mac, enum ofp_version ofp_version,
                   struct ofpbuf *out)
{
    encode_SET_ETH_addr(mac, ofp_version, OFPAT_RAW_SET_DL_SRC, MFF_ETH_SRC,
                        out);

}

static void
encode_SET_ETH_DST(const struct ofpact_mac *mac,
                               enum ofp_version ofp_version,
                               struct ofpbuf *out)
{
    encode_SET_ETH_addr(mac, ofp_version, OFPAT_RAW_SET_DL_DST, MFF_ETH_DST,
                        out);

}

static char * OVS_WARN_UNUSED_RESULT
parse_SET_ETH_SRC(char *arg, const struct ofpact_parse_params *pp)
{
/*
ofpact_put_SET_ETH_SRC(out)将struct ofpbuf转换为struct ofpact_mac，是openvswitch action
从字符串解析构造openvswitch action
*/
    return str_to_mac(arg, &ofpact_put_SET_ETH_SRC(pp->ofpacts)->mac);
}

static char * OVS_WARN_UNUSED_RESULT
parse_SET_ETH_DST(char *arg, const struct ofpact_parse_params *pp)
{
    return str_to_mac(arg, &ofpact_put_SET_ETH_DST(pp->ofpacts)->mac);
}

static void
format_SET_ETH_SRC(const struct ofpact_mac *a,
                   const struct ofpact_format_params *fp)
{
/*
struct ofpact_mac是openvswitch action
将openvswitch action转化为string
*/
    ds_put_format(fp->s, "%smod_dl_src:%s"ETH_ADDR_FMT,
                  colors.param, colors.end, ETH_ADDR_ARGS(a->mac));
}

static void
format_SET_ETH_DST(const struct ofpact_mac *a,
                   const struct ofpact_format_params *fp)
{
    ds_put_format(fp->s, "%smod_dl_dst:%s"ETH_ADDR_FMT,
                  colors.param, colors.end, ETH_ADDR_ARGS(a->mac));
}

static enum ofperr
check_SET_ETH_SRC(const struct ofpact_mac *a OVS_UNUSED,
                  const struct ofpact_check_params *cp OVS_UNUSED)
{
    return 0;
}

static enum ofperr
check_SET_ETH_DST(const struct ofpact_mac *a OVS_UNUSED,
                  const struct ofpact_check_params *cp OVS_UNUSED)
{
    return 0;
}

/* Set gtp pgw eth actions. */
static enum ofperr
decode_OFPAT_RAW10_GTP_PGW_ETH(const struct ofp_action_dl_addr *a,
                              enum ofp_version ofp_version OVS_UNUSED,
                              struct ofpbuf *out)
{
    ofpact_put_GTP_PGW_ETH(out)->mac = a->dl_addr;
    return 0;
}

static enum ofperr
decode_OFPAT_RAW11_GTP_PGW_ETH(const struct ofp_action_dl_addr *a,
                              enum ofp_version ofp_version OVS_UNUSED,
                              struct ofpbuf *out)
{
    ofpact_put_GTP_PGW_ETH(out)->mac = a->dl_addr;
    return 0;
}

static enum ofperr
decode_OFPAT_RAW12_GTP_PGW_ETH(const struct ofp_action_dl_addr *a,
                              enum ofp_version ofp_version OVS_UNUSED,
                              struct ofpbuf *out)
{
    ofpact_put_GTP_PGW_ETH(out)->mac = a->dl_addr;
    return 0;
}

static void
encode_GTP_PGW_ETH(const struct ofpact_mac *mac,
                  enum ofp_version ofp_version, struct ofpbuf *out)
{
/*
put_OFPAT10_GTP_PGW_ETH(out)将struct ofpbuf转换为struct ofp_action_dl_addr，是openflow action
struct ofpact_mac是openvswitch action

将openvswitch action赋值给openflow action
*/
    if (ofp_version == OFP10_VERSION) {
        put_OFPAT10_GTP_PGW_ETH(out)->dl_addr = mac->mac;
    } else if (ofp_version == OFP11_VERSION) {
        put_OFPAT11_GTP_PGW_ETH(out)->dl_addr = mac->mac;
    } else {
        put_OFPAT12_GTP_PGW_ETH(out)->dl_addr = mac->mac;
    }
}

static char * OVS_WARN_UNUSED_RESULT
parse_GTP_PGW_ETH(char *arg, struct ofpbuf *ofpacts,
                  enum ofputil_protocol *usable_protocols OVS_UNUSED)
{
    struct eth_addr gtp_pgw_eth;
    char *error;

    error = str_to_mac(arg, &gtp_pgw_eth);
    if (error) {
        return error;
    }

    ofpact_put_GTP_PGW_ETH(ofpacts)->mac = gtp_pgw_eth;
    return NULL;
}

static void
format_GTP_PGW_ETH(const struct ofpact_mac *a, struct ds *s)
{
    ds_put_format(s, "gtp_pgw_eth:"ETH_ADDR_FMT, ETH_ADDR_ARGS(a->mac));
}

因为这里我们涉及key value的action，所以我们还需要参考learn的函数

actions=learn(dl_type=0x800, nw_proto=17, udp_dst=udp_src)
idle_timeout=seconds
hard_timeout=seconds
priority=value
cookie=value


static enum ofperr
decode_NXAST_RAW_LEARN(const struct nx_action_learn *nal,
                       enum ofp_version ofp_version OVS_UNUSED,
                       const struct vl_mff_map *vl_mff_map,
                       uint64_t *tlv_bitmap, struct ofpbuf *ofpacts)
{
    struct ofpact_learn *learn;
    enum ofperr error;

    learn = ofpact_put_LEARN(ofpacts);

    error = decode_LEARN_common(nal, NXAST_RAW_LEARN, learn);
    if (error) {
        return error;
    }

    if (learn->flags & ~(NX_LEARN_F_SEND_FLOW_REM |
                         NX_LEARN_F_DELETE_LEARNED)) {
        return OFPERR_OFPBAC_BAD_ARGUMENT;
    }

    return decode_LEARN_specs(nal + 1, (char *) nal + ntohs(nal->len),
                              vl_mff_map, tlv_bitmap, ofpacts);
}

static void
encode_LEARN(const struct ofpact_learn *learn,
             enum ofp_version ofp_version OVS_UNUSED, struct ofpbuf *out)
{
    const struct ofpact_learn_spec *spec;
    struct nx_action_learn *nal;
    size_t start_ofs;

    start_ofs = out->size;

    if (learn->ofpact.raw == NXAST_RAW_LEARN2
        || learn->limit != 0
        || learn->flags & NX_LEARN_F_WRITE_RESULT) {
        struct nx_action_learn2 *nal2;

        nal2 = put_NXAST_LEARN2(out);
        nal2->limit = htonl(learn->limit);
        nal2->result_dst_ofs = htons(learn->result_dst.ofs);
        nal = &nal2->up;
    } else {
        nal = put_NXAST_LEARN(out);
    }
    nal->idle_timeout = htons(learn->idle_timeout);
    nal->hard_timeout = htons(learn->hard_timeout);
    nal->fin_idle_timeout = htons(learn->fin_idle_timeout);
    nal->fin_hard_timeout = htons(learn->fin_hard_timeout);
    nal->priority = htons(learn->priority);
    nal->cookie = learn->cookie;
    nal->flags = htons(learn->flags);
    nal->table_id = learn->table_id;

    if (learn->flags & NX_LEARN_F_WRITE_RESULT) {
        nx_put_header(out, learn->result_dst.field->id, 0, false);
    }

    OFPACT_LEARN_SPEC_FOR_EACH (spec, learn) {
        put_u16(out, spec->n_bits | spec->dst_type | spec->src_type);

        if (spec->src_type == NX_LEARN_SRC_FIELD) {
            put_u32(out, nxm_header_from_mff(spec->src.field));
            put_u16(out, spec->src.ofs);
        } else {
            size_t n_dst_bytes = 2 * DIV_ROUND_UP(spec->n_bits, 16);
            uint8_t *bits = ofpbuf_put_zeros(out, n_dst_bytes);
            unsigned int n_bytes = DIV_ROUND_UP(spec->n_bits, 8);

            memcpy(bits + n_dst_bytes - n_bytes, ofpact_learn_spec_imm(spec),
                   n_bytes);
        }

        if (spec->dst_type == NX_LEARN_DST_MATCH ||
            spec->dst_type == NX_LEARN_DST_LOAD) {
            put_u32(out, nxm_header_from_mff(spec->dst.field));
            put_u16(out, spec->dst.ofs);
        }
    }

    pad_ofpat(out, start_ofs);
}

static char * OVS_WARN_UNUSED_RESULT
parse_LEARN(char *arg, const struct ofpact_parse_params *pp)
{
    return learn_parse(arg, pp->port_map, pp->table_map, pp->ofpacts);
}

static void
format_LEARN(const struct ofpact_learn *a,
             const struct ofpact_format_params *fp)
{
    learn_format(a, fp->port_map, fp->table_map, fp->s);
}

char * OVS_WARN_UNUSED_RESULT
learn_parse(char *arg, const struct ofputil_port_map *port_map,
            const struct ofputil_table_map *table_map,
            struct ofpbuf *ofpacts)
{
    char *orig = xstrdup(arg);
    char *error = learn_parse__(orig, arg, port_map, table_map, ofpacts);
    free(orig);
    return error;
}

static char * OVS_WARN_UNUSED_RESULT
learn_parse__(char *orig, char *arg, const struct ofputil_port_map *port_map,
              const struct ofputil_table_map *table_map,
              struct ofpbuf *ofpacts)
{
    struct ofpact_learn *learn;
    struct match match;
    char *name, *value;

    learn = ofpact_put_LEARN(ofpacts);
    learn->idle_timeout = OFP_FLOW_PERMANENT;
    learn->hard_timeout = OFP_FLOW_PERMANENT;
    learn->priority = OFP_DEFAULT_PRIORITY;
    learn->table_id = 1;

    match_init_catchall(&match);
    while (ofputil_parse_key_value(&arg, &name, &value)) {
        if (!strcmp(name, "table")) {
            if (!ofputil_table_from_string(value, table_map,
                                           &learn->table_id)) {
                return xasprintf("unknown table \"%s\"", value);
            } else if (learn->table_id == 255) {
                return xasprintf("%s: table id 255 not valid for `learn' "
                                 "action", orig);
            }
        } else if (!strcmp(name, "priority")) {
            learn->priority = atoi(value);
        } else if (!strcmp(name, "idle_timeout")) {
            learn->idle_timeout = atoi(value);
        } else if (!strcmp(name, "hard_timeout")) {
            learn->hard_timeout = atoi(value);
        } else if (!strcmp(name, "fin_idle_timeout")) {
            learn->fin_idle_timeout = atoi(value);
        } else if (!strcmp(name, "fin_hard_timeout")) {
            learn->fin_hard_timeout = atoi(value);
        } else if (!strcmp(name, "cookie")) {
            learn->cookie = htonll(strtoull(value, NULL, 0));
        } else if (!strcmp(name, "send_flow_rem")) {
            learn->flags |= NX_LEARN_F_SEND_FLOW_REM;
        } else if (!strcmp(name, "delete_learned")) {
            learn->flags |= NX_LEARN_F_DELETE_LEARNED;
        } else if (!strcmp(name, "limit")) {
            learn->limit = atoi(value);
        } else if (!strcmp(name, "result_dst")) {
            char *error;
            learn->flags |= NX_LEARN_F_WRITE_RESULT;
            error = mf_parse_subfield(&learn->result_dst, value);
            if (error) {
                return error;
            }
            if (!learn->result_dst.field->writable) {
                return xasprintf("%s is read-only", value);
            }
            if (learn->result_dst.n_bits != 1) {
                return xasprintf("result_dst in 'learn' action must be a "
                                 "single bit");
            }
        } else {
            struct ofpact_learn_spec *spec;
            char *error;

            spec = ofpbuf_put_zeros(ofpacts, sizeof *spec);
            error = learn_parse_spec(orig, name, value, port_map,
                                     spec, ofpacts, &match);
            if (error) {
                return error;
            }
            learn = ofpacts->header;
        }
    }

    if (ofpbuf_oversized(ofpacts)) {
        return xasprintf("input too big");
    }

    ofpact_finish_LEARN(ofpacts, &learn);

    return NULL;
}

static void
format_LEARN(const struct ofpact_learn *a,
             const struct ofpact_format_params *fp)
{
    learn_format(a, fp->port_map, fp->table_map, fp->s);
}

void
learn_format(const struct ofpact_learn *learn,
             const struct ofputil_port_map *port_map,
             const struct ofputil_table_map *table_map,
             struct ds *s)
{
    const struct ofpact_learn_spec *spec;
    struct match match;

    match_init_catchall(&match);

    ds_put_format(s, "%slearn(%s%stable=%s",
                  colors.learn, colors.end, colors.special, colors.end);
    ofputil_format_table(learn->table_id, table_map, s);
    if (learn->idle_timeout != OFP_FLOW_PERMANENT) {
        ds_put_format(s, ",%sidle_timeout=%s%"PRIu16,
                      colors.param, colors.end, learn->idle_timeout);
    }
    if (learn->hard_timeout != OFP_FLOW_PERMANENT) {
        ds_put_format(s, ",%shard_timeout=%s%"PRIu16,
                      colors.param, colors.end, learn->hard_timeout);
    }
    if (learn->fin_idle_timeout) {
        ds_put_format(s, ",%sfin_idle_timeout=%s%"PRIu16,
                      colors.param, colors.end, learn->fin_idle_timeout);
    }
    if (learn->fin_hard_timeout) {
        ds_put_format(s, "%s,fin_hard_timeout=%s%"PRIu16,
                      colors.param, colors.end, learn->fin_hard_timeout);
    }
    if (learn->priority != OFP_DEFAULT_PRIORITY) {
        ds_put_format(s, "%s,priority=%s%"PRIu16,
                      colors.special, colors.end, learn->priority);
    }
    if (learn->flags & NX_LEARN_F_SEND_FLOW_REM) {
        ds_put_format(s, ",%ssend_flow_rem%s", colors.value, colors.end);
    }
    if (learn->flags & NX_LEARN_F_DELETE_LEARNED) {
        ds_put_format(s, ",%sdelete_learned%s", colors.value, colors.end);
    }
    if (learn->cookie != 0) {
        ds_put_format(s, ",%scookie=%s%#"PRIx64,
                      colors.param, colors.end, ntohll(learn->cookie));
    }
    if (learn->limit != 0) {
        ds_put_format(s, ",%slimit=%s%"PRIu32,
                      colors.param, colors.end, learn->limit);
    }
    if (learn->flags & NX_LEARN_F_WRITE_RESULT) {
        ds_put_format(s, ",%sresult_dst=%s", colors.param, colors.end);
        mf_format_subfield(&learn->result_dst, s);
    }

    OFPACT_LEARN_SPEC_FOR_EACH (spec, learn) {
        unsigned int n_bytes = DIV_ROUND_UP(spec->n_bits, 8);
        ds_put_char(s, ',');

        switch (spec->src_type | spec->dst_type) {
        case NX_LEARN_SRC_IMMEDIATE | NX_LEARN_DST_MATCH: {
            if (spec->dst.ofs == 0
                && spec->dst.n_bits == spec->dst.field->n_bits) {
                union mf_value value;

                memset(&value, 0, sizeof value);
                memcpy(&value.b[spec->dst.field->n_bytes - n_bytes],
                       ofpact_learn_spec_imm(spec), n_bytes);
                ds_put_format(s, "%s%s=%s", colors.param,
                              spec->dst.field->name, colors.end);
                mf_format(spec->dst.field, &value, NULL, port_map, s);
            } else {
                ds_put_format(s, "%s", colors.param);
                mf_format_subfield(&spec->dst, s);
                ds_put_format(s, "=%s", colors.end);
                ds_put_hex(s, ofpact_learn_spec_imm(spec), n_bytes);
            }
            break;
        }
        case NX_LEARN_SRC_FIELD | NX_LEARN_DST_MATCH:
            ds_put_format(s, "%s", colors.param);
            mf_format_subfield(&spec->dst, s);
            ds_put_format(s, "%s", colors.end);
            if (spec->src.field != spec->dst.field ||
                spec->src.ofs != spec->dst.ofs) {
                ds_put_format(s, "%s=%s", colors.param, colors.end);
                mf_format_subfield(&spec->src, s);
            }
            break;

        case NX_LEARN_SRC_IMMEDIATE | NX_LEARN_DST_LOAD:
            ds_put_format(s, "%sload:%s", colors.special, colors.end);
            ds_put_hex(s, ofpact_learn_spec_imm(spec), n_bytes);
            ds_put_format(s, "%s->%s", colors.special, colors.end);
            mf_format_subfield(&spec->dst, s);
            break;

        case NX_LEARN_SRC_FIELD | NX_LEARN_DST_LOAD:
            ds_put_format(s, "%sload:%s", colors.special, colors.end);
            mf_format_subfield(&spec->src, s);
            ds_put_format(s, "%s->%s", colors.special, colors.end);
            mf_format_subfield(&spec->dst, s);
            break;

        case NX_LEARN_SRC_FIELD | NX_LEARN_DST_OUTPUT:
            ds_put_format(s, "%soutput:%s", colors.special, colors.end);
            mf_format_subfield(&spec->src, s);
            break;
        }
    }
    ds_put_format(s, "%s)%s", colors.learn, colors.end);
}

s表示短、l表示长；
ntohs =net to host short int 16位
htons=host to net short int 16位
ntohl =net to host long int 32位
htonl=host to net long int 32位

我们写 /* OF1.0+(28): struct ofp_action_config_gw. */ OFPAT_RAW_CONFIG_GW 对应的decode, encode, parse, format

static enum ofperr
decode_OFPAT_RAW_CONFIG_GW(const struct ofp_action_config_gw *a,
                            enum ofp_version ofp_version OVS_UNUSED,
                            struct ofpbuf *out)
{
    struct ofpact_config_gw *config_gw;

    config_gw = ofpact_put_CONFIG_GW(out);

    //may do ntohs htons ntohl htonl
    config_gw->param1 = a->param1;
    config_gw->param2 = a->param2;
    config_gw->param3 = a->param3;
    config_gw->param4 = a->param4;
    config_gw->param5 = a->param5;
    config_gw->param6 = a->param6;
    config_gw->param7 = a->param7;
    config_gw->param8 = a->param8;
    config_gw->param9 = a->param9;
}


static void
encode_CONFIG_GW(const struct ofpact_config_gw *config_gw,
                  enum ofp_version ofp_version, struct ofpbuf *out)
{

    struct ofp_action_config_gw *ofp_config_gw;

    ofp_config_gw = put_OFPAT_CONFIG_GW(out);

    //may do ntohs htons ntohl htonl
    ofp_config_gw->param1 = config_gw->param1;
    ofp_config_gw->param2 = config_gw->param2;
    ofp_config_gw->param3 = config_gw->param3;
    ofp_config_gw->param4 = config_gw->param4;
    ofp_config_gw->param5 = config_gw->param5;
    ofp_config_gw->param6 = config_gw->param6;
    ofp_config_gw->param7 = config_gw->param7;
    ofp_config_gw->param8 = config_gw->param8;
    ofp_config_gw->param9 = config_gw->param9;
}

static char * OVS_WARN_UNUSED_RESULT
parse_CONFIG_GW(const char *arg, const struct ofpact_parse_params *pp)
{
    struct ofpbuf *ofpacts;
    struct ofpact_config_gw *config_gw;
    char *name, *value;
    struct eth_addr ethaddr;
    char *error;

    ofpacts = pp->ofpacts;
    config_gw = ofpact_put_CONFIG_GW(ofpacts);

    while (ofputil_parse_key_value(&arg, &name, &value)) {
        if (!strcmp(name, "param1")) {
            config_gw->param1 = atoi(value);
        } else if (!strcmp(name, "param2")) {
            config_gw->param2 = atoi(value);
        } else if (!strcmp(name, "param3")) {
            error = str_to_mac(value, &ethaddr);
            if (error) {
                return error;
            }
            config_gw->param3 = ethaddr;
        } else if (!strcmp(name, "param4")) {
            config_gw->param4 = atoi(value);
        } else if (!strcmp(name, "param5")) {
            config_gw->param5 = atoi(value);
        } else if (!strcmp(name, "param6")) {
            error = str_to_mac(value, &ethaddr);
            if (error) {
                return error;
            }
            config_gw->param6 = ethaddr;
        } else if (!strcmp(name, "param7")) {
            config_gw->param7 = atoi(value);
        } else if (!strcmp(name, "param8")) {
            config_gw->param8 = atoi(value);
        } else if (!strcmp(name, "param9")) {
            error = str_to_mac(value, &ethaddr);
            if (error) {
                return error;
            }
            config_gw->param9 = ethaddr;
        } 
    }

    return NULL;
}

static void
format_CONFIG_GW(const struct ofpact_config_gw *a, const struct ofpact_format_params *fp)
{
    struct ds *s;

    s = fp->s;

    ds_put_format(s, "config_gw(");
    if (a->param1 != 0) {
        ds_put_format(s, "param1=%"PRIu32, a->param1);
    }
    if (a->param2 != 0) {
        ds_put_format(s, ",param2=%"PRIx32, ntohl(a->param2));
    }
    if (a->param3 != 0) {
        ds_put_format(s, ",param3=%"ETH_ADDR_FMT, ETH_ADDR_ARGS(a->param3));
    }
    if (a->param4 != 0) {
        ds_put_format(s, "param1=%"PRIu32, a->param1);
    }
    if (a->param5 != 0) {
        ds_put_format(s, ",param2=%"PRIx32, ntohl(a->param2));
    }
    if (a->param6 != 0) {
        ds_put_format(s, ",param3=%"ETH_ADDR_FMT, ETH_ADDR_ARGS(a->param3));
    }
    if (a->param7 != 0) {
        ds_put_format(s, "param1=%"PRIu32, a->param1);
    }
    if (a->param8 != 0) {
        ds_put_format(s, ",param2=%"PRIx32, ntohl(a->param2));
    }
    if (a->param9 != 0) {
        ds_put_format(s, ",param3=%"ETH_ADDR_FMT, ETH_ADDR_ARGS(a->param3));
    }

    ds_put_format(s, ")");
}


////////////////////4. action实现，模式一，内核模式datapath

datapath\linux\compat\include\linux\openvswitch.h

enum ovs_action_attr {
    OVS_ACTION_ATTR_UNSPEC,
    OVS_ACTION_ATTR_OUTPUT,       /* u32 port number. */
    OVS_ACTION_ATTR_USERSPACE,    /* Nested OVS_USERSPACE_ATTR_*. */
    OVS_ACTION_ATTR_SET,          /* One nested OVS_KEY_ATTR_*. */
    OVS_ACTION_ATTR_PUSH_VLAN,    /* struct ovs_action_push_vlan. */
    OVS_ACTION_ATTR_POP_VLAN,     /* No argument. */
    OVS_ACTION_ATTR_SAMPLE,       /* Nested OVS_SAMPLE_ATTR_*. */
    OVS_ACTION_ATTR_RECIRC,       /* u32 recirc_id. */
    OVS_ACTION_ATTR_HASH,         /* struct ovs_action_hash. */
    OVS_ACTION_ATTR_PUSH_MPLS,    /* struct ovs_action_push_mpls. */
    OVS_ACTION_ATTR_POP_MPLS,     /* __be16 ethertype. */
    OVS_ACTION_ATTR_SET_MASKED,   /* One nested OVS_KEY_ATTR_* including
                       * data immediately followed by a mask.
                       * The data must be zero for the unmasked
                       * bits. */
    OVS_ACTION_ATTR_CT,           /* Nested OVS_CT_ATTR_* . */
    OVS_ACTION_ATTR_TRUNC,        /* u32 struct ovs_action_trunc. */
    OVS_ACTION_ATTR_PUSH_ETH,     /* struct ovs_action_push_eth. */
    OVS_ACTION_ATTR_POP_ETH,      /* No argument. */
    OVS_ACTION_ATTR_CT_CLEAR,     /* No argument. */
    OVS_ACTION_ATTR_PUSH_NSH,     /* Nested OVS_NSH_KEY_ATTR_*. */
    OVS_ACTION_ATTR_POP_NSH,      /* No argument. */
    OVS_ACTION_ATTR_METER,        /* u32 meter number. */
    OVS_ACTION_ATTR_CLONE,        /* Nested OVS_CLONE_ATTR_*.  */
    OVS_ACTION_ATTR_CHECK_PKT_LEN, /* Nested OVS_CHECK_PKT_LEN_ATTR_*. */

#ifndef __KERNEL__
    OVS_ACTION_ATTR_TUNNEL_PUSH,   /* struct ovs_action_push_tnl*/
    OVS_ACTION_ATTR_TUNNEL_POP,    /* u32 port number. */
    OVS_ACTION_ATTR_DROP,          /* u32 xlate_error. */
    OVS_ACTION_ATTR_LB_OUTPUT,     /* u32 bond-id. */
#endif
    __OVS_ACTION_ATTR_MAX,        /* Nothing past this will be accepted
                       * from userspace. */

#ifdef __KERNEL__
    OVS_ACTION_ATTR_SET_TO_MASKED, /* Kernel module internal masked
                    * set action converted from
                    * OVS_ACTION_ATTR_SET. */
#endif
};

定义内核中的action

在datapath/linux/compat/include/linux/openvswitch.h:中添加：

enum ovs_action_attr {
    /* ... */

    /*
    * after #ifndef __KERNEL__ ... #endif.
    * the equals is thus ABSOLUTELY NECESSARY
    */

    OVS_ACTION_ATTR_PROBDROP = 23, /* unit32_t, prob in [0,2^32 -1] */

    __OVS_ACTION_ATTR_MAX, /* Nothing past this will be accepted
                            * from userspace. */

    /* ... */

}

OVS_ACTION_ATTR_PROBDROP = 23 如果我们不为该枚举条目指定显式值，则内核和用户区部分 ovs-vswitchd将对新操作使用不同的代码（这里不加会出错）

在内核模块中实现action函数，并调用执行，datapath/actions.c

/* Ask for a random number.
   "p" is the amount we should let through, here true means drop,
   false means let it pass on */
static bool prob_drop(uint32_t prob)
{
    /* since we can't use rand() in the kernel */
    return prandom_u32() > prob;　　
}

static int do_execute_actions(/* ... */)
{
    /* ... */
    switch (nla_type(a)) {
    /* ... */
    case OVS_ACTION_ATTR_PROBDROP:
        /* No need to free, taken care of for us
           This function just reads the attribute to
           know if we should drop. */
        if(prob_drop(nla_get_u32(a)))
        {
            while (rem) {
                a = nla_next(a, &rem);
            }
        }
        break;
    }
    /* ... */
}


/* Execute a list of actions against 'skb'. */
static int do_execute_actions(struct datapath *dp, struct sk_buff *skb,
                  struct sw_flow_key *key,
                  const struct nlattr *attr, int len)
{
    const struct nlattr *a;
    int rem;

    for (a = attr, rem = len; rem > 0;
         a = nla_next(a, &rem)) {
        int err = 0;

        switch (nla_type(a)) {
        case OVS_ACTION_ATTR_OUTPUT: {
            int port = nla_get_u32(a);
            struct sk_buff *clone;

            /* Every output action needs a separate clone
             * of 'skb', In case the output action is the
             * last action, cloning can be avoided.
             */
            if (nla_is_last(a, rem)) {
                do_output(dp, skb, port, key);
                /* 'skb' has been used for output.
                 */
                return 0;
            }

            clone = skb_clone(skb, GFP_ATOMIC);
            if (clone)
                do_output(dp, clone, port, key);
            OVS_CB(skb)->cutlen = 0;
            break;
        }

        case OVS_ACTION_ATTR_TRUNC: {
            struct ovs_action_trunc *trunc = nla_data(a);

            if (skb->len > trunc->max_len)
                OVS_CB(skb)->cutlen = skb->len - trunc->max_len;
            break;
        }

        case OVS_ACTION_ATTR_USERSPACE:
            output_userspace(dp, skb, key, a, attr,
                             len, OVS_CB(skb)->cutlen);
            OVS_CB(skb)->cutlen = 0;
            break;

        case OVS_ACTION_ATTR_HASH:
            execute_hash(skb, key, a);
            break;

        case OVS_ACTION_ATTR_PUSH_MPLS:
            err = push_mpls(skb, key, nla_data(a));
            break;

        case OVS_ACTION_ATTR_POP_MPLS:
            err = pop_mpls(skb, key, nla_get_be16(a));
            break;

        case OVS_ACTION_ATTR_PUSH_VLAN:
            err = push_vlan(skb, key, nla_data(a));
            break;

        case OVS_ACTION_ATTR_POP_VLAN:
            err = pop_vlan(skb, key);
            break;

        case OVS_ACTION_ATTR_RECIRC: {
            bool last = nla_is_last(a, rem);

            err = execute_recirc(dp, skb, key, a, last);
            if (last) {
                /* If this is the last action, the skb has
                 * been consumed or freed.
                 * Return immediately.
                 */
                return err;
            }
            break;
        }

        case OVS_ACTION_ATTR_SET:
            err = execute_set_action(skb, key, nla_data(a));
            break;

        case OVS_ACTION_ATTR_SET_MASKED:
        case OVS_ACTION_ATTR_SET_TO_MASKED:
            err = execute_masked_set_action(skb, key, nla_data(a));
            break;

        case OVS_ACTION_ATTR_SAMPLE: {
            bool last = nla_is_last(a, rem);

            err = sample(dp, skb, key, a, last);
            if (last)
                return err;

            break;
        }

        case OVS_ACTION_ATTR_CT:
            if (!is_flow_key_valid(key)) {
                err = ovs_flow_key_update(skb, key);
                if (err)
                    return err;
            }

            err = ovs_ct_execute(ovs_dp_get_net(dp), skb, key,
                         nla_data(a));

            /* Hide stolen IP fragments from user space. */
            if (err)
                return err == -EINPROGRESS ? 0 : err;
            break;

        case OVS_ACTION_ATTR_CT_CLEAR:
            err = ovs_ct_clear(skb, key);
            break;

        case OVS_ACTION_ATTR_PUSH_ETH:
            err = push_eth(skb, key, nla_data(a));
            break;

        case OVS_ACTION_ATTR_POP_ETH:
            err = pop_eth(skb, key);
            break;

        case OVS_ACTION_ATTR_PUSH_NSH: {
            u8 buffer[NSH_HDR_MAX_LEN];
            struct nshhdr *nh = (struct nshhdr *)buffer;

            err = nsh_hdr_from_nlattr(nla_data(a), nh,
                          NSH_HDR_MAX_LEN);
            if (unlikely(err))
                break;
            err = push_nsh(skb, key, nh);
            break;
        }

        case OVS_ACTION_ATTR_POP_NSH:
            err = pop_nsh(skb, key);
            break;

        case OVS_ACTION_ATTR_METER:
            if (ovs_meter_execute(dp, skb, key, nla_get_u32(a))) {
                consume_skb(skb);
                return 0;
            }
                       break;

        case OVS_ACTION_ATTR_CLONE: {
            bool last = nla_is_last(a, rem);

            err = clone(dp, skb, key, a, last);
            if (last)
                return err;
            break;
        }

        case OVS_ACTION_ATTR_CHECK_PKT_LEN: {
                        bool last = nla_is_last(a, rem);

                        err = execute_check_pkt_len(dp, skb, key, a, last);
                        if (last)
                                return err;

                        break;
                }
        }

        if (unlikely(err)) {
            kfree_skb(skb);
            return err;
        }
    }

/*
#ifndef HAVE_CONSUME_SKB
#define consume_skb kfree_skb
#endif
*/
    consume_skb(skb);
    return 0;
}

////////////////////5. action实现，模式二，DPDK模式

lib/packets.h：

/* ... */

bool prob_drop(uint32_t prob);

#endif /* packets.h */

lib/packets.c:

/* Ask for a random number.
   "p" is the amount we should let through, here true means drop,
   false means let it pass on */
bool
prob_drop(uint32_t prob)
{
    unsigned int roll_i;
    random_bytes(&roll_i, sizeof(roll_i));
    return roll_i > prob;
}

lib/dpif-netdev.c:

static void
dp_execute_cb( /* ... */ )
{
    /* ... */
    switch ((enum ovs_action_attr)type) {
    /* ... */
    case OVS_ACTION_ATTR_PROBDROP:
        OVS_NOT_REACHED();
    }
}

static bool
requires_datapath_assistance(const struct nlattr *a)
{
    enum ovs_action_attr type = nl_attr_type(a);

    switch (type) {
    /* ... */
    case OVS_ACTION_ATTR_PROBDROP:
        return false;
    /* ... */
    }
}

odp_execute_actions(&aux, packets, should_steal, actions,
                        actions_len, dp_execute_cb);
在这个函数里面，只有requires_datapath_assistance为true，才会调用dp_execute_cb

lib/odp-execute.c

void
odp_execute_actions( /* ... */ )
{
    /* ... */
    switch ((enum ovs_action_attr)type) {
    /* ... */
    case OVS_ACTION_ATTR_PROBDROP: {　　　　
        size_t i;
        const size_t num = dp_packet_batch_size(batch);

        DP_PACKET_BATCH_REFILL_FOR_EACH (i, num, packet, batch) {
            if (!prob_drop(nl_attr_get_u32(a))) {
                dp_packet_batch_refill(batch, packet, i);
            } else {
                dp_packet_delete(packet);
            }
        }
        break;
    }

    }
}


lib/dpif.c:

static void
dpif_execute_helper_cb( /* ... */ )
{
    /* ... */
    switch ((enum ovs_action_attr)type) {
    /* ... */
    case OVS_ACTION_ATTR_PROBDROP:
        OVS_NOT_REACHED();
    }
}

ofproto/ofproto-dpif-ipfix.c:

void
dpif_ipfix_read_actions( /* ... */ )
{
    /* ... */
    switch (type) {
    /* ... */
    case OVS_ACTION_ATTR_PROBDROP:
        /* Again, ignore for now. Not needed. */
        break;
    }
}

ofproto/ofproto-dpif-sflow.c:

void
dpif_sflow_read_actions( /* ... */ )
{
    switch (type) {
    /* ... */
    case OVS_ACTION_ATTR_PROBDROP:
        /* Ignore sFlow for now, unless needed. */
        break;
    }
}

/* Executes all of the 'actions_len' bytes of datapath actions in 'actions' on
 * the packets in 'batch'.  If 'steal' is true, possibly modifies and
 * definitely free the packets in 'batch', otherwise leaves 'batch' unchanged.
 *
 * Some actions (e.g. output actions) can only be executed by a datapath.  This
 * function implements those actions by passing the action and the packets to
 * 'dp_execute_action' (along with 'dp').  If 'dp_execute_action' is passed a
 * true 'steal' parameter then it must definitely free the packets passed into
 * it.  The packet can be modified whether 'steal' is false or true.  If a
 * packet is removed from the batch, then the fate of the packet is determined
 * by the code that does this removal, irrespective of the value of 'steal'.
 * Otherwise, if the packet is not removed from the batch and 'steal' is false
 * then the packet could either be cloned or not. */
void
odp_execute_actions(void *dp, struct dp_packet_batch *batch, bool steal,
                    const struct nlattr *actions, size_t actions_len,
                    odp_execute_cb dp_execute_action)
{
    struct dp_packet *packet;
    const struct nlattr *a;
    unsigned int left;

    NL_ATTR_FOR_EACH_UNSAFE (a, left, actions, actions_len) {
        int type = nl_attr_type(a);
        bool last_action = (left <= NLA_ALIGN(a->nla_len));

        if (requires_datapath_assistance(a)) {
            if (dp_execute_action) {
                /* Allow 'dp_execute_action' to steal the packet data if we do
                 * not need it any more. */
                bool should_steal = steal && last_action;

                dp_execute_action(dp, batch, a, should_steal);

                if (last_action || dp_packet_batch_is_empty(batch)) {
                    /* We do not need to free the packets.
                     * Either dp_execute_actions() has stolen them
                     * or the batch is freed due to errors. In either
                     * case we do not need to execute further actions.
                     */
                    return;
                }
            }
            continue;
        }

        switch ((enum ovs_action_attr) type) {

        case OVS_ACTION_ATTR_HASH: {
            const struct ovs_action_hash *hash_act = nl_attr_get(a);

            /* Calculate a hash value directly. This might not match the
             * value computed by the datapath, but it is much less expensive,
             * and the current use case (bonding) does not require a strict
             * match to work properly. */
            switch (hash_act->hash_alg) {
            case OVS_HASH_ALG_L4: {
                struct flow flow;
                uint32_t hash;

                DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                    /* RSS hash can be used here instead of 5tuple for
                     * performance reasons. */
                    if (dp_packet_rss_valid(packet)) {
                        hash = dp_packet_get_rss_hash(packet);
                        hash = hash_int(hash, hash_act->hash_basis);
                    } else {
                        flow_extract(packet, &flow);
                        hash = flow_hash_5tuple(&flow, hash_act->hash_basis);
                    }
                    packet->md.dp_hash = hash;
                }
                break;
            }
            case OVS_HASH_ALG_SYM_L4: {
                struct flow flow;
                uint32_t hash;

                DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                    flow_extract(packet, &flow);
                    hash = flow_hash_symmetric_l3l4(&flow,
                                                    hash_act->hash_basis,
                                                    false);
                    packet->md.dp_hash = hash;
                }
                break;
            }
            default:
                /* Assert on unknown hash algorithm.  */
                OVS_NOT_REACHED();
            }
            break;
        }

        case OVS_ACTION_ATTR_PUSH_VLAN: {
            const struct ovs_action_push_vlan *vlan = nl_attr_get(a);

            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                eth_push_vlan(packet, vlan->vlan_tpid, vlan->vlan_tci);
            }
            break;
        }

        case OVS_ACTION_ATTR_POP_VLAN:
            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                eth_pop_vlan(packet);
            }
            break;

        case OVS_ACTION_ATTR_PUSH_MPLS: {
            const struct ovs_action_push_mpls *mpls = nl_attr_get(a);

            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                push_mpls(packet, mpls->mpls_ethertype, mpls->mpls_lse);
            }
            break;
         }

        case OVS_ACTION_ATTR_POP_MPLS:
            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                pop_mpls(packet, nl_attr_get_be16(a));
            }
            break;

        case OVS_ACTION_ATTR_SET:
            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                odp_execute_set_action(packet, nl_attr_get(a));
            }
            break;

        case OVS_ACTION_ATTR_SET_MASKED:
            DP_PACKET_BATCH_FOR_EACH(i, packet, batch) {
                odp_execute_masked_set_action(packet, nl_attr_get(a));
            }
            break;

        case OVS_ACTION_ATTR_SAMPLE:
            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                odp_execute_sample(dp, packet, steal && last_action, a,
                                   dp_execute_action);
            }

            if (last_action) {
                /* We do not need to free the packets. odp_execute_sample() has
                 * stolen them*/
                return;
            }
            break;

        case OVS_ACTION_ATTR_TRUNC: {
            const struct ovs_action_trunc *trunc =
                        nl_attr_get_unspec(a, sizeof *trunc);

            batch->trunc = true;
            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                dp_packet_set_cutlen(packet, trunc->max_len);
            }
            break;
        }

        case OVS_ACTION_ATTR_CLONE:
            odp_execute_clone(dp, batch, steal && last_action, a,
                                                dp_execute_action);
            if (last_action) {
                /* We do not need to free the packets. odp_execute_clone() has
                 * stolen them.  */
                return;
            }
            break;
        case OVS_ACTION_ATTR_METER:
            /* Not implemented yet. */
            break;
        case OVS_ACTION_ATTR_PUSH_ETH: {
            const struct ovs_action_push_eth *eth = nl_attr_get(a);

            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                push_eth(packet, &eth->addresses.eth_dst,
                         &eth->addresses.eth_src);
            }
            break;
        }

        case OVS_ACTION_ATTR_POP_ETH:
            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                pop_eth(packet);
            }
            break;

        case OVS_ACTION_ATTR_PUSH_NSH: {
            uint32_t buffer[NSH_HDR_MAX_LEN / 4];
            struct nsh_hdr *nsh_hdr = ALIGNED_CAST(struct nsh_hdr *, buffer);
            nsh_reset_ver_flags_ttl_len(nsh_hdr);
            odp_nsh_hdr_from_attr(nl_attr_get(a), nsh_hdr, NSH_HDR_MAX_LEN);
            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                push_nsh(packet, nsh_hdr);
            }
            break;
        }
        case OVS_ACTION_ATTR_POP_NSH: {
            size_t i;
            const size_t num = dp_packet_batch_size(batch);

            DP_PACKET_BATCH_REFILL_FOR_EACH (i, num, packet, batch) {
                if (pop_nsh(packet)) {
                    dp_packet_batch_refill(batch, packet, i);
                } else {
                    COVERAGE_INC(datapath_drop_nsh_decap_error);
                    dp_packet_delete(packet);
                }
            }
            break;
        }
        case OVS_ACTION_ATTR_CT_CLEAR:
            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                conntrack_clear(packet);
            }
            break;

        case OVS_ACTION_ATTR_CHECK_PKT_LEN:
            DP_PACKET_BATCH_FOR_EACH (i, packet, batch) {
                odp_execute_check_pkt_len(dp, packet, steal && last_action, a,
                                          dp_execute_action);
            }

            if (last_action) {
                /* We do not need to free the packets.
                 * odp_execute_check_pkt_len() has stolen them. */
                return;
            }
            break;

        case OVS_ACTION_ATTR_DROP:{
            const enum xlate_error *drop_reason = nl_attr_get(a);

            dp_update_drop_action_counter(*drop_reason,
                                          dp_packet_batch_size(batch));
            dp_packet_delete_batch(batch, steal);
            return;
        }
        case OVS_ACTION_ATTR_OUTPUT:
        case OVS_ACTION_ATTR_LB_OUTPUT:
        case OVS_ACTION_ATTR_TUNNEL_PUSH:
        case OVS_ACTION_ATTR_TUNNEL_POP:
        case OVS_ACTION_ATTR_USERSPACE:
        case OVS_ACTION_ATTR_RECIRC:
        case OVS_ACTION_ATTR_CT:
        case OVS_ACTION_ATTR_UNSPEC:
        case __OVS_ACTION_ATTR_MAX:
            OVS_NOT_REACHED();
        }
    }

    dp_packet_delete_batch(batch, steal);
}

////////////////////6. fast path处理，到fast path没有匹配上，upcall到慢路径slow path，action处理，以及处理完毕后，将flow放入fast path，的整个流程，内核态模式

netdev_port_receive->ovs_vport_receive->ovs_dp_process_received_packet
->   ovs_flow_extract
   + ovs_flow_tbl_lookup
   + ovs_dp_upcall -> queue_userspace_packet -> genlmsg_unicast (发送消息给用户空间)
   + ovs_execute_actions -> do_execute_actions (快路径执行action)

对于内核态的fast path，如何upcall到show path呢？

ovs_thread_create->udpif_upcall_handler->recv_upcalls(内核态模式处理upcall的核心函数)
->  upcall_receive (无论是内核模式，还是DPDK模式，都先调用upcall_receive，两者的type都是一样的，都是DPIF_UC_MISS(就是MISS_UPCALL)，不同的是，内核PMD是PMD_ID_NULL，而DPDK的PMD有pmd_id)
  + process_upcall (无论是内核模式，还是DPDK模式，都再调用process_upcall查找openflow流表，并对于actions进行转换)
  + handle_upcalls (这里只有内核模式有，安装流表到内核，并在内核执行action)

process_upcall->upcall_xlate->xlate_actions
->rule_dpif_lookup_from_table (到table的分类器中查找流表)
  + do_xlate_actions

xlate_actions函数：openflow流表匹配完成后，调用do_xlate_actions函数把openflow action转化为精确流表的action

/* Translates the flow, actions, or rule in 'xin' into datapath actions in
 * 'xout'.
 * The caller must take responsibility for eventually freeing 'xout', with
 * xlate_out_uninit().
 * Returns 'XLATE_OK' if translation was successful.  In case of an error an
 * empty set of actions will be returned in 'xin->odp_actions' (if non-NULL),
 * so that most callers may ignore the return value and transparently install a
 * drop flow when the translation fails. */
enum xlate_error xlate_actions(struct xlate_in *xin, struct xlate_out *xout)

Translating ofpact action- Kernel datapath  In ofproto-dpif-xlate.c do_xlate_actions nl_msg_put_u16
Eg.
 OpenFlows
table=0, priority=100 in_port=1,ip,actions=check_pkt_larger:1500->NXM_NX_REG0[0],resubmit(,1)
table=1, priority=200,in_port=1,ip,reg0=0x1/0x1 actions=output:3
table=1, priority=100,in_port=1,ip,actions=output:4
Translated to datapath action as:
 check_pkt_len(1500, gt(output:3), less_eq(output:4))

Translating ofpact action- DPDK datapath  in lib/odp-execute.c odp_execute_actions


/* Translates the flow, actions, or rule in 'xin' into datapath actions in
 * 'xout'.
 * The caller must take responsibility for eventually freeing 'xout', with
 * xlate_out_uninit().
 * Returns 'XLATE_OK' if translation was successful.  In case of an error an
 * empty set of actions will be returned in 'xin->odp_actions' (if non-NULL),
 * so that most callers may ignore the return value and transparently install a
 * drop flow when the translation fails. */
enum xlate_error
xlate_actions(struct xlate_in *xin, struct xlate_out *xout)

handle_upcalls 将flow rule添加到内核中的fast path(如果should_install_flow为true，put_op_init里面设置op->dop.type = DPIF_OP_FLOW_PUT)，且在内核执行action(设置op->dop.type = DPIF_OP_EXECUTE) 
-> dpif_operate -> dpif_netlink_operate -> dpif_netlink_operate_chunks -> dpif_netlink_operate__ (case DPIF_OP_FLOW_PUT: dpif_netlink_init_flow_put + dpif_netlink_flow_to_ofpbuf ; case DPIF_OP_EXECUTE: dpif_netlink_encode_execute)
+ nl_transact_multiple(通过netlink发送给内核)

static void
handle_upcalls(struct udpif *udpif, struct upcall *upcalls,
               size_t n_upcalls)
{
    struct dpif_op *opsp[UPCALL_MAX_BATCH * 2];
    struct ukey_op ops[UPCALL_MAX_BATCH * 2];
    size_t n_ops, n_opsp, i;

    /* Handle the packets individually in order of arrival.
     *
     *   - For SLOW_CFM, SLOW_LACP, SLOW_STP, SLOW_BFD, and SLOW_LLDP,
     *     translation is what processes received packets for these
     *     protocols.
     *
     *   - For SLOW_ACTION, translation executes the actions directly.
     *
     * The loop fills 'ops' with an array of operations to execute in the
     * datapath. */
    n_ops = 0;
    for (i = 0; i < n_upcalls; i++) {
        struct upcall *upcall = &upcalls[i];
        const struct dp_packet *packet = upcall->packet;
        struct ukey_op *op;

        if (should_install_flow(udpif, upcall)) {
            struct udpif_key *ukey = upcall->ukey;

            if (ukey_install(udpif, ukey)) {
                upcall->ukey_persists = true;
                put_op_init(&ops[n_ops++], ukey, DPIF_FP_CREATE);
            }
        }

        if (upcall->odp_actions.size) {
            op = &ops[n_ops++];
            op->ukey = NULL;
            op->dop.type = DPIF_OP_EXECUTE;
            op->dop.execute.packet = CONST_CAST(struct dp_packet *, packet);
            op->dop.execute.flow = upcall->flow;
            odp_key_to_dp_packet(upcall->key, upcall->key_len,
                                 op->dop.execute.packet);
            op->dop.execute.actions = upcall->odp_actions.data;
            op->dop.execute.actions_len = upcall->odp_actions.size;
            op->dop.execute.needs_help = (upcall->xout.slow & SLOW_ACTION) != 0;
            op->dop.execute.probe = false;
            op->dop.execute.mtu = upcall->mru;
            op->dop.execute.hash = upcall->hash;
        }
    }

    /* Execute batch. */
    n_opsp = 0;
    for (i = 0; i < n_ops; i++) {
        opsp[n_opsp++] = &ops[i].dop;
    }
    dpif_operate(udpif->dpif, opsp, n_opsp, DPIF_OFFLOAD_AUTO);
    for (i = 0; i < n_ops; i++) {
        struct udpif_key *ukey = ops[i].ukey;

        if (ukey) {
            ovs_mutex_lock(&ukey->mutex);
            if (ops[i].dop.error) {
                transition_ukey(ukey, UKEY_EVICTED);
            } else if (ukey->state < UKEY_OPERATIONAL) {
                transition_ukey(ukey, UKEY_OPERATIONAL);
            }
            ovs_mutex_unlock(&ukey->mutex);
        }
    }
}

dpif_netlink_init_flow_put (struct dpif_netlink_flow *request)
->   request->cmd = (put->flags & DPIF_FP_CREATE
                    ? OVS_FLOW_CMD_NEW : OVS_FLOW_CMD_SET);
   + request->actions = (put->actions
                        ? put->actions
                        : CONST_CAST(struct nlattr *, &dummy_action));

dpif_netlink_flow_to_ofpbuf (struct dpif_netlink_flow *flow) flow就是上面的request
->   nl_msg_put_genlmsghdr(buf, 0, ovs_flow_family,
                          NLM_F_REQUEST | flow->nlmsg_flags,
                          flow->cmd, OVS_FLOW_VERSION);
   + nl_msg_put_unspec(buf, OVS_FLOW_ATTR_ACTIONS,
                              flow->actions, flow->actions_len);

dpif_netlink_encode_execute
->   nl_msg_put_genlmsghdr(buf, 0, ovs_packet_family, NLM_F_REQUEST,
                          OVS_PACKET_CMD_EXECUTE, OVS_PACKET_VERSION);
   + nl_msg_put_unspec(buf, OVS_PACKET_ATTR_PACKET,
                      dp_packet_data(d_exec->packet),
                      dp_packet_size(d_exec->packet));
   + nl_msg_put_unspec(buf, OVS_PACKET_ATTR_ACTIONS,
                      d_exec->actions, d_exec->actions_len);

接下来我们到内核里面datapath\datapath.c

static const struct genl_ops dp_flow_genl_ops[] = {
    { .cmd = OVS_FLOW_CMD_NEW,
#ifdef HAVE_GENL_VALIDATE_FLAGS
      .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,
#endif
      .flags = GENL_UNS_ADMIN_PERM, /* Requires CAP_NET_ADMIN privilege. */
#ifdef HAVE_GENL_OPS_POLICY
      .policy = flow_policy,
#endif
      .doit = ovs_flow_cmd_new -> ovs_flow_tbl_insert(&dp->table, new_flow, &mask)
    },
......
    { .cmd = OVS_FLOW_CMD_SET,
#ifdef HAVE_GENL_VALIDATE_FLAGS
      .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,
#endif
      .flags = GENL_UNS_ADMIN_PERM, /* Requires CAP_NET_ADMIN privilege. */
#ifdef HAVE_GENL_OPS_POLICY
      .policy = flow_policy,
#endif
      .doit = ovs_flow_cmd_set,
    },
};

static struct genl_ops dp_packet_genl_ops[] = {
    { .cmd = OVS_PACKET_CMD_EXECUTE,
#ifdef HAVE_GENL_VALIDATE_FLAGS
      .validate = GENL_DONT_VALIDATE_STRICT | GENL_DONT_VALIDATE_DUMP,
#endif
      .flags = GENL_UNS_ADMIN_PERM, /* Requires CAP_NET_ADMIN privilege. */
#ifdef HAVE_GENL_OPS_POLICY
      .policy = packet_policy,
#endif
      .doit = ovs_packet_cmd_execute
    }
};

static int ovs_packet_cmd_execute(struct sk_buff *skb, struct genl_info *info)
{
    struct ovs_header *ovs_header = info->userhdr;
    struct net *net = sock_net(skb->sk);
    struct nlattr **a = info->attrs;
    struct sw_flow_actions *acts;
    struct sk_buff *packet;
    struct sw_flow *flow;
    struct sw_flow_actions *sf_acts;
    struct datapath *dp;
    struct vport *input_vport;
    u16 mru = 0;
    u64 hash;
    int len;
    int err;
    bool log = !a[OVS_PACKET_ATTR_PROBE];

    err = -EINVAL;
    if (!a[OVS_PACKET_ATTR_PACKET] || !a[OVS_PACKET_ATTR_KEY] ||
        !a[OVS_PACKET_ATTR_ACTIONS])
        goto err;

    len = nla_len(a[OVS_PACKET_ATTR_PACKET]);
    packet = __dev_alloc_skb(NET_IP_ALIGN + len, GFP_KERNEL);
    err = -ENOMEM;
    if (!packet)
        goto err;
    skb_reserve(packet, NET_IP_ALIGN);

    nla_memcpy(__skb_put(packet, len), a[OVS_PACKET_ATTR_PACKET], len);

    /* Set packet's mru */
    if (a[OVS_PACKET_ATTR_MRU]) {
        mru = nla_get_u16(a[OVS_PACKET_ATTR_MRU]);
        packet->ignore_df = 1;
    }
    OVS_CB(packet)->mru = mru;

    if (a[OVS_PACKET_ATTR_HASH]) {
        hash = nla_get_u64(a[OVS_PACKET_ATTR_HASH]);

        __skb_set_hash(packet, hash & 0xFFFFFFFFULL,
                   !!(hash & OVS_PACKET_HASH_SW_BIT),
                   !!(hash & OVS_PACKET_HASH_L4_BIT));
    }

    /* Build an sw_flow for sending this packet. */
    flow = ovs_flow_alloc();
    err = PTR_ERR(flow);
    if (IS_ERR(flow))
        goto err_kfree_skb;

    err = ovs_flow_key_extract_userspace(net, a[OVS_PACKET_ATTR_KEY],
                         packet, &flow->key, log);
    if (err)
        goto err_flow_free;

    err = ovs_nla_copy_actions(net, a[OVS_PACKET_ATTR_ACTIONS],
                   &flow->key, &acts, log);
    if (err)
        goto err_flow_free;

    rcu_assign_pointer(flow->sf_acts, acts);
    packet->priority = flow->key.phy.priority;
    packet->mark = flow->key.phy.skb_mark;

    rcu_read_lock();
    dp = get_dp_rcu(net, ovs_header->dp_ifindex);
    err = -ENODEV;
    if (!dp)
        goto err_unlock;

    input_vport = ovs_vport_rcu(dp, flow->key.phy.in_port);
    if (!input_vport)
        input_vport = ovs_vport_rcu(dp, OVSP_LOCAL);

    if (!input_vport)
        goto err_unlock;

    packet->dev = input_vport->dev;
    OVS_CB(packet)->input_vport = input_vport;
    sf_acts = rcu_dereference(flow->sf_acts);

    local_bh_disable();
    err = ovs_execute_actions(dp, packet, sf_acts, &flow->key);
    local_bh_enable();
    rcu_read_unlock();

    ovs_flow_free(flow, false);
    return err;

err_unlock:
    rcu_read_unlock();
err_flow_free:
    ovs_flow_free(flow, false);
err_kfree_skb:
    kfree_skb(packet);
err:
    return err;
}

/* Execute a list of actions against 'skb'. */
int ovs_execute_actions(struct datapath *dp, struct sk_buff *skb,
            const struct sw_flow_actions *acts,
            struct sw_flow_key *key)
{
    int err, level;

    level = __this_cpu_inc_return(exec_actions_level);
    if (unlikely(level > OVS_RECURSION_LIMIT)) {
        net_crit_ratelimited("ovs: recursion limit reached on datapath %s, probable configuration error\n",
                     ovs_dp_name(dp));
        kfree_skb(skb);
        err = -ENETDOWN;
        goto out;
    }

    OVS_CB(skb)->acts_origlen = acts->orig_len;
    err = do_execute_actions(dp, skb, key,
                 acts->actions, acts->actions_len);

    if (level == 1)
        process_deferred_actions(dp);

out:
    __this_cpu_dec(exec_actions_level);
    return err;
}

do_execute_actions 在上面解析了(4. action实现，模式一，内核模式datapath)
 

handler线程只对传统ovs架构下,对内核upcall的消息进行处理。即慢速路径的处理就是handler线程的工作内容。ovs+dpdk下，handler线程也存在，但是一直处于堵塞状态，实际上什么也没干。ovs+dpdk下的慢速路径的处理直接由收包线程执行，由pmd线程做的。

////////////////////7. fast path处理，到fast path没有匹配上，upcall到慢路径slow path，action处理，以及处理完毕后，将flow放入fast path，整个流程，DPDK模式

dp_netdev_input
->   dfc_processing (emc匹配)
   + fast_path_processing (dpcls匹配 + upcall)
   + packet_batch_per_flow_execute (执行action，这是快路径中执行action) ->dp_netdev_execute_actions->odp_execute_actions


对于DPDK的fast path，如果upcall到slow path呢？

fast_path_processing
->   dp_netdev_pmd_lookup_dpcls (根据入端口找到它的dpcls) 
   + dpcls_lookup(查找fast path，也即查找dpcls，返回是否有miss)
   + 如果有miss，调用 handle_packet_upcall 开始查找openflow流表。如果查找openflow流表成功并需要下发到dpcls时，需要判断是否超出最大流表限制
   + 对于没有miss的部分，也即查找dpcls成功的，调用emc_probabilistic_insert将相关rule下发到emc表项

handle_packet_upcall
->   dp_netdev_upcall (在这里，在当前的线程，对actions进行转换，并收集哪些put_actions应该放到dpcls里面)
   + dp_netdev_execute_actions (执行action，这是慢路径中执行action，说明在xlate只做action的转换，而不做action的执行) 
   + add_actions = put_actions->size ? put_actions : actions (执行完了action之后，如果dpcls表不满，可以将action添加到dpcls，如果error == ENOSPC，这个值是在dp_netdev_upcall里面，被should_install_flow函数赋值的，如果满了，则就是error，如果不满，则不是error)
   + if (OVS_LIKELY(error != ENOSPC)) netdev_flow = dp_netdev_pmd_lookup_flow(pmd, key, NULL);
   + dp_netdev_flow_add(pmd, &match, &ufid, add_actions->data, add_actions->size) (将flow rule添加到DPDK中的fast path的dpcls)
   + emc_probabilistic_insert (将flow rule添加到DPDK中的fast path的emc)

dp_netdev_upcall->upcall_cb(对于DPDK模式来说，这个是处理upcall的核心函数)
-> upcall_receive (无论是内核模式，还是DPDK模式，都先调用upcall_receive，两者的type都是一样的，都是DPIF_UC_MISS，不同的是，内核PMD是PMD_ID_NULL，而DPDK的PMD有pmd_id)
   + process_upcall (无论是内核模式，还是DPDK模式，都再调用process_upcall查找openflow流表，并对于actions进行转换)
   + should_install_flow(udpif, &upcall) (如果超过了最大流表限制，则返回ENOSPC，这里并不安装流表到dpcls，而到上层函数去安装)

dp_netdev_execute_actions->odp_execute_actions 在上面解析了(5. action实现，模式二，DPDK模式)

在DPDK模式下，可以看出action的执行可以在外层fast path的最后，也可以在内层handle_packet_upcall中执行，在handle_packet_upcall中执行action的代码里有下面的注释
/* We can't allow the packet batching in the next loop to execute
     * the actions.  Otherwise, if there are any slow path actions,
     * we'll send the packet up twice. */
    dp_packet_batch_init_packet(&b, packet);
    dp_netdev_execute_actions(pmd, &b, true, &match.flow,
                              actions->data, actions->size);
upcall的时候，直接将action执行完，不需要等到外层再执行。

////////////////////8. 用户态和内核态netlink互通


ofproto/ofproto-dpif-xlate.c

struct xlate_out {
    /* Caching exceptions:
     *
     *   - If 'slow' is nonzero, the translation needs to be slow-pathed for
     *     one reason or another.  (The particular value is only important for
     *     explaining to an administrator why the flow is slow-pathed.)  This
     *     makes OVS install a datapath flow with a send-to-userspace action.
     *     Only on revalidation will the flow be replaced, if appropriate, by
     *     one that does something else with the traffic.
     *
     *   - If 'avoid_caching' is true, then OVS won't install a datapath flow
     *     at all.  If the reason to avoid caching goes away, the next upcall
     *     will immediately install a correct datapath flow.
     *
     *   - Otherwise a datapath flow can be installed in the usual way.
     *
     * If 'avoid_caching' is true then 'slow' doesn't matter.
     */
    enum slow_path_reason slow;
    bool avoid_caching;

    /* Recirc action IDs on which references are held. */
    struct recirc_refs recircs;
};

struct xlate_in {
    struct ofproto_dpif *ofproto;
    ovs_version_t        tables_version;   /* Lookup in this version. */

    /* Flow to which the OpenFlow actions apply.  xlate_actions() will modify
     * this flow when actions change header fields. *////////////////////////
    struct flow flow;

    /* Pointer to the original flow received during the upcall. xlate_actions()
     * will never modify this flow. */
    const struct flow *upcall_flow;

    /* The packet corresponding to 'flow', or a null pointer if we are
     * revalidating without a packet to refer to. *///////////////////////////
    const struct dp_packet *packet;

    /* Should OFPP_NORMAL update the MAC learning table?  Should "learn"
     * actions update the flow table? Should FIN_TIMEOUT change the
     * timeouts? Or should controller action send packet to the controller?
     *
     * We want to update these tables if we are actually processing a packet,
     * or if we are accounting for packets that the datapath has processed, but
     * not if we are just revalidating, or if we want to execute the
     * side-effects later via the xlate cache. */
    bool allow_side_effects;

    /* The rule initiating translation or NULL. If both 'rule' and 'ofpacts'
     * are NULL, xlate_actions() will do the initial rule lookup itself. */
    struct rule_dpif *rule;

    /* The actions to translate.  If 'rule' is not NULL, these may be NULL. */
    const struct ofpact *ofpacts;
    size_t ofpacts_len;

    /* Union of the set of TCP flags seen so far in this flow.  (Used only by
     * NXAST_FIN_TIMEOUT.  Set to zero to avoid updating updating rules'
     * timeouts.) */
    uint16_t tcp_flags;

    /* Set to nonnull to trace the translation.  See ofproto-dpif-trace.h for
     * more information.  This points to the list of oftrace nodes to which the
     * translation should add tracing information (with oftrace_report()). */
    struct ovs_list *trace;

    /* If nonnull, flow translation credits the specified statistics to each
     * rule reached through a resubmit or OFPP_TABLE action.
     *
     * This is normally null so the client has to set it manually after
     * calling xlate_in_init(). */
    const struct dpif_flow_stats *resubmit_stats;

    /* Counters carried over from a pre-existing translation of a related flow.
     * This can occur due to, e.g., the translation of an ARP packet that was
     * generated as the result of outputting to a tunnel port.  In that case,
     * the original flow going to the tunnel is the related flow.  Since the
     * two flows are different, they should not use the same xlate_ctx
     * structure.  However, we still need limit the maximum recursion across
     * the entire translation.
     *
     * These fields are normally set to zero, so the client has to set them
     * manually after calling xlate_in_init().  In that case, they should be
     * copied from the same-named fields in the related flow's xlate_ctx.
     *
     * These fields are really implementation details; the client doesn't care
     * about what they mean.  See the corresponding fields in xlate_ctx for
     * real documentation. */
    int depth;
    int resubmits;

    /* If nonnull, flow translation populates this cache with references to all
     * modules that are affected by translation. This 'xlate_cache' may be
     * passed to xlate_push_stats() to perform the same function as
     * xlate_actions() without the full cost of translation.
     *
     * This is normally null so the client has to set it manually after
     * calling xlate_in_init(). */
    struct xlate_cache *xcache;

    /* If nonnull, flow translation puts the resulting datapath actions in this
     * buffer.  If null, flow translation will not produce datapath actions. *//////////////
    struct ofpbuf *odp_actions;

    /* If nonnull, flow translation populates this with wildcards relevant in
     * translation.  Any fields that were used to calculate the action are set,
     * to allow caching and kernel wildcarding to work.  For example, if the
     * flow lookup involved performing the "normal" action on IPv4 and ARP
     * packets, 'wc' would have the 'in_port' (always set), 'dl_type' (flow
     * match), 'vlan_tci' (normal action), and 'dl_dst' (normal action) fields
     * set. */
    struct flow_wildcards *wc;

    /* The frozen state to be resumed, as returned by xlate_lookup(). */
    const struct frozen_state *frozen_state;

    /* If true, the packet to be translated is from a packet_out msg. */
    bool in_packet_out;

    /* ofproto/trace maintains this queue to trace flows that require
     * recirculation. */
    struct ovs_list *recirc_queue;

    /* UUID of first non-patch port packet was received on.*/
    struct uuid xport_uuid;
};

/* Translates the flow, actions, or rule in 'xin' into datapath actions in
 * 'xout'.
 * The caller must take responsibility for eventually freeing 'xout', with
 * xlate_out_uninit().
 * Returns 'XLATE_OK' if translation was successful.  In case of an error an
 * empty set of actions will be returned in 'xin->odp_actions' (if non-NULL),
 * so that most callers may ignore the return value and transparently install a
 * drop flow when the translation fails. */
enum xlate_error
xlate_actions(struct xlate_in *xin, struct xlate_out *xout)
{
    *xout = (struct xlate_out) {
        .slow = 0,
        .recircs = RECIRC_REFS_EMPTY_INITIALIZER,
    };

    struct xlate_cfg *xcfg = ovsrcu_get(struct xlate_cfg *, &xcfgp);
    struct xbridge *xbridge = xbridge_lookup(xcfg, xin->ofproto);
    if (!xbridge) {
        return XLATE_BRIDGE_NOT_FOUND;
    }

    struct flow *flow = &xin->flow;

    uint8_t stack_stub[1024];
    uint64_t action_set_stub[1024 / 8];
    uint64_t frozen_actions_stub[1024 / 8];
    uint64_t actions_stub[256 / 8];
    struct ofpbuf scratch_actions = OFPBUF_STUB_INITIALIZER(actions_stub);
    struct xlate_ctx ctx = {
        .xin = xin,
        .xout = xout,
        .base_flow = *flow,
        .orig_tunnel_ipv6_dst = flow_tnl_dst(&flow->tunnel),
        .xcfg = xcfg,
        .xbridge = xbridge,
        .stack = OFPBUF_STUB_INITIALIZER(stack_stub),
        .rule = xin->rule,
        .wc = (xin->wc
               ? xin->wc
               : &(struct flow_wildcards) { .masks = { .dl_type = 0 } }),
        .odp_actions = xin->odp_actions ? xin->odp_actions : &scratch_actions,

        .depth = xin->depth,
        .resubmits = xin->resubmits,
        .in_action_set = false,
        .in_packet_out = xin->in_packet_out,
        .pending_encap = false,
        .pending_decap = false,
        .encap_data = NULL,

        .table_id = 0,
        .rule_cookie = OVS_BE64_MAX,
        .orig_skb_priority = flow->skb_priority,
        .sflow_n_outputs = 0,
        .sflow_odp_port = 0,
        .nf_output_iface = NF_OUT_DROP,
        .exit = false,
        .error = XLATE_OK,
        .mirrors = 0,

        .freezing = false,
        .recirc_update_dp_hash = false,
        .frozen_actions = OFPBUF_STUB_INITIALIZER(frozen_actions_stub),
        .pause = NULL,

        .was_mpls = false,
        .conntracked = false,

        .ct_nat_action = NULL,

        .action_set_has_group = false,
        .action_set = OFPBUF_STUB_INITIALIZER(action_set_stub),
    };

    /* 'base_flow' reflects the packet as it came in, but we need it to reflect
     * the packet as the datapath will treat it for output actions. Our
     * datapath doesn't retain tunneling information without us re-setting
     * it, so clear the tunnel data.
     */

    memset(&ctx.base_flow.tunnel, 0, sizeof ctx.base_flow.tunnel);

    ofpbuf_reserve(ctx.odp_actions, NL_A_U32_SIZE);
    xlate_wc_init(&ctx);

    COVERAGE_INC(xlate_actions);

    xin->trace = xlate_report(&ctx, OFT_BRIDGE, "bridge(\"%s\")",
                              xbridge->name);
......
    /* Tunnel metadata in udpif format must be normalized before translation. */
    if (flow->tunnel.flags & FLOW_TNL_F_UDPIF) {
        const struct tun_table *tun_tab = ofproto_get_tun_tab(
            &ctx.xbridge->ofproto->up);
        int err;

        err = tun_metadata_from_geneve_udpif(tun_tab, &xin->upcall_flow->tunnel,
                                             &xin->upcall_flow->tunnel,
                                             &flow->tunnel);
        if (err) {
            xlate_report_error(&ctx, "Invalid Geneve tunnel metadata");
            ctx.error = XLATE_INVALID_TUNNEL_METADATA;
            goto exit;
        }
    } else if (!flow->tunnel.metadata.tab) {
        /* If the original flow did not come in on a tunnel, then it won't have
         * FLOW_TNL_F_UDPIF set. However, we still need to have a metadata
         * table in case we generate tunnel actions. */
        flow->tunnel.metadata.tab = ofproto_get_tun_tab(
            &ctx.xbridge->ofproto->up);
    }
    ctx.wc->masks.tunnel.metadata.tab = flow->tunnel.metadata.tab;

    /* Get the proximate input port of the packet.  (If xin->frozen_state,
     * flow->in_port is the ultimate input port of the packet.) */
    struct xport *in_port = get_ofp_port(xbridge,
                                         ctx.base_flow.in_port.ofp_port);
    if (in_port && !in_port->peer) {
        ctx.xin->xport_uuid = in_port->uuid;
    }

    if (flow->packet_type != htonl(PT_ETH) && in_port &&
        in_port->pt_mode == NETDEV_PT_LEGACY_L3 && ctx.table_id == 0) {
        /* Add dummy Ethernet header to non-L2 packet if it's coming from a
         * L3 port. So all packets will be L2 packets for lookup.
         * The dl_type has already been set from the packet_type. */
        flow->packet_type = htonl(PT_ETH);
        flow->dl_src = eth_addr_zero;
        flow->dl_dst = eth_addr_zero;
        ctx.pending_encap = true;
    }

    if (!xin->ofpacts && !ctx.rule) {
        ctx.rule = rule_dpif_lookup_from_table(
            ctx.xbridge->ofproto, ctx.xin->tables_version, flow, ctx.wc,
            ctx.xin->resubmit_stats, &ctx.table_id,
            flow->in_port.ofp_port, true, true, ctx.xin->xcache);
        if (ctx.xin->resubmit_stats) {
            rule_dpif_credit_stats(ctx.rule, ctx.xin->resubmit_stats, false);
        }
        if (ctx.xin->xcache) {
            struct xc_entry *entry;

            entry = xlate_cache_add_entry(ctx.xin->xcache, XC_RULE);
            entry->rule = ctx.rule;
            ofproto_rule_ref(&ctx.rule->up);
        }

        xlate_report_table(&ctx, ctx.rule, ctx.table_id);
    }

    /* Tunnel stats only for not-thawed packets. */
    if (!xin->frozen_state && in_port && in_port->is_tunnel) {
        if (ctx.xin->resubmit_stats) {
            netdev_vport_inc_rx(in_port->netdev, ctx.xin->resubmit_stats);
            if (in_port->bfd) {
                bfd_account_rx(in_port->bfd, ctx.xin->resubmit_stats);
            }
        }
        if (ctx.xin->xcache) {
            struct xc_entry *entry;

            entry = xlate_cache_add_entry(ctx.xin->xcache, XC_NETDEV);
            entry->dev.rx = netdev_ref(in_port->netdev);
            entry->dev.bfd = bfd_ref(in_port->bfd);
        }
    }

    if (!xin->frozen_state && process_special(&ctx, in_port)) {
        /* process_special() did all the processing for this packet.
         *
         * We do not perform special processing on thawed packets, since that
         * was done before they were frozen and should not be redone. */
        mirror_ingress_packet(&ctx);
    } else if (in_port && in_port->xbundle
               && xbundle_mirror_out(xbridge, in_port->xbundle)) {
        xlate_report_error(&ctx, "dropping packet received on port "
                           "%s, which is reserved exclusively for mirroring",
                           in_port->xbundle->name);
    } else {
        /* Sampling is done on initial reception; don't redo after thawing. */
        unsigned int user_cookie_offset = 0;
        if (!xin->frozen_state) {
            user_cookie_offset = compose_sflow_action(&ctx);
            compose_ipfix_action(&ctx, ODPP_NONE);
        }
        size_t sample_actions_len = ctx.odp_actions->size;
        bool ecn_drop = !tnl_process_ecn(flow);

        if (!ecn_drop
            && (!in_port || may_receive(in_port, &ctx))) {
            const struct ofpact *ofpacts;
            size_t ofpacts_len;

            if (xin->ofpacts) {
                ofpacts = xin->ofpacts;
                ofpacts_len = xin->ofpacts_len;
            } else if (ctx.rule) {
                const struct rule_actions *actions
                    = rule_get_actions(&ctx.rule->up);
                ofpacts = actions->ofpacts;
                ofpacts_len = actions->ofpacts_len;
                ctx.rule_cookie = ctx.rule->up.flow_cookie;
            } else {
                OVS_NOT_REACHED();
            }

            mirror_ingress_packet(&ctx);
            do_xlate_actions(ofpacts, ofpacts_len, &ctx, true, false);//////////////////
            if (ctx.error) {
                goto exit;
            }

            /* We've let OFPP_NORMAL and the learning action look at the
             * packet, so cancel all actions and freezing if forwarding is
             * disabled. */
            if (in_port && (!xport_stp_forward_state(in_port) ||
                            !xport_rstp_forward_state(in_port))) {
                ctx.odp_actions->size = sample_actions_len;
                ctx_cancel_freeze(&ctx);
                ofpbuf_clear(&ctx.action_set);
                ctx.error = XLATE_FORWARDING_DISABLED;
            }

            if (!ctx.freezing) {
                xlate_action_set(&ctx);
            }
            if (ctx.freezing) {
                finish_freezing(&ctx);
            }
        } else if (ecn_drop) {
            ctx.error = XLATE_CONGESTION_DROP;
        }

        /* Output only fully processed packets. */
        if (!ctx.freezing
            && xbridge->has_in_band
            && in_band_must_output_to_local_port(flow)
            && !actions_output_to_local_port(&ctx)) {
            WC_MASK_FIELD(ctx.wc, nw_proto);
            WC_MASK_FIELD(ctx.wc, tp_src);
            WC_MASK_FIELD(ctx.wc, tp_dst);
            WC_MASK_FIELD(ctx.wc, dl_type);
            xlate_report(&ctx, OFT_DETAIL, "outputting DHCP packet "
                         "to local port for in-band control");
            compose_output_action(&ctx, OFPP_LOCAL, NULL, false, false);
        }

        if (user_cookie_offset) {
            fix_sflow_action(&ctx, user_cookie_offset);
        }
    }

    if (nl_attr_oversized(ctx.odp_actions->size)) {
        /* These datapath actions are too big for a Netlink attribute, so we
         * can't hand them to the kernel directly.  dpif_execute() can execute
         * them one by one with help, so just mark the result as SLOW_ACTION to
         * prevent the flow from being installed. */
        COVERAGE_INC(xlate_actions_oversize);
        ctx.xout->slow |= SLOW_ACTION;
    } else if (too_many_output_actions(ctx.odp_actions)) {
        COVERAGE_INC(xlate_actions_too_many_output);
        ctx.xout->slow |= SLOW_ACTION;
    }

    /* Update NetFlow for non-frozen traffic. */
    if (xbridge->netflow && !xin->frozen_state) {
        if (ctx.xin->resubmit_stats) {
            netflow_flow_update(xbridge->netflow, flow,
                                ctx.nf_output_iface,
                                ctx.xin->resubmit_stats);
        }
        if (ctx.xin->xcache) {
            struct xc_entry *entry;

            entry = xlate_cache_add_entry(ctx.xin->xcache, XC_NETFLOW);
            entry->nf.netflow = netflow_ref(xbridge->netflow);
            entry->nf.flow = xmemdup(flow, sizeof *flow);
            entry->nf.iface = ctx.nf_output_iface;
        }
    }

    /* Translate tunnel metadata masks to udpif format if necessary. */
    if (xin->upcall_flow->tunnel.flags & FLOW_TNL_F_UDPIF) {
        if (ctx.wc->masks.tunnel.metadata.present.map) {
            const struct flow_tnl *upcall_tnl = &xin->upcall_flow->tunnel;
            struct geneve_opt opts[TLV_TOT_OPT_SIZE /
                                   sizeof(struct geneve_opt)];

            tun_metadata_to_geneve_udpif_mask(&flow->tunnel,
                                              &ctx.wc->masks.tunnel,
                                              upcall_tnl->metadata.opts.gnv,
                                              upcall_tnl->metadata.present.len,
                                              opts);
             memset(&ctx.wc->masks.tunnel.metadata, 0,
                    sizeof ctx.wc->masks.tunnel.metadata);
             memcpy(&ctx.wc->masks.tunnel.metadata.opts.gnv, opts,
                    upcall_tnl->metadata.present.len);
        }
        ctx.wc->masks.tunnel.metadata.present.len = 0xff;
        ctx.wc->masks.tunnel.metadata.tab = NULL;
        ctx.wc->masks.tunnel.flags |= FLOW_TNL_F_UDPIF;
    } else if (!xin->upcall_flow->tunnel.metadata.tab) {
        /* If we didn't have options in UDPIF format and didn't have an existing
         * metadata table, then it means that there were no options at all when
         * we started processing and any wildcards we picked up were from
         * action generation. Without options on the incoming packet, wildcards
         * aren't meaningful. To avoid them possibly getting misinterpreted,
         * just clear everything. */
        if (ctx.wc->masks.tunnel.metadata.present.map) {
            memset(&ctx.wc->masks.tunnel.metadata, 0,
                   sizeof ctx.wc->masks.tunnel.metadata);
        } else {
            ctx.wc->masks.tunnel.metadata.tab = NULL;
        }
    }

    xlate_wc_finish(&ctx);

exit:
    /* Reset the table to what it was when we came in. If we only fetched
     * it locally, then it has no meaning outside of flow translation. */
    flow->tunnel.metadata.tab = xin->upcall_flow->tunnel.metadata.tab;

    ofpbuf_uninit(&ctx.stack);
    ofpbuf_uninit(&ctx.action_set);
    ofpbuf_uninit(&ctx.frozen_actions);
    ofpbuf_uninit(&scratch_actions);
    ofpbuf_delete(ctx.encap_data);

    /* Make sure we return a "drop flow" in case of an error. */
    if (ctx.error) {
        xout->slow = 0;
        if (xin->odp_actions) {
            ofpbuf_clear(xin->odp_actions);
        }
    }

    /* Install drop action if datapath supports explicit drop action. */
    if (xin->odp_actions && !xin->odp_actions->size &&
        ovs_explicit_drop_action_supported(ctx.xbridge->ofproto)) {
        put_drop_action(xin->odp_actions, ctx.error);
    }

    /* Since congestion drop and forwarding drop are not exactly
     * translation error, we are resetting the translation error.
     */
    if (ctx.error == XLATE_CONGESTION_DROP ||
        ctx.error == XLATE_FORWARDING_DISABLED) {
        ctx.error = XLATE_OK;
    }

    return ctx.error;
}

Actions有以下的操作：
output:port 和 output:NXM_NX_REG0[16..31]
enqueue:port:queue
mod_vlan_vid:vlan_vid
strip_vlan
mod_dl_src:mac 和 mod_dl_dst:mac
mod_nw_src:ip 和 mod_nw_dst:ip
mod_tp_src:port 和 mod_tp_dst:port
set_tunnel:id
resubmit([port],[table])
move:src[start..end]−>dst[start..end]
load:value−>dst[start..end]
learn(argument[,argument]...)

配置Flow。
1. 删除所有的Flow
ovs-ofctl del-flows br-tun
2. 配置Table 0
从port 1进来的，由table 1处理
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=1 in_port=1 actions=resubmit(,1)"
从port 2/3进来的，由Table 3处理
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=1 in_port=2 actions=resubmit(,3)"
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=1 in_port=3 actions=resubmit(,3)"
默认丢弃
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=0 actions=drop"
3. 配置Table 1
对于单播，由table 20处理
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=1 table=1 dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=resubmit(,20)"
对于多播，由table 21处理
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=1 table=1 dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=resubmit(,21)"
4. 配置Table 2
默认丢弃
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=0 table=2 actions=drop"
5. 配置Table 3
默认丢弃
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=0 table=3 actions=drop"
Tunnel ID -> VLAN ID
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=1 table=3 tun_id=0x1 actions=mod_vlan_vid:1,resubmit(,10)"
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=1 table=3 tun_id=0x2 actions=mod_vlan_vid:2,resubmit(,10)"
6. 配置Table 10
MAC地址学习
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=1 table=10  actions=learn(table=20,priority=1,hard_timeout=300,NXM_OF_VLAN_TCI[0..11],NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:0->NXM_OF_VLAN_TCI[],load:NXM_NX_TUN_ID[]->NXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output:1"

Table 10是用来学习MAC地址的，学习的结果放在Table 20里面，Table20被称为MAC learning table
NXM_OF_VLAN_TCI这个是VLAN Tag，在MAC Learning table中，每一个entry都是仅仅对某一个VLAN来说的，不同VLAN的learning table是分开的。在学习的结果的entry中，会标出这个entry是对于哪个VLAN的。
NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[]这个的意思是当前包里面的MAC Source Address会被放在学习结果的entry里面的dl_dst里面。这是因为每个switch都是通过Ingress包来学习，某个MAC从某个port进来，switch就应该记住以后发往这个MAC的包要从这个port出去，因而MAC source address就被放在了Mac destination address里面，因为这是为发送用的。
load:0->NXM_OF_VLAN_TCI[]意思是发送出去的时候，vlan tag设为0，所以结果中有actions=strip_vlan
load:NXM_NX_TUN_ID[]->NXM_NX_TUN_ID[]意思是发出去的时候，设置tunnel id，进来的时候是多少，发送的时候就是多少，所以结果中有set_tunnel:0x3e9
output:NXM_OF_IN_PORT[]意思是发送给哪个port，由于是从port2进来的，因而结果中有output:2

7. 配置Table 20
这个是MAC Address Learning Table，如果不空就按照规则处理。
如果为空，就使用默认规则，交给Table 21处理。
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=0 table=20 actions=resubmit(,21)"
8. 配置Table 21
默认丢弃
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=0 table=21 actions=drop"
VLAN ID -> Tunnel ID
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=1 table=21 dl_vlan=1 actions=strip_vlan,set_tunnel:0x1,output:2,output:3"
ovs-ofctl add-flow br-tun "hard_timeout=0 idle_timeout=0 priority=1 table=21 dl_vlan=2 actions=strip_vlan,set_tunnel:0x2,output:2,output:3"


fast path的action和slow path的action不一样，是如何转换过来的呢？

内核模式fast path的action有： do_execute_actions
OVS_ACTION_ATTR_CHECK_PKT_LEN
OVS_ACTION_ATTR_CLONE
OVS_ACTION_ATTR_CT
OVS_ACTION_ATTR_CT_CLEAR
OVS_ACTION_ATTR_HASH
OVS_ACTION_ATTR_METER
OVS_ACTION_ATTR_OUTPUT
OVS_ACTION_ATTR_POP_ETH
OVS_ACTION_ATTR_POP_MPLS
OVS_ACTION_ATTR_POP_NSH
OVS_ACTION_ATTR_POP_VLAN
OVS_ACTION_ATTR_PUSH_ETH
OVS_ACTION_ATTR_PUSH_MPLS
OVS_ACTION_ATTR_PUSH_NSH
OVS_ACTION_ATTR_PUSH_VLAN
OVS_ACTION_ATTR_RECIRC
OVS_ACTION_ATTR_SAMPLE
OVS_ACTION_ATTR_SET
OVS_ACTION_ATTR_SET_MASKED
OVS_ACTION_ATTR_SET_TO_MASKED
OVS_ACTION_ATTR_TRUNC
OVS_ACTION_ATTR_USERSPACE


DPDK模式fast path的action有： odp_execute_actions
OVS_ACTION_ATTR_CHECK_PKT_LEN
OVS_ACTION_ATTR_CLONE
OVS_ACTION_ATTR_CT
OVS_ACTION_ATTR_CT_CLEAR
OVS_ACTION_ATTR_DROP
OVS_ACTION_ATTR_HASH
OVS_ACTION_ATTR_LB_OUTPUT
OVS_ACTION_ATTR_METER
OVS_ACTION_ATTR_OUTPUT
OVS_ACTION_ATTR_POP_ETH
OVS_ACTION_ATTR_POP_MPLS
OVS_ACTION_ATTR_POP_NSH
OVS_ACTION_ATTR_POP_VLAN
OVS_ACTION_ATTR_PUSH_ETH
OVS_ACTION_ATTR_PUSH_MPLS
OVS_ACTION_ATTR_PUSH_NSH
OVS_ACTION_ATTR_PUSH_VLAN
OVS_ACTION_ATTR_RECIRC
OVS_ACTION_ATTR_SAMPLE
OVS_ACTION_ATTR_SET
OVS_ACTION_ATTR_SET_MASKED
OVS_ACTION_ATTR_TRUNC
OVS_ACTION_ATTR_TUNNEL_POP
OVS_ACTION_ATTR_TUNNEL_PUSH
OVS_ACTION_ATTR_UNSPEC
OVS_ACTION_ATTR_USERSPACE
__OVS_ACTION_ATTR_MAX

slow path的openflow action有： do_xlate_actions
OFPACT_CONTROLLER
OFPACT_ENQUEUE
OFPACT_GROUP
OFPACT_OUTPUT
OFPACT_POP_QUEUE
OFPACT_PUSH_MPLS
OFPACT_PUSH_VLAN
OFPACT_REG_MOVE
OFPACT_RESUBMIT
OFPACT_SET_ETH_DST
OFPACT_SET_ETH_SRC
OFPACT_SET_FIELD
OFPACT_SET_IP_DSCP
OFPACT_SET_IP_ECN
OFPACT_SET_IP_TTL
OFPACT_SET_IPV4_DST
OFPACT_SET_IPV4_SRC
OFPACT_SET_L4_DST_PORT
OFPACT_SET_L4_SRC_PORT
OFPACT_SET_QUEUE
OFPACT_SET_TUNNEL
OFPACT_SET_VLAN_PCP
OFPACT_SET_VLAN_VID
OFPACT_STACK_POP
OFPACT_STACK_PUSH
OFPACT_STRIP_VLAN

如何从openflow的action转换成为内核的action呢？

我们解析以下几个
OFPACT_RESUBMIT
OFPACT_OUTPUT
OFPACT_SET_ETH_DST
OFPACT_SET_IPV4_DST

------------------OFPACT_SET_ETH_DST

do_xlate_actions(const struct ofpact *ofpacts, size_t ofpacts_len,
                 struct xlate_ctx *ctx, bool is_last_action,
                 bool group_bucket_action)
    struct flow_wildcards *wc = ctx->wc;
    struct flow *flow = &ctx->xin->flow;
    const struct ofpact *a;
        case OFPACT_SET_ETH_DST:
            WC_MASK_FIELD(wc, dl_dst);
            flow->dl_dst = ofpact_get_SET_ETH_DST(a)->mac;
            break;
这里修改了flow里面的值，但是这里的值是在转换函数里面设置的，真正执行action的时候，如何修改的真正包里面的值呢？

compose_output_action__->
        /* Commit accumulated flow updates before output. */
        xlate_commit_actions(ctx);

compose_conntrack_action->
    /* Ensure that any prior actions are applied before composing the new
     * conntrack action. */
    xlate_commit_actions(ctx);

static void
xlate_commit_actions(struct xlate_ctx *ctx)
{
    bool use_masked = ctx->xbridge->support.masked_set_action;

    ctx->xout->slow |= commit_odp_actions(&ctx->xin->flow, &ctx->base_flow,
                                          ctx->odp_actions, ctx->wc,
                                          use_masked, ctx->pending_encap,
                                          ctx->pending_decap, ctx->encap_data);
    ctx->pending_encap = false;
    ctx->pending_decap = false;
    ofpbuf_delete(ctx->encap_data);
    ctx->encap_data = NULL;
}

/* If any of the flow key data that ODP actions can modify are different in
 * 'base' and 'flow', appends ODP actions to 'odp_actions' that change the flow
 * key from 'base' into 'flow', and then changes 'base' the same way.  Does not
 * commit set_tunnel actions.  Users should call commit_odp_tunnel_action()
 * in addition to this function if needed.  Sets fields in 'wc' that are
 * used as part of the action.
 *
 * In the common case, this function returns 0.  If the flow key modification
 * requires the flow's packets to be forced into the userspace slow path, this
 * function returns SLOW_ACTION.  This only happens when there is no ODP action
 * to modify some field that was actually modified.  For example, there is no
 * ODP action to modify any ARP field, so such a modification triggers
 * SLOW_ACTION.  (When this happens, packets that need such modification get
 * flushed to userspace and handled there, which works OK but much more slowly
 * than if the datapath handled it directly.) */
enum slow_path_reason
commit_odp_actions(const struct flow *flow, struct flow *base,
                   struct ofpbuf *odp_actions, struct flow_wildcards *wc,
                   bool use_masked, bool pending_encap, bool pending_decap,
                   struct ofpbuf *encap_data)
{
    /* If you add a field that OpenFlow actions can change, and that is visible
     * to the datapath (including all data fields), then you should also add
     * code here to commit changes to the field. */
    BUILD_ASSERT_DECL(FLOW_WC_SEQ == 42);

    enum slow_path_reason slow1, slow2;
    bool mpls_done = false;

    commit_encap_decap_action(flow, base, odp_actions, wc,
                              pending_encap, pending_decap, encap_data);
    commit_set_ether_action(flow, base, odp_actions, wc, use_masked);
    /* Make packet a non-MPLS packet before committing L3/4 actions,
     * which would otherwise do nothing. */
    if (eth_type_mpls(base->dl_type) && !eth_type_mpls(flow->dl_type)) {
        commit_mpls_action(flow, base, odp_actions);
        mpls_done = true;
    }
    commit_set_nsh_action(flow, base, odp_actions, wc, use_masked);
    slow1 = commit_set_nw_action(flow, base, odp_actions, wc, use_masked);
    commit_set_port_action(flow, base, odp_actions, wc, use_masked);
    slow2 = commit_set_icmp_action(flow, base, odp_actions, wc);
    if (!mpls_done) {
        commit_mpls_action(flow, base, odp_actions);
    }
    commit_vlan_action(flow, base, odp_actions, wc);
    commit_set_priority_action(flow, base, odp_actions, wc, use_masked);
    commit_set_pkt_mark_action(flow, base, odp_actions, wc, use_masked);

    return slow1 ? slow1 : slow2;
}

可以看出commit_odp_actions是将各种各样的action都提交，其实是提交给了netlink message.

static void
commit_set_ether_action(const struct flow *flow, struct flow *base_flow,
                        struct ofpbuf *odp_actions,
                        struct flow_wildcards *wc,
                        bool use_masked)
{
    struct ovs_key_ethernet key, base, mask, orig_mask;
    struct offsetof_sizeof ovs_key_ethernet_offsetof_sizeof_arr[] =
        OVS_KEY_ETHERNET_OFFSETOF_SIZEOF_ARR;

    if (flow->packet_type != htonl(PT_ETH)) {
        return;
    }

    get_ethernet_key(flow, &key);
    get_ethernet_key(base_flow, &base);
    get_ethernet_key(&wc->masks, &mask);
    memcpy(&orig_mask, &mask, sizeof mask);

    if (commit(OVS_KEY_ATTR_ETHERNET, use_masked,
               &key, &base, &mask, sizeof key,
               ovs_key_ethernet_offsetof_sizeof_arr, odp_actions)) {
        put_ethernet_key(&base, base_flow);
        or_masks(&mask, &orig_mask, ovs_key_ethernet_offsetof_sizeof_arr);
        put_ethernet_key(&mask, &wc->masks);
    }
}

static bool
commit(enum ovs_key_attr attr, bool use_masked_set,
       const void *key, void *base, void *mask, size_t size,
       struct offsetof_sizeof *offsetof_sizeof_arr,
       struct ofpbuf *odp_actions)
{
    if (keycmp_mask(key, base, offsetof_sizeof_arr, mask)) {
        bool fully_masked = odp_mask_is_exact(attr, mask, size);

        if (use_masked_set && !fully_masked) {
            commit_masked_set_action(odp_actions, attr, key, mask, size);
        } else {
            if (!fully_masked) {
                memset(mask, 0xff, size);
            }
            commit_set_action(odp_actions, attr, key, size);
        }
        memcpy(base, key, size);
        return true;
    } else {
        /* Mask bits are set when we have either read or set the corresponding
         * values.  Masked bits will be exact-matched, no need to set them
         * if the value did not actually change. */
        return false;
    }
}

static void
commit_set_action(struct ofpbuf *odp_actions, enum ovs_key_attr key_type,
                  const void *key, size_t key_size)
{
    size_t offset = nl_msg_start_nested(odp_actions, OVS_ACTION_ATTR_SET);
    nl_msg_put_unspec(odp_actions, key_type, key, key_size);
    nl_msg_end_nested(odp_actions, offset);
}

/* Masked set actions have a mask following the data within the netlink
 * attribute.  The unmasked bits in the data will be cleared as the data
 * is copied to the action. */
void
commit_masked_set_action(struct ofpbuf *odp_actions,
                         enum ovs_key_attr key_type,
                         const void *key_, const void *mask_, size_t key_size)
{
    size_t offset = nl_msg_start_nested(odp_actions,
                                        OVS_ACTION_ATTR_SET_MASKED);
    char *data = nl_msg_put_unspec_uninit(odp_actions, key_type, key_size * 2);
    const char *key = key_, *mask = mask_;

    memcpy(data + key_size, mask, key_size);
    /* Clear unmasked bits while copying. */
    while (key_size--) {
        *data++ = *key++ & *mask++;
    }
    nl_msg_end_nested(odp_actions, offset);
}

在netlink message里面的action如何提交给内核中呢？

handle_upcalls 将flow rule添加到内核中的fast path(如果should_install_flow为true，put_op_init里面设置op->dop.type = DPIF_OP_FLOW_PUT)，且在内核执行action(设置op->dop.type = DPIF_OP_EXECUTE) 
-> dpif_operate -> dpif_netlink_operate -> dpif_netlink_operate_chunks -> dpif_netlink_operate__ (case DPIF_OP_FLOW_PUT: dpif_netlink_init_flow_put + dpif_netlink_flow_to_ofpbuf ; case DPIF_OP_EXECUTE: dpif_netlink_encode_execute)
+ nl_transact_multiple(通过netlink发送给内核)

前面我们重点分析了case DPIF_OP_EXECUTE: dpif_netlink_encode_execute

这里我们分析case DPIF_OP_FLOW_PUT: dpif_netlink_init_flow_put + dpif_netlink_flow_to_ofpbuf

static void
dpif_netlink_init_flow_put(struct dpif_netlink *dpif,
                           const struct dpif_flow_put *put,
                           struct dpif_netlink_flow *request)
{
    static const struct nlattr dummy_action;

    dpif_netlink_flow_init(request);
    request->cmd = (put->flags & DPIF_FP_CREATE
                    ? OVS_FLOW_CMD_NEW : OVS_FLOW_CMD_SET);
    request->dp_ifindex = dpif->dp_ifindex;
    request->key = put->key;
    request->key_len = put->key_len;
    request->mask = put->mask;
    request->mask_len = put->mask_len;
    dpif_netlink_flow_init_ufid(request, put->ufid, false);

    /* Ensure that OVS_FLOW_ATTR_ACTIONS will always be included. */
    request->actions = (put->actions
                        ? put->actions
                        : CONST_CAST(struct nlattr *, &dummy_action));
    request->actions_len = put->actions_len;
    if (put->flags & DPIF_FP_ZERO_STATS) {
        request->clear = true;
    }
    if (put->flags & DPIF_FP_PROBE) {
        request->probe = true;
    }
    request->nlmsg_flags = put->flags & DPIF_FP_MODIFY ? 0 : NLM_F_CREATE;
}

/* Appends to 'buf' (which must initially be empty) a "struct ovs_header"
 * followed by Netlink attributes corresponding to 'flow'. */
static void
dpif_netlink_flow_to_ofpbuf(const struct dpif_netlink_flow *flow,
                            struct ofpbuf *buf)
{
    struct ovs_header *ovs_header;

    nl_msg_put_genlmsghdr(buf, 0, ovs_flow_family,
                          NLM_F_REQUEST | flow->nlmsg_flags,
                          flow->cmd, OVS_FLOW_VERSION);

    ovs_header = ofpbuf_put_uninit(buf, sizeof *ovs_header);
    ovs_header->dp_ifindex = flow->dp_ifindex;

    if (flow->ufid_present) {
        nl_msg_put_u128(buf, OVS_FLOW_ATTR_UFID, flow->ufid);
    }
    if (flow->ufid_terse) {
        nl_msg_put_u32(buf, OVS_FLOW_ATTR_UFID_FLAGS,
                       OVS_UFID_F_OMIT_KEY | OVS_UFID_F_OMIT_MASK
                       | OVS_UFID_F_OMIT_ACTIONS);
    }
    if (!flow->ufid_terse || !flow->ufid_present) {
        if (flow->key_len) {
            put_exclude_packet_type(buf, OVS_FLOW_ATTR_KEY, flow->key,
                                           flow->key_len);
        }
        if (flow->mask_len) {
            put_exclude_packet_type(buf, OVS_FLOW_ATTR_MASK, flow->mask,
                                           flow->mask_len);
        }
        if (flow->actions || flow->actions_len) {
            nl_msg_put_unspec(buf, OVS_FLOW_ATTR_ACTIONS,
                              flow->actions, flow->actions_len);
        }
    }

    /* We never need to send these to the kernel. */
    ovs_assert(!flow->stats);
    ovs_assert(!flow->tcp_flags);
    ovs_assert(!flow->used);

    if (flow->clear) {
        nl_msg_put_flag(buf, OVS_FLOW_ATTR_CLEAR);
    }
    if (flow->probe) {
        nl_msg_put_flag(buf, OVS_FLOW_ATTR_PROBE);
    }
}

在内核中如何设置这个action到内核流表中呢？

OVS_FLOW_CMD_NEW -> ovs_flow_cmd_new

static int ovs_flow_cmd_new(struct sk_buff *skb, struct genl_info *info)
{
    struct net *net = sock_net(skb->sk);
    struct nlattr **a = info->attrs;
    struct ovs_header *ovs_header = info->userhdr;
    struct sw_flow *flow = NULL, *new_flow;
    struct sw_flow_mask mask;
    struct sk_buff *reply;
    struct datapath *dp;
    struct sw_flow_actions *acts;
    struct sw_flow_match match;
    u32 ufid_flags = ovs_nla_get_ufid_flags(a[OVS_FLOW_ATTR_UFID_FLAGS]);
    int error;
    bool log = !a[OVS_FLOW_ATTR_PROBE];

    /* Must have key and actions. */
    error = -EINVAL;
    if (!a[OVS_FLOW_ATTR_KEY]) {
        OVS_NLERR(log, "Flow key attr not present in new flow.");
        goto error;
    }
    if (!a[OVS_FLOW_ATTR_ACTIONS]) {
        OVS_NLERR(log, "Flow actions attr not present in new flow.");
        goto error;
    }

    /* Most of the time we need to allocate a new flow, do it before
     * locking.
     */
    new_flow = ovs_flow_alloc();
    if (IS_ERR(new_flow)) {
        error = PTR_ERR(new_flow);
        goto error;
    }

    /* Extract key. */
    ovs_match_init(&match, &new_flow->key, false, &mask);
    error = ovs_nla_get_match(net, &match, a[OVS_FLOW_ATTR_KEY],
                  a[OVS_FLOW_ATTR_MASK], log);
    if (error)
        goto err_kfree_flow;

    /* Extract flow identifier. */
    error = ovs_nla_get_identifier(&new_flow->id, a[OVS_FLOW_ATTR_UFID],
                       &new_flow->key, log);
    if (error)
        goto err_kfree_flow;

    /* unmasked key is needed to match when ufid is not used. */
    if (ovs_identifier_is_key(&new_flow->id))
        match.key = new_flow->id.unmasked_key;

    ovs_flow_mask_key(&new_flow->key, &new_flow->key, true, &mask);

    /* Validate actions. */
    error = ovs_nla_copy_actions(net, a[OVS_FLOW_ATTR_ACTIONS],
                     &new_flow->key, &acts, log);
    if (error) {
        OVS_NLERR(log, "Flow actions may not be safe on all matching packets.");
        goto err_kfree_flow;
    }

    reply = ovs_flow_cmd_alloc_info(acts, &new_flow->id, info, false,
                    ufid_flags);
    if (IS_ERR(reply)) {
        error = PTR_ERR(reply);
        goto err_kfree_acts;
    }

    ovs_lock();
    dp = get_dp(net, ovs_header->dp_ifindex);
    if (unlikely(!dp)) {
        error = -ENODEV;
        goto err_unlock_ovs;
    }

    /* Check if this is a duplicate flow */
    if (ovs_identifier_is_ufid(&new_flow->id))
        flow = ovs_flow_tbl_lookup_ufid(&dp->table, &new_flow->id);
    if (!flow)
        flow = ovs_flow_tbl_lookup(&dp->table, &new_flow->key);
    if (likely(!flow)) {
        rcu_assign_pointer(new_flow->sf_acts, acts);

        /* Put flow in bucket. */
        error = ovs_flow_tbl_insert(&dp->table, new_flow, &mask);
        if (unlikely(error)) {
            acts = NULL;
            goto err_unlock_ovs;
        }

        if (unlikely(reply)) {
            error = ovs_flow_cmd_fill_info(new_flow,
                               ovs_header->dp_ifindex,
                               reply, info->snd_portid,
                               info->snd_seq, 0,
                               OVS_FLOW_CMD_NEW,
                               ufid_flags);
            BUG_ON(error < 0);
        }
        ovs_unlock();
    } else {
        struct sw_flow_actions *old_acts;

        /* Bail out if we're not allowed to modify an existing flow.
         * We accept NLM_F_CREATE in place of the intended NLM_F_EXCL
         * because Generic Netlink treats the latter as a dump
         * request.  We also accept NLM_F_EXCL in case that bug ever
         * gets fixed.
         */
        if (unlikely(info->nlhdr->nlmsg_flags & (NLM_F_CREATE
                             | NLM_F_EXCL))) {
            error = -EEXIST;
            goto err_unlock_ovs;
        }
        /* The flow identifier has to be the same for flow updates.
         * Look for any overlapping flow.
         */
        if (unlikely(!ovs_flow_cmp(flow, &match))) {
            if (ovs_identifier_is_key(&flow->id))
                flow = ovs_flow_tbl_lookup_exact(&dp->table,
                                 &match);
            else /* UFID matches but key is different */
                flow = NULL;
            if (!flow) {
                error = -ENOENT;
                goto err_unlock_ovs;
            }
        }
        /* Update actions. */
        old_acts = ovsl_dereference(flow->sf_acts);
        rcu_assign_pointer(flow->sf_acts, acts);

        if (unlikely(reply)) {
            error = ovs_flow_cmd_fill_info(flow,
                               ovs_header->dp_ifindex,
                               reply, info->snd_portid,
                               info->snd_seq, 0,
                               OVS_FLOW_CMD_NEW,
                               ufid_flags);
            BUG_ON(error < 0);
        }
        ovs_unlock();

        ovs_nla_free_flow_actions_rcu(old_acts);
        ovs_flow_free(new_flow, false);
    }

    if (reply)
        ovs_notify(&dp_flow_genl_family, &ovs_dp_flow_multicast_group, reply, info);
    return 0;

err_unlock_ovs:
    ovs_unlock();
    kfree_skb(reply);
err_kfree_acts:
    ovs_nla_free_flow_actions(acts);
err_kfree_flow:
    ovs_flow_free(new_flow, false);
error:
    return error;
}

/* 'key' must be the masked key. */
int ovs_nla_copy_actions(struct net *net, const struct nlattr *attr,
             const struct sw_flow_key *key,
             struct sw_flow_actions **sfa, bool log)
{
    int err;
    u32 mpls_label_count = 0;

    *sfa = nla_alloc_flow_actions(min(nla_len(attr), MAX_ACTIONS_BUFSIZE));
    if (IS_ERR(*sfa))
        return PTR_ERR(*sfa);

    if (eth_p_mpls(key->eth.type))
        mpls_label_count = hweight_long(key->mpls.num_labels_mask);

    (*sfa)->orig_len = nla_len(attr);
    err = __ovs_nla_copy_actions(net, attr, key, sfa, key->eth.type,
                     key->eth.vlan.tci, mpls_label_count, log);
    if (err)
        ovs_nla_free_flow_actions(*sfa);

    return err;
}


static int __ovs_nla_copy_actions(struct net *net, const struct nlattr *attr,
                  const struct sw_flow_key *key,
                  struct sw_flow_actions **sfa,
                  __be16 eth_type, __be16 vlan_tci,
                  u32 mpls_label_count, bool log)
{
    u8 mac_proto = ovs_key_mac_proto(key);
    const struct nlattr *a;
    int rem, err;

    nla_for_each_nested(a, attr, rem) {
        /* Expected argument lengths, (u32)-1 for variable length. */
        static const u32 action_lens[OVS_ACTION_ATTR_MAX + 1] = {
            [OVS_ACTION_ATTR_OUTPUT] = sizeof(u32),
            [OVS_ACTION_ATTR_RECIRC] = sizeof(u32),
            [OVS_ACTION_ATTR_USERSPACE] = (u32)-1,
            [OVS_ACTION_ATTR_PUSH_MPLS] = sizeof(struct ovs_action_push_mpls),
            [OVS_ACTION_ATTR_POP_MPLS] = sizeof(__be16),
            [OVS_ACTION_ATTR_PUSH_VLAN] = sizeof(struct ovs_action_push_vlan),
            [OVS_ACTION_ATTR_POP_VLAN] = 0,
            [OVS_ACTION_ATTR_SET] = (u32)-1,
            [OVS_ACTION_ATTR_SET_MASKED] = (u32)-1,
            [OVS_ACTION_ATTR_SAMPLE] = (u32)-1,
            [OVS_ACTION_ATTR_HASH] = sizeof(struct ovs_action_hash),
            [OVS_ACTION_ATTR_CT] = (u32)-1,
            [OVS_ACTION_ATTR_CT_CLEAR] = 0,
            [OVS_ACTION_ATTR_TRUNC] = sizeof(struct ovs_action_trunc),
            [OVS_ACTION_ATTR_PUSH_ETH] = sizeof(struct ovs_action_push_eth),
            [OVS_ACTION_ATTR_POP_ETH] = 0,
            [OVS_ACTION_ATTR_PUSH_NSH] = (u32)-1,
            [OVS_ACTION_ATTR_POP_NSH] = 0,
            [OVS_ACTION_ATTR_METER] = sizeof(u32),
            [OVS_ACTION_ATTR_CLONE] = (u32)-1,
            [OVS_ACTION_ATTR_CHECK_PKT_LEN] = (u32)-1,
        };
        const struct ovs_action_push_vlan *vlan;
        int type = nla_type(a);
        bool skip_copy;

        if (type > OVS_ACTION_ATTR_MAX ||
            (action_lens[type] != nla_len(a) &&
             action_lens[type] != (u32)-1))
            return -EINVAL;

        skip_copy = false;
        switch (type) {
        case OVS_ACTION_ATTR_UNSPEC:
            return -EINVAL;

        case OVS_ACTION_ATTR_USERSPACE:
            err = validate_userspace(a);
            if (err)
                return err;
            break;

        case OVS_ACTION_ATTR_OUTPUT:
            if (nla_get_u32(a) >= DP_MAX_PORTS)
                return -EINVAL;
            break;

        case OVS_ACTION_ATTR_TRUNC: {
            const struct ovs_action_trunc *trunc = nla_data(a);

            if (trunc->max_len < ETH_HLEN)
                return -EINVAL;
            break;
        }

        case OVS_ACTION_ATTR_HASH: {
            const struct ovs_action_hash *act_hash = nla_data(a);

            switch (act_hash->hash_alg) {
            case OVS_HASH_ALG_L4:
                break;
            default:
                return  -EINVAL;
            }

            break;
        }

        case OVS_ACTION_ATTR_POP_VLAN:
            if (mac_proto != MAC_PROTO_ETHERNET)
                return -EINVAL;
            vlan_tci = htons(0);
            break;

        case OVS_ACTION_ATTR_PUSH_VLAN:
            if (mac_proto != MAC_PROTO_ETHERNET)
                return -EINVAL;
            vlan = nla_data(a);
            if (!eth_type_vlan(vlan->vlan_tpid))
                return -EINVAL;
            if (!(vlan->vlan_tci & htons(VLAN_CFI_MASK)))
                return -EINVAL;
            vlan_tci = vlan->vlan_tci;
            break;

        case OVS_ACTION_ATTR_RECIRC:
            break;

        case OVS_ACTION_ATTR_PUSH_MPLS: {
            const struct ovs_action_push_mpls *mpls = nla_data(a);

            if (!eth_p_mpls(mpls->mpls_ethertype))
                return -EINVAL;
            /* Prohibit push MPLS other than to a white list
             * for packets that have a known tag order.
             */
            if (vlan_tci & htons(VLAN_CFI_MASK) ||
                (eth_type != htons(ETH_P_IP) &&
                 eth_type != htons(ETH_P_IPV6) &&
                 eth_type != htons(ETH_P_ARP) &&
                 eth_type != htons(ETH_P_RARP) &&
                 !eth_p_mpls(eth_type)))
                return -EINVAL;
            eth_type = mpls->mpls_ethertype;
            mpls_label_count++;
            break;
        }

        case OVS_ACTION_ATTR_POP_MPLS: {
            __be16  proto;
            if (vlan_tci & htons(VLAN_CFI_MASK) ||
                !eth_p_mpls(eth_type))
                return -EINVAL;

            /* Disallow subsequent L2.5+ set actions and mpls_pop
             * actions once the last MPLS label in the packet is
             * popped as there is no check here to ensure that
             * the new eth type is valid and thus set actions could
             * write off the end of the packet or otherwise corrupt
             * it.
             *
             * Support for these actions is planned using packet
             * recirculation.
             */
            proto = nla_get_be16(a);
            mpls_label_count--;

            if (!eth_p_mpls(proto) || !mpls_label_count)
                eth_type = htons(0);
            else
                eth_type =  proto;
            break;
        }
        case OVS_ACTION_ATTR_SET:
            err = validate_set(a, key, sfa,
                       &skip_copy, mac_proto, eth_type,
                       false, log);
            if (err)
                return err;
            break;

        case OVS_ACTION_ATTR_SET_MASKED:
            err = validate_set(a, key, sfa,
                       &skip_copy, mac_proto, eth_type,
                       true, log);
            if (err)
                return err;
            break;

        case OVS_ACTION_ATTR_SAMPLE: {
            bool last = nla_is_last(a, rem);

            err = validate_and_copy_sample(net, a, key, sfa,
                               eth_type, vlan_tci,
                               mpls_label_count,
                               log, last);
            if (err)
                return err;
            skip_copy = true;
            break;
        }

        case OVS_ACTION_ATTR_CT:
            err = ovs_ct_copy_action(net, a, key, sfa, log);
            if (err)
                return err;
            skip_copy = true;
            break;

        case OVS_ACTION_ATTR_CT_CLEAR:
            break;

        case OVS_ACTION_ATTR_PUSH_ETH:
            /* Disallow pushing an Ethernet header if one
             * is already present */
            if (mac_proto != MAC_PROTO_NONE)
                return -EINVAL;
            mac_proto = MAC_PROTO_ETHERNET;
            break;

        case OVS_ACTION_ATTR_POP_ETH:
            if (mac_proto != MAC_PROTO_ETHERNET)
                return -EINVAL;
            if (vlan_tci & htons(VLAN_CFI_MASK))
                return -EINVAL;
            mac_proto = MAC_PROTO_NONE;
            break;

        case OVS_ACTION_ATTR_PUSH_NSH:
            if (mac_proto != MAC_PROTO_ETHERNET) {
                u8 next_proto;

                next_proto = tun_p_from_eth_p(eth_type);
                if (!next_proto)
                    return -EINVAL;
            }
            mac_proto = MAC_PROTO_NONE;
            if (!validate_nsh(nla_data(a), false, true, true))
                return -EINVAL;
            break;

        case OVS_ACTION_ATTR_POP_NSH: {
            __be16 inner_proto;

            if (eth_type != htons(ETH_P_NSH))
                return -EINVAL;
            inner_proto = tun_p_to_eth_p(key->nsh.base.np);
            if (!inner_proto)
                return -EINVAL;
            if (key->nsh.base.np == TUN_P_ETHERNET)
                mac_proto = MAC_PROTO_ETHERNET;
            else
                mac_proto = MAC_PROTO_NONE;
            break;
        }

        case OVS_ACTION_ATTR_METER:
            /* Non-existent meters are simply ignored.  */
            break;

        case OVS_ACTION_ATTR_CLONE: {
            bool last = nla_is_last(a, rem);

            err = validate_and_copy_clone(net, a, key, sfa,
                              eth_type, vlan_tci,
                              mpls_label_count,
                              log, last);
            if (err)
                return err;
            skip_copy = true;
            break;
        }

        case OVS_ACTION_ATTR_CHECK_PKT_LEN: {
                        bool last = nla_is_last(a, rem);

                        err = validate_and_copy_check_pkt_len(net, a, key, sfa,
                                                              eth_type,
                                                              vlan_tci, log,
                                  mpls_label_count,
                                                              last);
                        if (err)
                                return err;
                        skip_copy = true;
                        break;
                }

        default:
            OVS_NLERR(log, "Unknown Action type %d", type);
            return -EINVAL;
        }
        if (!skip_copy) {
            err = copy_action(a, sfa, log);
            if (err)
                return err;
        }
    }

    if (rem > 0)
        return -EINVAL;

    return 0;
}

static int __ovs_nla_copy_actions( /*...*/ )
{
    /* ... */
    static const u32 action_lens[OVS_ACTION_ATTR_MAX + 1] = {
        /* ... */
        [OVS_ACTION_ATTR_PROBDROP] = sizeof(u32),
    };
    /* ... */

    /* Be careful here, your compiler may not catch this one
    * even with -Werror */
    switch (type) {
    /* ... */
    case OVS_ACTION_ATTR_PROBDROP:
        /* Finalest sanity checks in the kernel. */
        break;
    /* ... */
    }
    /* ... */
}

OFPACT_SET_ETH_DST在内核中对应的action其实是OVS_ACTION_ATTR_SET_MASKED，是设置一个attr，设置什么attr呢，OVS_KEY_ATTR_ETHERNET，同理可以设置ip，OVS_KEY_ATTR_IPV4

在内核中执行action的时候 do_execute_actions
        case OVS_ACTION_ATTR_SET:
            err = execute_set_action(skb, key, nla_data(a));
            break;
        case OVS_ACTION_ATTR_SET_MASKED:
        case OVS_ACTION_ATTR_SET_TO_MASKED:
            err = execute_masked_set_action(skb, key, nla_data(a));
            break;

static int execute_set_action(struct sk_buff *skb,
                  struct sw_flow_key *flow_key,
                  const struct nlattr *a)
{
    /* Only tunnel set execution is supported without a mask. */
    if (nla_type(a) == OVS_KEY_ATTR_TUNNEL_INFO) {
        struct ovs_tunnel_info *tun = nla_data(a);

        ovs_skb_dst_drop(skb);
        ovs_dst_hold((struct dst_entry *)tun->tun_dst);
        ovs_skb_dst_set(skb, (struct dst_entry *)tun->tun_dst);
        return 0;
    }

    return -EINVAL;
}

/* Mask is at the midpoint of the data. */
#define get_mask(a, type) ((const type)nla_data(a) + 1)

static int execute_masked_set_action(struct sk_buff *skb,
                     struct sw_flow_key *flow_key,
                     const struct nlattr *a)
{
    int err = 0;

    switch (nla_type(a)) {
    case OVS_KEY_ATTR_PRIORITY:
        OVS_SET_MASKED(skb->priority, nla_get_u32(a),
                   *get_mask(a, u32 *));
        flow_key->phy.priority = skb->priority;
        break;

    case OVS_KEY_ATTR_SKB_MARK:
        OVS_SET_MASKED(skb->mark, nla_get_u32(a), *get_mask(a, u32 *));
        flow_key->phy.skb_mark = skb->mark;
        break;

    case OVS_KEY_ATTR_TUNNEL_INFO:
        /* Masked data not supported for tunnel. */
        err = -EINVAL;
        break;

    case OVS_KEY_ATTR_ETHERNET:
        err = set_eth_addr(skb, flow_key, nla_data(a),
                   get_mask(a, struct ovs_key_ethernet *));
        break;

    case OVS_KEY_ATTR_NSH:
        err = set_nsh(skb, flow_key, a);
        break;

    case OVS_KEY_ATTR_IPV4:
        err = set_ipv4(skb, flow_key, nla_data(a),
                   get_mask(a, struct ovs_key_ipv4 *));
        break;

    case OVS_KEY_ATTR_IPV6:
        err = set_ipv6(skb, flow_key, nla_data(a),
                   get_mask(a, struct ovs_key_ipv6 *));
        break;

    case OVS_KEY_ATTR_TCP:
        err = set_tcp(skb, flow_key, nla_data(a),
                  get_mask(a, struct ovs_key_tcp *));
        break;

    case OVS_KEY_ATTR_UDP:
        err = set_udp(skb, flow_key, nla_data(a),
                  get_mask(a, struct ovs_key_udp *));
        break;

    case OVS_KEY_ATTR_SCTP:
        err = set_sctp(skb, flow_key, nla_data(a),
                   get_mask(a, struct ovs_key_sctp *));
        break;

    case OVS_KEY_ATTR_MPLS:
        err = set_mpls(skb, flow_key, nla_data(a), get_mask(a,
                                    __be32 *));
        break;

    case OVS_KEY_ATTR_CT_STATE:
    case OVS_KEY_ATTR_CT_ZONE:
    case OVS_KEY_ATTR_CT_MARK:
    case OVS_KEY_ATTR_CT_LABELS:
    case OVS_KEY_ATTR_CT_ORIG_TUPLE_IPV4:
    case OVS_KEY_ATTR_CT_ORIG_TUPLE_IPV6:
        err = -EINVAL;
        break;
    }

    return err;
}

-------------------------

/* Put this with the other "compose" functions. */
static void
compose_probdrop_action(struct xlate_ctx *ctx, struct ofpact_probdrop *op)
{
    uint32_t prob = op->prob;

    nl_msg_put_u32(ctx->odp_actions, OVS_ACTION_ATTR_PROBDROP, prob);
}

/* ... */

static void
do_xlate_actions( /* ... */ )
{
    switch (a->type) {
    /* ... */

    case OFPACT_PROBDROP:
        compose_probdrop_action(ctx, ofpact_get_PROBDROP(a));
        break;
    }
}
/* ... */

/* No action can undo the packet drop: reflect this. */
static bool
reversible_actions(const struct ofpact *ofpacts, size_t ofpacts_len)
{
    const struct ofpact *a;

    OFPACT_FOR_EACH (a, ofpacts, ofpacts_len) {
        switch (a->type) {
        /*... */
        case OFPACT_PROBDROP:
            return false;
        }
    }
    return true;
}

/* ... */

/* PROBDROP likely doesn't require explicit thawing. */
static void
freeze_unroll_actions( /* ... */ )
{
    /* ... */
    switch (a->type) {
        case OFPACT_PROBDROP:
            /* These may not generate PACKET INs. */
            break;
    }
}

/* ... */

/* Naturally, don't need to recirculate since we don't change packets. */
static void
recirc_for_mpls(const struct ofpact *a, struct xlate_ctx *ctx)
{
    /* ... */

    switch (a->type) {
    case OFPACT_PROBDROP:
    default:
        break;
    }
}

static void
do_xlate_actions(const struct ofpact *ofpacts, size_t ofpacts_len,
                 struct xlate_ctx *ctx, bool is_last_action,
                 bool group_bucket_action)
{
    struct flow_wildcards *wc = ctx->wc;
    struct flow *flow = &ctx->xin->flow;
    const struct ofpact *a;

    /* dl_type already in the mask, not set below. */

    if (!ofpacts_len) {
        xlate_report(ctx, OFT_ACTION, "drop");
        return;
    }

    OFPACT_FOR_EACH (a, ofpacts, ofpacts_len) {
        struct ofpact_controller *controller;
        const struct ofpact_metadata *metadata;
        const struct ofpact_set_field *set_field;
        const struct mf_field *mf;
        bool last = is_last_action && ofpact_last(a, ofpacts, ofpacts_len)
                    && ctx->action_set.size;

        if (ctx->error) {
            break;
        }

        recirc_for_mpls(a, ctx);

        if (ctx->exit) {
            /* Check if need to store the remaining actions for later
             * execution. */
            if (ctx->freezing) {
                freeze_unroll_actions(a, ofpact_end(ofpacts, ofpacts_len),
                                      ctx);
            }
            break;
        }

        if (OVS_UNLIKELY(ctx->xin->trace)) {
            struct ds s = DS_EMPTY_INITIALIZER;
            struct ofpact_format_params fp = { .s = &s };
            ofpacts_format(a, OFPACT_ALIGN(a->len), &fp);
            xlate_report(ctx, OFT_ACTION, "%s", ds_cstr(&s));
            ds_destroy(&s);
        }

        switch (a->type) {
        case OFPACT_OUTPUT:
            xlate_output_action(ctx, ofpact_get_OUTPUT(a)->port,
                                ofpact_get_OUTPUT(a)->max_len, true, last,
                                false, group_bucket_action);
            break;

        case OFPACT_GROUP:
            if (xlate_group_action(ctx, ofpact_get_GROUP(a)->group_id, last)) {
                /* Group could not be found. */

                /* XXX: Terminates action list translation, but does not
                 * terminate the pipeline. */
                return;
            }
            break;

        case OFPACT_CONTROLLER:
            controller = ofpact_get_CONTROLLER(a);
            if (controller->pause) {
                ctx->pause = controller;
                ctx_trigger_freeze(ctx);
                a = ofpact_next(a);
            } else {
                xlate_controller_action(ctx, controller->max_len,
                                        controller->reason,
                                        controller->controller_id,
                                        controller->provider_meter_id,
                                        controller->userdata,
                                        controller->userdata_len);
            }
            break;

        case OFPACT_ENQUEUE:
            memset(&wc->masks.skb_priority, 0xff,
                   sizeof wc->masks.skb_priority);
            xlate_enqueue_action(ctx, ofpact_get_ENQUEUE(a), last,
                                 group_bucket_action);
            break;

        case OFPACT_SET_VLAN_VID:
            wc->masks.vlans[0].tci |= htons(VLAN_VID_MASK | VLAN_CFI);
            if (flow->vlans[0].tci & htons(VLAN_CFI) ||
                ofpact_get_SET_VLAN_VID(a)->push_vlan_if_needed) {
                if (!flow->vlans[0].tpid) {
                    flow->vlans[0].tpid = htons(ETH_TYPE_VLAN);
                }
                flow->vlans[0].tci &= ~htons(VLAN_VID_MASK);
                flow->vlans[0].tci |=
                    (htons(ofpact_get_SET_VLAN_VID(a)->vlan_vid) |
                     htons(VLAN_CFI));
            }
            break;

        case OFPACT_SET_VLAN_PCP:
            wc->masks.vlans[0].tci |= htons(VLAN_PCP_MASK | VLAN_CFI);
            if (flow->vlans[0].tci & htons(VLAN_CFI) ||
                ofpact_get_SET_VLAN_PCP(a)->push_vlan_if_needed) {
                if (!flow->vlans[0].tpid) {
                    flow->vlans[0].tpid = htons(ETH_TYPE_VLAN);
                }
                flow->vlans[0].tci &= ~htons(VLAN_PCP_MASK);
                flow->vlans[0].tci |=
                    htons((ofpact_get_SET_VLAN_PCP(a)->vlan_pcp
                           << VLAN_PCP_SHIFT) | VLAN_CFI);
            }
            break;

        case OFPACT_STRIP_VLAN:
            flow_pop_vlan(flow, wc);
            break;

        case OFPACT_PUSH_VLAN:
            flow_push_vlan_uninit(flow, wc);
            flow->vlans[0].tpid = ofpact_get_PUSH_VLAN(a)->ethertype;
            flow->vlans[0].tci = htons(VLAN_CFI);
            break;

        case OFPACT_SET_ETH_SRC:
            WC_MASK_FIELD(wc, dl_src);
            flow->dl_src = ofpact_get_SET_ETH_SRC(a)->mac;
            break;

        case OFPACT_SET_ETH_DST:
            WC_MASK_FIELD(wc, dl_dst);
            flow->dl_dst = ofpact_get_SET_ETH_DST(a)->mac;
            break;

        case OFPACT_SET_IPV4_SRC:
            if (flow->dl_type == htons(ETH_TYPE_IP)) {
                memset(&wc->masks.nw_src, 0xff, sizeof wc->masks.nw_src);
                flow->nw_src = ofpact_get_SET_IPV4_SRC(a)->ipv4;
            }
            break;

        case OFPACT_SET_IPV4_DST:
            if (flow->dl_type == htons(ETH_TYPE_IP)) {
                memset(&wc->masks.nw_dst, 0xff, sizeof wc->masks.nw_dst);
                flow->nw_dst = ofpact_get_SET_IPV4_DST(a)->ipv4;
            }
            break;

        case OFPACT_SET_IP_DSCP:
            if (is_ip_any(flow)) {
                wc->masks.nw_tos |= IP_DSCP_MASK;
                flow->nw_tos &= ~IP_DSCP_MASK;
                flow->nw_tos |= ofpact_get_SET_IP_DSCP(a)->dscp;
            }
            break;

        case OFPACT_SET_IP_ECN:
            if (is_ip_any(flow)) {
                wc->masks.nw_tos |= IP_ECN_MASK;
                flow->nw_tos &= ~IP_ECN_MASK;
                flow->nw_tos |= ofpact_get_SET_IP_ECN(a)->ecn;
            }
            break;

        case OFPACT_SET_IP_TTL:
            if (is_ip_any(flow)) {
                wc->masks.nw_ttl = 0xff;
                flow->nw_ttl = ofpact_get_SET_IP_TTL(a)->ttl;
            }
            break;

        case OFPACT_SET_L4_SRC_PORT:
            if (is_ip_any(flow) && !(flow->nw_frag & FLOW_NW_FRAG_LATER)) {
                memset(&wc->masks.nw_proto, 0xff, sizeof wc->masks.nw_proto);
                memset(&wc->masks.tp_src, 0xff, sizeof wc->masks.tp_src);
                flow->tp_src = htons(ofpact_get_SET_L4_SRC_PORT(a)->port);
            }
            break;

        case OFPACT_SET_L4_DST_PORT:
            if (is_ip_any(flow) && !(flow->nw_frag & FLOW_NW_FRAG_LATER)) {
                memset(&wc->masks.nw_proto, 0xff, sizeof wc->masks.nw_proto);
                memset(&wc->masks.tp_dst, 0xff, sizeof wc->masks.tp_dst);
                flow->tp_dst = htons(ofpact_get_SET_L4_DST_PORT(a)->port);
            }
            break;

        case OFPACT_RESUBMIT:
            /* Freezing complicates resubmit.  Some action in the flow
             * entry found by resubmit might trigger freezing.  If that
             * happens, then we do not want to execute the resubmit again after
             * during thawing, so we want to skip back to the head of the loop
             * to avoid that, only adding any actions that follow the resubmit
             * to the frozen actions.
             */
            xlate_ofpact_resubmit(ctx, ofpact_get_RESUBMIT(a), last);
            continue;

        case OFPACT_SET_TUNNEL:
            flow->tunnel.tun_id = htonll(ofpact_get_SET_TUNNEL(a)->tun_id);
            break;

        case OFPACT_SET_QUEUE:
            memset(&wc->masks.skb_priority, 0xff,
                   sizeof wc->masks.skb_priority);
            xlate_set_queue_action(ctx, ofpact_get_SET_QUEUE(a)->queue_id);
            break;

        case OFPACT_POP_QUEUE:
            memset(&wc->masks.skb_priority, 0xff,
                   sizeof wc->masks.skb_priority);
            if (flow->skb_priority != ctx->orig_skb_priority) {
                flow->skb_priority = ctx->orig_skb_priority;
                xlate_report(ctx, OFT_DETAIL, "queue = %#"PRIx32,
                             flow->skb_priority);
            }
            break;

        case OFPACT_REG_MOVE:
            xlate_ofpact_reg_move(ctx, ofpact_get_REG_MOVE(a));
            break;

        case OFPACT_SET_FIELD:
            set_field = ofpact_get_SET_FIELD(a);
            mf = set_field->field;

            /* Set the field only if the packet actually has it. */
            if (mf_are_prereqs_ok(mf, flow, wc)) {
                mf_mask_field_masked(mf, ofpact_set_field_mask(set_field), wc);
                mf_set_flow_value_masked(mf, set_field->value,
                                         ofpact_set_field_mask(set_field),
                                         flow);
            } else {
                xlate_report(ctx, OFT_WARN,
                             "unmet prerequisites for %s, set_field ignored",
                             mf->name);

            }
            break;

        case OFPACT_STACK_PUSH:
            nxm_execute_stack_push(ofpact_get_STACK_PUSH(a), flow, wc,
                                   &ctx->stack);
            break;

        case OFPACT_STACK_POP:
            xlate_ofpact_stack_pop(ctx, ofpact_get_STACK_POP(a));
            break;

        case OFPACT_PUSH_MPLS:
            compose_mpls_push_action(ctx, ofpact_get_PUSH_MPLS(a));
            break;

        case OFPACT_POP_MPLS:
            compose_mpls_pop_action(ctx, ofpact_get_POP_MPLS(a)->ethertype);
            break;

        case OFPACT_SET_MPLS_LABEL:
            compose_set_mpls_label_action(
                ctx, ofpact_get_SET_MPLS_LABEL(a)->label);
            break;

        case OFPACT_SET_MPLS_TC:
            compose_set_mpls_tc_action(ctx, ofpact_get_SET_MPLS_TC(a)->tc);
            break;

        case OFPACT_SET_MPLS_TTL:
            compose_set_mpls_ttl_action(ctx, ofpact_get_SET_MPLS_TTL(a)->ttl);
            break;

        case OFPACT_DEC_MPLS_TTL:
            if (compose_dec_mpls_ttl_action(ctx)) {
                return;
            }
            break;

        case OFPACT_DEC_NSH_TTL:
            if (compose_dec_nsh_ttl_action(ctx)) {
                return;
            }
            break;

        case OFPACT_DEC_TTL:
            wc->masks.nw_ttl = 0xff;
            if (compose_dec_ttl(ctx, ofpact_get_DEC_TTL(a))) {
                return;
            }
            break;

        case OFPACT_NOTE:
            /* Nothing to do. */
            break;

        case OFPACT_MULTIPATH:
            multipath_execute(ofpact_get_MULTIPATH(a), flow, wc);
            xlate_report_subfield(ctx, &ofpact_get_MULTIPATH(a)->dst);
            break;

        case OFPACT_BUNDLE:
            xlate_bundle_action(ctx, ofpact_get_BUNDLE(a), last,
                                group_bucket_action);
            break;

        case OFPACT_OUTPUT_REG:
            xlate_output_reg_action(ctx, ofpact_get_OUTPUT_REG(a), last,
                    group_bucket_action);
            break;

        case OFPACT_OUTPUT_TRUNC:
            xlate_output_trunc_action(ctx, ofpact_get_OUTPUT_TRUNC(a)->port,
                                ofpact_get_OUTPUT_TRUNC(a)->max_len, last,
                                group_bucket_action);
            break;

        case OFPACT_LEARN:
            xlate_learn_action(ctx, ofpact_get_LEARN(a));
            break;

        case OFPACT_CONJUNCTION:
            /* A flow with a "conjunction" action represents part of a special
             * kind of "set membership match".  Such a flow should not actually
             * get executed, but it could via, say, a "packet-out", even though
             * that wouldn't be useful.  Log it to help debugging. */
            xlate_report_error(ctx, "executing no-op conjunction action");
            break;

        case OFPACT_EXIT:
            ctx->exit = true;
            break;

        case OFPACT_UNROLL_XLATE:
            xlate_ofpact_unroll_xlate(ctx, ofpact_get_UNROLL_XLATE(a));
            break;

        case OFPACT_FIN_TIMEOUT:
            memset(&wc->masks.nw_proto, 0xff, sizeof wc->masks.nw_proto);
            xlate_fin_timeout(ctx, ofpact_get_FIN_TIMEOUT(a));
            break;

        case OFPACT_DELETE_FIELD:
            xlate_delete_field(ctx, flow, ofpact_get_DELETE_FIELD(a));
            break;

        case OFPACT_CLEAR_ACTIONS:
            xlate_report_action_set(ctx, "was");
            ofpbuf_clear(&ctx->action_set);
            ctx->xin->flow.actset_output = OFPP_UNSET;
            ctx->action_set_has_group = false;
            break;

        case OFPACT_WRITE_ACTIONS:
            xlate_write_actions(ctx, ofpact_get_WRITE_ACTIONS(a));
            xlate_report_action_set(ctx, "is");
            break;

        case OFPACT_WRITE_METADATA:
            metadata = ofpact_get_WRITE_METADATA(a);
            flow->metadata &= ~metadata->mask;
            flow->metadata |= metadata->metadata & metadata->mask;
            break;

        case OFPACT_METER:
            xlate_meter_action(ctx, ofpact_get_METER(a));
            break;

        case OFPACT_GOTO_TABLE: {
            struct ofpact_goto_table *ogt = ofpact_get_GOTO_TABLE(a);

            ovs_assert(ctx->table_id < ogt->table_id);

            xlate_table_action(ctx, ctx->xin->flow.in_port.ofp_port,
                               ogt->table_id, true, true, false, last,
                               do_xlate_actions);
            break;
        }

        case OFPACT_SAMPLE:
            xlate_sample_action(ctx, ofpact_get_SAMPLE(a));
            break;

        case OFPACT_CLONE:
            compose_clone(ctx, ofpact_get_CLONE(a), last);
            break;

        case OFPACT_ENCAP:
            xlate_generic_encap_action(ctx, ofpact_get_ENCAP(a));
            break;

        case OFPACT_DECAP: {
            bool recirc_needed =
                    xlate_generic_decap_action(ctx, ofpact_get_DECAP(a));
            if (!ctx->error && recirc_needed) {
                /* Recirculate for parsing of inner packet. */
                ctx_trigger_freeze(ctx);
                /* Then continue with next action. */
                a = ofpact_next(a);
            }
            break;
        }

        case OFPACT_CT:
            compose_conntrack_action(ctx, ofpact_get_CT(a), last);
            break;

        case OFPACT_CT_CLEAR:
            compose_ct_clear_action(ctx);
            break;

        case OFPACT_NAT:
            /* This will be processed by compose_conntrack_action(). */
            ctx->ct_nat_action = ofpact_get_NAT(a);
            break;

        case OFPACT_DEBUG_RECIRC:
            ctx_trigger_freeze(ctx);
            a = ofpact_next(a);
            break;

        case OFPACT_DEBUG_SLOW:
            ctx->xout->slow |= SLOW_ACTION;
            break;

        case OFPACT_CHECK_PKT_LARGER: {
            if (last) {
                /* If this is last action, then there is no need to
                 * translate the action. */
                break;
            }
            const struct ofpact *remaining_acts = ofpact_next(a);
            size_t remaining_acts_len = ofpact_remaining_len(remaining_acts,
                                                             ofpacts,
                                                             ofpacts_len);
            xlate_check_pkt_larger(ctx, ofpact_get_CHECK_PKT_LARGER(a),
                                   remaining_acts, remaining_acts_len);
            break;
        }
        }

        /* Check if need to store this and the remaining actions for later
         * execution. */
        if (!ctx->error && ctx->exit && ctx_first_frozen_action(ctx)) {
            freeze_unroll_actions(a, ofpact_end(ofpacts, ofpacts_len), ctx);
            break;
        }
    }
}

------------
        case OFPACT_OUTPUT:
            xlate_output_action(ctx, ofpact_get_OUTPUT(a)->port,
                                ofpact_get_OUTPUT(a)->max_len, true, last,
                                false, group_bucket_action);

/* Emits an action that outputs to 'port', within 'ctx'.
 *
 * 'controller_len' affects only packets sent to an OpenFlow controller.  It
 * is the maximum number of bytes of the packet to send.  UINT16_MAX means to
 * send the whole packet (and 0 means to omit the packet entirely).
 *
 * 'may_packet_in' determines whether the packet may be sent to an OpenFlow
 * controller.  If it is false, then the packet is never sent to the OpenFlow
 * controller.
 *
 * 'is_last_action' should be true if this output is the last OpenFlow action
 * to be processed, which enables certain optimizations.
 *
 * 'truncate' should be true if the packet to be output is being truncated,
 * which suppresses certain optimizations. */
static void
xlate_output_action(struct xlate_ctx *ctx, ofp_port_t port,
                    uint16_t controller_len, bool may_packet_in,
                    bool is_last_action, bool truncate,
                    bool group_bucket_action)
{
    ofp_port_t prev_nf_output_iface = ctx->nf_output_iface;

    ctx->nf_output_iface = NF_OUT_DROP;

    switch (port) {
    case OFPP_IN_PORT:
        compose_output_action(ctx, ctx->xin->flow.in_port.ofp_port, NULL,
                              is_last_action, truncate);
        break;
    case OFPP_TABLE:
        xlate_table_action(ctx, ctx->xin->flow.in_port.ofp_port,
                           0, may_packet_in, true, false, false,
                           do_xlate_actions);
        break;
    case OFPP_NORMAL:
        xlate_normal(ctx);
        break;
    case OFPP_FLOOD:
        flood_packets(ctx, false, is_last_action);
        break;
    case OFPP_ALL:
        flood_packets(ctx, true, is_last_action);
        break;
    case OFPP_CONTROLLER:
        xlate_controller_action(ctx, controller_len,
                                (ctx->in_packet_out ? OFPR_PACKET_OUT
                                 : group_bucket_action ? OFPR_GROUP
                                 : ctx->in_action_set ? OFPR_ACTION_SET
                                 : OFPR_ACTION),
                                0, UINT32_MAX, NULL, 0);
        break;
    case OFPP_NONE:
        break;
    case OFPP_LOCAL:
    default:
        if (port != ctx->xin->flow.in_port.ofp_port) {
            compose_output_action(ctx, port, NULL, is_last_action, truncate);
        } else {
            xlate_report_info(ctx, "skipping output to input port");
        }
        break;
    }

    if (prev_nf_output_iface == NF_OUT_FLOOD) {
        ctx->nf_output_iface = NF_OUT_FLOOD;
    } else if (ctx->nf_output_iface == NF_OUT_DROP) {
        ctx->nf_output_iface = prev_nf_output_iface;
    } else if (prev_nf_output_iface != NF_OUT_DROP &&
               ctx->nf_output_iface != NF_OUT_FLOOD) {
        ctx->nf_output_iface = NF_OUT_MULTI;
    }
}

#define OFPP_MAX        OFP_PORT_C(0xff00) /* Max # of switch ports. */
#define OFPP_FIRST_RESV OFP_PORT_C(0xfff7) /* First assigned reserved port. */
#define OFPP_LAST_RESV  OFP_PORT_C(0xffff) /* Last assigned reserved port. */

/* Reserved output "ports". */
#define OFPP_UNSET      OFP_PORT_C(0xfff7) /* For OXM_OF_ACTSET_OUTPUT only. */
#define OFPP_IN_PORT    OFP_PORT_C(0xfff8) /* Where the packet came in. */
#define OFPP_TABLE      OFP_PORT_C(0xfff9) /* Perform actions in flow table. */
#define OFPP_NORMAL     OFP_PORT_C(0xfffa) /* Process with normal L2/L3. */
#define OFPP_FLOOD      OFP_PORT_C(0xfffb) /* All ports except input port and
                                            * ports disabled by STP. */
#define OFPP_ALL        OFP_PORT_C(0xfffc) /* All ports except input port. */
#define OFPP_CONTROLLER OFP_PORT_C(0xfffd) /* Send to controller. */
#define OFPP_LOCAL      OFP_PORT_C(0xfffe) /* Local openflow "port". */
#define OFPP_NONE       OFP_PORT_C(0xffff) /* Not associated with any port. */


static void
xlate_normal(struct xlate_ctx *ctx)
{
    struct flow_wildcards *wc = ctx->wc;
    struct flow *flow = &ctx->xin->flow;
    struct xbundle *in_xbundle;
    struct xport *in_port;
    struct mac_entry *mac;
    void *mac_port;
    struct xvlan in_xvlan;
    struct xvlan xvlan;
    uint16_t vlan;

    memset(&wc->masks.dl_src, 0xff, sizeof wc->masks.dl_src);
    memset(&wc->masks.dl_dst, 0xff, sizeof wc->masks.dl_dst);
    wc->masks.vlans[0].tci |= htons(VLAN_VID_MASK | VLAN_CFI);

    in_xbundle = lookup_input_bundle(ctx, flow->in_port.ofp_port, &in_port);
    if (!in_xbundle) {
        xlate_report(ctx, OFT_WARN, "no input bundle, dropping");
        return;
    }

    /* Drop malformed frames. */
    if (eth_type_vlan(flow->dl_type) &&
        !(flow->vlans[0].tci & htons(VLAN_CFI))) {
        if (ctx->xin->packet != NULL) {
            xlate_report_error(ctx, "dropping packet with partial "
                               "VLAN tag received on port %s",
                               in_xbundle->name);
        }
        xlate_report(ctx, OFT_WARN, "partial VLAN tag, dropping");
        return;
    }

    /* Drop frames on bundles reserved for mirroring. */
    if (xbundle_mirror_out(ctx->xbridge, in_xbundle)) {
        if (ctx->xin->packet != NULL) {
            xlate_report_error(ctx, "dropping packet received on port %s, "
                               "which is reserved exclusively for mirroring",
                               in_xbundle->name);
        }
        xlate_report(ctx, OFT_WARN,
                     "input port is mirror output port, dropping");
        return;
    }

    /* Check VLAN. */
    xvlan_extract(flow, &in_xvlan);
    if (!input_vid_is_valid(ctx, in_xvlan.v[0].vid, in_xbundle)) {
        xlate_report(ctx, OFT_WARN,
                     "disallowed VLAN VID for this input port, dropping");
        return;
    }
    xvlan_input_translate(in_xbundle, &in_xvlan, &xvlan);
    vlan = xvlan.v[0].vid;

    /* Check other admissibility requirements. */
    if (in_port && !is_admissible(ctx, in_port, vlan)) {
        return;
    }

    /* Learn source MAC. */
    bool is_grat_arp = is_gratuitous_arp(flow, wc);
    if (ctx->xin->allow_side_effects
        && flow->packet_type == htonl(PT_ETH)
        && in_port->pt_mode != NETDEV_PT_LEGACY_L3
    ) {
        update_learning_table(ctx, in_xbundle, flow->dl_src, vlan,
                              is_grat_arp);
    }
    if (ctx->xin->xcache && in_xbundle != &ofpp_none_bundle) {
        struct xc_entry *entry;

        /* Save just enough info to update mac learning table later. */
        entry = xlate_cache_add_entry(ctx->xin->xcache, XC_NORMAL);
        entry->normal.ofproto = ctx->xbridge->ofproto;
        entry->normal.in_port = flow->in_port.ofp_port;
        entry->normal.dl_src = flow->dl_src;
        entry->normal.vlan = vlan;
        entry->normal.is_gratuitous_arp = is_grat_arp;
    }

    /* Determine output bundle. */
    if (mcast_snooping_enabled(ctx->xbridge->ms)
        && !eth_addr_is_broadcast(flow->dl_dst)
        && eth_addr_is_multicast(flow->dl_dst)
        && is_ip_any(flow)) {
        struct mcast_snooping *ms = ctx->xbridge->ms;
        struct mcast_group *grp = NULL;

        if (is_igmp(flow, wc)) {
            /*
             * IGMP packets need to take the slow path, in order to be
             * processed for mdb updates. That will prevent expires
             * firing off even after hosts have sent reports.
             */
            ctx->xout->slow |= SLOW_ACTION;

            memset(&wc->masks.tp_src, 0xff, sizeof wc->masks.tp_src);
            if (mcast_snooping_is_membership(flow->tp_src) ||
                mcast_snooping_is_query(flow->tp_src)) {
                if (ctx->xin->allow_side_effects && ctx->xin->packet) {
                    update_mcast_snooping_table(ctx, flow, vlan,
                                                in_xbundle, ctx->xin->packet);
                }
            }

            if (mcast_snooping_is_membership(flow->tp_src)) {
                struct mcast_output out = MCAST_OUTPUT_INIT;

                ovs_rwlock_rdlock(&ms->rwlock);
                xlate_normal_mcast_send_mrouters(ctx, ms, in_xbundle, &xvlan,
                                                 &out);
                /* RFC4541: section 2.1.1, item 1: A snooping switch should
                 * forward IGMP Membership Reports only to those ports where
                 * multicast routers are attached.  Alternatively stated: a
                 * snooping switch should not forward IGMP Membership Reports
                 * to ports on which only hosts are attached.
                 * An administrative control may be provided to override this
                 * restriction, allowing the report messages to be flooded to
                 * other ports. */
                xlate_normal_mcast_send_rports(ctx, ms, in_xbundle, &out);
                ovs_rwlock_unlock(&ms->rwlock);

                mcast_output_finish(ctx, &out, in_xbundle, &xvlan);
            } else {
                xlate_report(ctx, OFT_DETAIL, "multicast traffic, flooding");
                xlate_normal_flood(ctx, in_xbundle, &xvlan);
            }
            return;
        } else if (is_mld(flow, wc)) {
            ctx->xout->slow |= SLOW_ACTION;
            if (ctx->xin->allow_side_effects && ctx->xin->packet) {
                update_mcast_snooping_table(ctx, flow, vlan,
                                            in_xbundle, ctx->xin->packet);
            }
            if (is_mld_report(flow, wc)) {
                struct mcast_output out = MCAST_OUTPUT_INIT;

                ovs_rwlock_rdlock(&ms->rwlock);
                xlate_normal_mcast_send_mrouters(ctx, ms, in_xbundle, &xvlan,
                                                 &out);
                xlate_normal_mcast_send_rports(ctx, ms, in_xbundle, &out);
                ovs_rwlock_unlock(&ms->rwlock);

                mcast_output_finish(ctx, &out, in_xbundle, &xvlan);
            } else {
                xlate_report(ctx, OFT_DETAIL, "MLD query, flooding");
                xlate_normal_flood(ctx, in_xbundle, &xvlan);
            }
            return;
        } else {
            if (is_ip_local_multicast(flow, wc)) {
                /* RFC4541: section 2.1.2, item 2: Packets with a dst IP
                 * address in the 224.0.0.x range which are not IGMP must
                 * be forwarded on all ports */
                xlate_report(ctx, OFT_DETAIL,
                             "RFC4541: section 2.1.2, item 2, flooding");
                xlate_normal_flood(ctx, in_xbundle, &xvlan);
                return;
            }
        }

        /* forwarding to group base ports */
        struct mcast_output out = MCAST_OUTPUT_INIT;

        ovs_rwlock_rdlock(&ms->rwlock);
        if (flow->dl_type == htons(ETH_TYPE_IP)) {
            grp = mcast_snooping_lookup4(ms, flow->nw_dst, vlan);
        } else if (flow->dl_type == htons(ETH_TYPE_IPV6)) {
            grp = mcast_snooping_lookup(ms, &flow->ipv6_dst, vlan);
        }
        if (grp) {
            xlate_normal_mcast_send_group(ctx, ms, grp, in_xbundle, &out);
            xlate_normal_mcast_send_fports(ctx, ms, in_xbundle, &out);
            xlate_normal_mcast_send_mrouters(ctx, ms, in_xbundle, &xvlan,
                                             &out);
        } else {
            if (mcast_snooping_flood_unreg(ms)) {
                xlate_report(ctx, OFT_DETAIL,
                             "unregistered multicast, flooding");
                out.flood = true;
            } else {
                xlate_normal_mcast_send_mrouters(ctx, ms, in_xbundle, &xvlan,
                                                 &out);
                xlate_normal_mcast_send_fports(ctx, ms, in_xbundle, &out);
            }
        }
        ovs_rwlock_unlock(&ms->rwlock);

        mcast_output_finish(ctx, &out, in_xbundle, &xvlan);
    } else {
        ovs_rwlock_rdlock(&ctx->xbridge->ml->rwlock);
        mac = mac_learning_lookup(ctx->xbridge->ml, flow->dl_dst, vlan);
        mac_port = mac ? mac_entry_get_port(ctx->xbridge->ml, mac) : NULL;
        ovs_rwlock_unlock(&ctx->xbridge->ml->rwlock);

        if (mac_port) {
            struct xbundle *mac_xbundle = xbundle_lookup(ctx->xcfg, mac_port);

            if (mac_xbundle && xbundle_mirror_out(ctx->xbridge, mac_xbundle)) {
                xlate_report(ctx, OFT_WARN,
                             "learned port is a mirror port, dropping");
                return;
            }

            if (mac_xbundle
                && mac_xbundle != in_xbundle
                && mac_xbundle->ofbundle != in_xbundle->ofbundle) {
                xlate_report(ctx, OFT_DETAIL, "forwarding to learned port");
                output_normal(ctx, mac_xbundle, &xvlan);
            } else if (!mac_xbundle) {
                xlate_report(ctx, OFT_WARN,
                             "learned port is unknown, dropping");
            } else {
                xlate_report(ctx, OFT_DETAIL,
                             "learned port is input port, dropping");
            }
        } else {
            xlate_report(ctx, OFT_DETAIL,
                         "no learned MAC for destination, flooding");
            xlate_normal_flood(ctx, in_xbundle, &xvlan);
        }
    }
}

static void
output_normal(struct xlate_ctx *ctx, const struct xbundle *out_xbundle,
              const struct xvlan *xvlan)
{
    uint16_t vid;
    union flow_vlan_hdr old_vlans[FLOW_MAX_VLAN_HEADERS];
    struct xport *xport;
    struct xlate_bond_recirc xr;
    bool use_recirc = false;
    struct xvlan out_xvlan;

    check_and_set_cvlan_mask(ctx->wc, out_xbundle);

    xvlan_output_translate(out_xbundle, xvlan, &out_xvlan);
    if (out_xbundle->use_priority_tags) {
        out_xvlan.v[0].pcp = ntohs(ctx->xin->flow.vlans[0].tci) &
                             VLAN_PCP_MASK;
    }
    vid = out_xvlan.v[0].vid;
    if (ovs_list_is_empty(&out_xbundle->xports)) {
        /* Partially configured bundle with no slaves.  Drop the packet. */
        return;
    } else if (!out_xbundle->bond) {
        xport = CONTAINER_OF(ovs_list_front(&out_xbundle->xports), struct xport,
                             bundle_node);
    } else {
        struct flow_wildcards *wc = ctx->wc;
        struct ofport_dpif *ofport;

        if (ctx->xbridge->support.odp.recirc) {
            /* In case recirculation is not actually in use, 'xr.recirc_id'
             * will be set to '0', since a valid 'recirc_id' can
             * not be zero.  */
            bond_update_post_recirc_rules(out_xbundle->bond,
                                          &xr.recirc_id,
                                          &xr.hash_basis);
            if (xr.recirc_id) {
                /* Use recirculation instead of output. */
                use_recirc = true;
                xr.hash_alg = OVS_HASH_ALG_L4;
                /* Recirculation does not require unmasking hash fields. */
                wc = NULL;
            }
        }

        ofport = bond_choose_output_slave(out_xbundle->bond,
                                          &ctx->xin->flow, wc, vid);
        xport = xport_lookup(ctx->xcfg, ofport);

        if (!xport) {
            /* No slaves enabled, so drop packet. */
            return;
        }

        /* If use_recirc is set, the main thread will handle stats
         * accounting for this bond. */
        if (!use_recirc) {
            if (ctx->xin->resubmit_stats) {
                bond_account(out_xbundle->bond, &ctx->xin->flow, vid,
                             ctx->xin->resubmit_stats->n_bytes);
            }
            if (ctx->xin->xcache) {
                struct xc_entry *entry;
                struct flow *flow;

                flow = &ctx->xin->flow;
                entry = xlate_cache_add_entry(ctx->xin->xcache, XC_BOND);
                entry->bond.bond = bond_ref(out_xbundle->bond);
                entry->bond.flow = xmemdup(flow, sizeof *flow);
                entry->bond.vid = vid;
            }
        }
    }

    memcpy(&old_vlans, &ctx->xin->flow.vlans, sizeof(old_vlans));
    xvlan_put(&ctx->xin->flow, &out_xvlan, out_xbundle->use_priority_tags);

    compose_output_action(ctx, xport->ofp_port, use_recirc ? &xr : NULL,
                          false, false);
    memcpy(&ctx->xin->flow.vlans, &old_vlans, sizeof(old_vlans));
}


static void
compose_output_action(struct xlate_ctx *ctx, ofp_port_t ofp_port,
                      const struct xlate_bond_recirc *xr,
                      bool is_last_action, bool truncate)
{
    compose_output_action__(ctx, ofp_port, xr, true,
                            is_last_action, truncate);
}

static void
compose_output_action__(struct xlate_ctx *ctx, ofp_port_t ofp_port,
                        const struct xlate_bond_recirc *xr, bool check_stp,
                        bool is_last_action OVS_UNUSED, bool truncate)
{
    const struct xport *xport = get_ofp_port(ctx->xbridge, ofp_port);
    struct flow_wildcards *wc = ctx->wc;
    struct flow *flow = &ctx->xin->flow;
    struct flow_tnl flow_tnl;
    union flow_vlan_hdr flow_vlans[FLOW_MAX_VLAN_HEADERS];
    uint8_t flow_nw_tos;
    odp_port_t out_port, odp_port, odp_tnl_port;
    bool is_native_tunnel = false;
    uint8_t dscp;
    struct eth_addr flow_dl_dst = flow->dl_dst;
    struct eth_addr flow_dl_src = flow->dl_src;
    ovs_be32 flow_packet_type = flow->packet_type;
    ovs_be16 flow_dl_type = flow->dl_type;

    /* If 'struct flow' gets additional metadata, we'll need to zero it out
     * before traversing a patch port. */
    BUILD_ASSERT_DECL(FLOW_WC_SEQ == 42);
    memset(&flow_tnl, 0, sizeof flow_tnl);

    if (!check_output_prerequisites(ctx, xport, flow, check_stp)) {
        return;
    }

    if (flow->packet_type == htonl(PT_ETH)) {
        /* Strip Ethernet header for legacy L3 port. */
        if (xport->pt_mode == NETDEV_PT_LEGACY_L3) {
            flow->packet_type = PACKET_TYPE_BE(OFPHTN_ETHERTYPE,
                                               ntohs(flow->dl_type));
        }
    }

    if (xport->peer) {
       if (truncate) {
           xlate_report_error(ctx, "Cannot truncate output to patch port");
       }
       patch_port_output(ctx, xport, xport->peer);
       return;
    }

    memcpy(flow_vlans, flow->vlans, sizeof flow_vlans);
    flow_nw_tos = flow->nw_tos;

    if (count_skb_priorities(xport)) {
        memset(&wc->masks.skb_priority, 0xff, sizeof wc->masks.skb_priority);
        if (dscp_from_skb_priority(xport, flow->skb_priority, &dscp)) {
            wc->masks.nw_tos |= IP_DSCP_MASK;
            flow->nw_tos &= ~IP_DSCP_MASK;
            flow->nw_tos |= dscp;
        }
    }

    if (xport->is_tunnel) {
        struct in6_addr dst;
         /* Save tunnel metadata so that changes made due to
          * the Logical (tunnel) Port are not visible for any further
          * matches, while explicit set actions on tunnel metadata are.
          */
        flow_tnl = flow->tunnel;
        odp_port = tnl_port_send(xport->ofport, flow, ctx->wc);
        if (odp_port == ODPP_NONE) {
            xlate_report(ctx, OFT_WARN, "Tunneling decided against output");
            goto out; /* restore flow_nw_tos */
        }
        dst = flow_tnl_dst(&flow->tunnel);
        if (ipv6_addr_equals(&dst, &ctx->orig_tunnel_ipv6_dst)) {
            xlate_report(ctx, OFT_WARN, "Not tunneling to our own address");
            goto out; /* restore flow_nw_tos */
        }
        if (ctx->xin->resubmit_stats) {
            netdev_vport_inc_tx(xport->netdev, ctx->xin->resubmit_stats);
        }
        if (ctx->xin->xcache) {
            struct xc_entry *entry;

            entry = xlate_cache_add_entry(ctx->xin->xcache, XC_NETDEV);
            entry->dev.tx = netdev_ref(xport->netdev);
        }
        out_port = odp_port;
        if (ovs_native_tunneling_is_on(ctx->xbridge->ofproto)) {
            xlate_report(ctx, OFT_DETAIL, "output to native tunnel");
            is_native_tunnel = true;
        } else {
            const char *tnl_type;

            xlate_report(ctx, OFT_DETAIL, "output to kernel tunnel");
            tnl_type = tnl_port_get_type(xport->ofport);
            commit_odp_tunnel_action(flow, &ctx->base_flow,
                                     ctx->odp_actions, tnl_type);
            flow->tunnel = flow_tnl; /* Restore tunnel metadata */
        }
    } else {
        odp_port = xport->odp_port;
        out_port = odp_port;
    }

    if (out_port != ODPP_NONE) {
        /* Commit accumulated flow updates before output. */
        xlate_commit_actions(ctx);

        if (xr && bond_use_lb_output_action(xport->xbundle->bond)) {
            /*
             * If bond mode is balance-tcp and optimize balance tcp is enabled
             * then use the hash directly for slave selection and avoid
             * recirculation.
             *
             * Currently support for netdev datapath only.
             */
            nl_msg_put_u32(ctx->odp_actions, OVS_ACTION_ATTR_LB_OUTPUT,
                           xr->recirc_id);
        } else if (xr) {
            /* Recirculate the packet. */
            struct ovs_action_hash *act_hash;

            /* Hash action. */
            enum ovs_hash_alg hash_alg = xr->hash_alg;
            if (hash_alg > ctx->xbridge->support.max_hash_alg) {
                /* Algorithm supported by all datapaths. */
                hash_alg = OVS_HASH_ALG_L4;
            }
            act_hash = nl_msg_put_unspec_uninit(ctx->odp_actions,
                                                OVS_ACTION_ATTR_HASH,
                                                sizeof *act_hash);
            act_hash->hash_alg = hash_alg;
            act_hash->hash_basis = xr->hash_basis;

            /* Recirc action. */
            nl_msg_put_u32(ctx->odp_actions, OVS_ACTION_ATTR_RECIRC,
                           xr->recirc_id);
        } else if (is_native_tunnel) {
            /* Output to native tunnel port. */
            native_tunnel_output(ctx, xport, flow, odp_port, truncate);
            flow->tunnel = flow_tnl; /* Restore tunnel metadata */

        } else if (terminate_native_tunnel(ctx, flow, wc,
                                           &odp_tnl_port)) {
            /* Intercept packet to be received on native tunnel port. */
            nl_msg_put_odp_port(ctx->odp_actions, OVS_ACTION_ATTR_TUNNEL_POP,
                                odp_tnl_port);

        } else {
            /* Tunnel push-pop action is not compatible with
             * IPFIX action. */
            compose_ipfix_action(ctx, out_port);

            /* Handle truncation of the mirrored packet. */
            if (ctx->mirror_snaplen > 0 &&
                    ctx->mirror_snaplen < UINT16_MAX) {
                struct ovs_action_trunc *trunc;

                trunc = nl_msg_put_unspec_uninit(ctx->odp_actions,
                                                 OVS_ACTION_ATTR_TRUNC,
                                                 sizeof *trunc);
                trunc->max_len = ctx->mirror_snaplen;
                if (!ctx->xbridge->support.trunc) {
                    ctx->xout->slow |= SLOW_ACTION;
                }
            }

            nl_msg_put_odp_port(ctx->odp_actions,
                                OVS_ACTION_ATTR_OUTPUT,
                                out_port);
        }

        ctx->sflow_odp_port = odp_port;
        ctx->sflow_n_outputs++;
        ctx->nf_output_iface = ofp_port;
    }

    if (mbridge_has_mirrors(ctx->xbridge->mbridge) && xport->xbundle) {
        mirror_packet(ctx, xport->xbundle,
                      xbundle_mirror_dst(xport->xbundle->xbridge,
                                         xport->xbundle));
    }

 out:
    /* Restore flow */
    memcpy(flow->vlans, flow_vlans, sizeof flow->vlans);
    flow->nw_tos = flow_nw_tos;
    flow->dl_dst = flow_dl_dst;
    flow->dl_src = flow_dl_src;
    flow->packet_type = flow_packet_type;
    flow->dl_type = flow_dl_type;
}

static void
xlate_commit_actions(struct xlate_ctx *ctx)
{
    bool use_masked = ctx->xbridge->support.masked_set_action;

    ctx->xout->slow |= commit_odp_actions(&ctx->xin->flow, &ctx->base_flow,
                                          ctx->odp_actions, ctx->wc,
                                          use_masked, ctx->pending_encap,
                                          ctx->pending_decap, ctx->encap_data);
    ctx->pending_encap = false;
    ctx->pending_decap = false;
    ofpbuf_delete(ctx->encap_data);
    ctx->encap_data = NULL;
}

/* If any of the flow key data that ODP actions can modify are different in
 * 'base' and 'flow', appends ODP actions to 'odp_actions' that change the flow
 * key from 'base' into 'flow', and then changes 'base' the same way.  Does not
 * commit set_tunnel actions.  Users should call commit_odp_tunnel_action()
 * in addition to this function if needed.  Sets fields in 'wc' that are
 * used as part of the action.
 *
 * In the common case, this function returns 0.  If the flow key modification
 * requires the flow's packets to be forced into the userspace slow path, this
 * function returns SLOW_ACTION.  This only happens when there is no ODP action
 * to modify some field that was actually modified.  For example, there is no
 * ODP action to modify any ARP field, so such a modification triggers
 * SLOW_ACTION.  (When this happens, packets that need such modification get
 * flushed to userspace and handled there, which works OK but much more slowly
 * than if the datapath handled it directly.) */
enum slow_path_reason
commit_odp_actions(const struct flow *flow, struct flow *base,
                   struct ofpbuf *odp_actions, struct flow_wildcards *wc,
                   bool use_masked, bool pending_encap, bool pending_decap,
                   struct ofpbuf *encap_data)
{
    /* If you add a field that OpenFlow actions can change, and that is visible
     * to the datapath (including all data fields), then you should also add
     * code here to commit changes to the field. */
    BUILD_ASSERT_DECL(FLOW_WC_SEQ == 42);

    enum slow_path_reason slow1, slow2;
    bool mpls_done = false;

    commit_encap_decap_action(flow, base, odp_actions, wc,
                              pending_encap, pending_decap, encap_data);
    commit_set_ether_action(flow, base, odp_actions, wc, use_masked);
    /* Make packet a non-MPLS packet before committing L3/4 actions,
     * which would otherwise do nothing. */
    if (eth_type_mpls(base->dl_type) && !eth_type_mpls(flow->dl_type)) {
        commit_mpls_action(flow, base, odp_actions);
        mpls_done = true;
    }
    commit_set_nsh_action(flow, base, odp_actions, wc, use_masked);
    slow1 = commit_set_nw_action(flow, base, odp_actions, wc, use_masked);
    commit_set_port_action(flow, base, odp_actions, wc, use_masked);
    slow2 = commit_set_icmp_action(flow, base, odp_actions, wc);
    if (!mpls_done) {
        commit_mpls_action(flow, base, odp_actions);
    }
    commit_vlan_action(flow, base, odp_actions, wc);
    commit_set_priority_action(flow, base, odp_actions, wc, use_masked);
    commit_set_pkt_mark_action(flow, base, odp_actions, wc, use_masked);

    return slow1 ? slow1 : slow2;
}




////////////////////9. 命令行ovs-ofctl修改



-----------------connmgr.c

/*
Openvswitch: Controller
openvwitch的一个bridge可以通过openflow协议，被一个统一的controller管理的
这里是Openflow的控制器连接
*/
connmgr_run(p->connmgr, handle_openflow);

connmgr_run->ofconn_run

static void
ofconn_run(struct ofconn *ofconn,
           void (*handle_openflow)(struct ofconn *,
                                   const struct ovs_list *msgs))
{
    struct connmgr *mgr = ofconn->connmgr;

    for (size_t i = 0; i < N_SCHEDULERS; i++) {
        struct ovs_list txq;

        pinsched_run(ofconn->schedulers[i], &txq);
        do_send_packet_ins(ofconn, &txq);
    }

    rconn_run(ofconn->rconn);

    /* Limit the number of iterations to avoid starving other tasks. */
    for (int i = 0; i < 50 && ofconn_may_recv(ofconn); i++) {
        struct ofpbuf *of_msg = rconn_recv(ofconn->rconn);
        if (!of_msg) {
            break;
        }

        if (mgr->fail_open) {
            fail_open_maybe_recover(mgr->fail_open);
        }

        struct ovs_list msgs;
        enum ofperr error = ofpmp_assembler_execute(&ofconn->assembler, of_msg,
                                                    &msgs, time_msec());
        if (error) {
            ofconn_send_error(ofconn, of_msg->data, error);
            ofpbuf_delete(of_msg);
        } else if (!ovs_list_is_empty(&msgs)) {
            handle_openflow(ofconn, &msgs); ////////////
            ofpbuf_list_delete(&msgs);
        }
    }

    long long int now = time_msec();

    if (now >= ofconn->next_bundle_expiry_check) {
        ofconn->next_bundle_expiry_check = now + BUNDLE_EXPIRY_INTERVAL;
        bundle_remove_expired(ofconn, now);
    }

    if (now >= ofconn->next_op_report) {
        ofconn_log_flow_mods(ofconn);
    }

    struct ofpbuf *error = ofpmp_assembler_run(&ofconn->assembler,
                                               time_msec());
    if (error) {
        ofconn_send(ofconn, error, NULL);
    }

    ovs_mutex_lock(&ofproto_mutex);
    if (rconn_is_reliable(ofconn->rconn)
        ? !rconn_is_connected(ofconn->rconn)
        : !rconn_is_alive(ofconn->rconn)) {
        ofconn_destroy(ofconn);
    }
    ovs_mutex_unlock(&ofproto_mutex);
}

--------------------ofproto.c

static void
handle_openflow(struct ofconn *ofconn, const struct ovs_list *msgs)
    OVS_EXCLUDED(ofproto_mutex)
{
    COVERAGE_INC(ofproto_recv_openflow);

    struct ofpbuf *msg = ofpbuf_from_list(ovs_list_front(msgs));
    enum ofptype type;
    enum ofperr error = ofptype_decode(&type, msg->data);
    if (!error) {
        if (type == OFPTYPE_TABLE_FEATURES_STATS_REQUEST) {
            handle_table_features_request(ofconn, msgs);
        } else if (type == OFPTYPE_FLOW_MONITOR_STATS_REQUEST) {
            handle_flow_monitor_request(ofconn, msgs);
        } else if (!ovs_list_is_short(msgs)) {
            error = OFPERR_OFPBRC_BAD_STAT;
        } else {
            error = handle_single_part_openflow(ofconn, msg->data, type);///////////
        }
    }
    if (error) {
        ofconn_send_error(ofconn, msg->data, error);
    }
}

/* Processes the single-part OpenFlow message 'oh' that was received on
 * 'ofconn'.  Returns an ofperr that, if nonzero, the caller should send back
 * to the controller. */
static enum ofperr
handle_single_part_openflow(struct ofconn *ofconn, const struct ofp_header *oh,
                            enum ofptype type)
    OVS_EXCLUDED(ofproto_mutex)
{
    switch (type) {
        /* OpenFlow requests. */
    case OFPTYPE_ECHO_REQUEST:
        return handle_echo_request(ofconn, oh);

    case OFPTYPE_FEATURES_REQUEST:
        return handle_features_request(ofconn, oh);

    case OFPTYPE_GET_CONFIG_REQUEST:
        return handle_get_config_request(ofconn, oh);

    case OFPTYPE_SET_CONFIG:
        return handle_set_config(ofconn, oh);

    case OFPTYPE_PACKET_OUT:
        return handle_packet_out(ofconn, oh);

    case OFPTYPE_PORT_MOD:
        return handle_port_mod(ofconn, oh);

    case OFPTYPE_FLOW_MOD:
        return handle_flow_mod(ofconn, oh);////////

    case OFPTYPE_GROUP_MOD:
        return handle_group_mod(ofconn, oh);

    case OFPTYPE_TABLE_MOD:
        return handle_table_mod(ofconn, oh);

    case OFPTYPE_METER_MOD:
        return handle_meter_mod(ofconn, oh);

    case OFPTYPE_BARRIER_REQUEST:
        return handle_barrier_request(ofconn, oh);

    case OFPTYPE_ROLE_REQUEST:
        return handle_role_request(ofconn, oh);

        /* OpenFlow replies. */
    case OFPTYPE_ECHO_REPLY:
        return 0;

        /* Nicira extension requests. */
    case OFPTYPE_FLOW_MOD_TABLE_ID:
        return handle_nxt_flow_mod_table_id(ofconn, oh);

    case OFPTYPE_SET_FLOW_FORMAT:
        return handle_nxt_set_flow_format(ofconn, oh);

    case OFPTYPE_SET_PACKET_IN_FORMAT:
        return handle_nxt_set_packet_in_format(ofconn, oh);

    case OFPTYPE_SET_CONTROLLER_ID:
        return handle_nxt_set_controller_id(ofconn, oh);

    case OFPTYPE_FLOW_AGE:
        /* Nothing to do. */
        return 0;

    case OFPTYPE_FLOW_MONITOR_CANCEL:
        return handle_flow_monitor_cancel(ofconn, oh);

    case OFPTYPE_SET_ASYNC_CONFIG:
        return handle_nxt_set_async_config(ofconn, oh);

    case OFPTYPE_GET_ASYNC_REQUEST:
        return handle_nxt_get_async_request(ofconn, oh);

    case OFPTYPE_NXT_RESUME:
        return handle_nxt_resume(ofconn, oh);

        /* Statistics requests. */
    case OFPTYPE_DESC_STATS_REQUEST:
        return handle_desc_stats_request(ofconn, oh);

    case OFPTYPE_FLOW_STATS_REQUEST:
        return handle_flow_stats_request(ofconn, oh);

    case OFPTYPE_AGGREGATE_STATS_REQUEST:
        return handle_aggregate_stats_request(ofconn, oh);

    case OFPTYPE_TABLE_STATS_REQUEST:
        return handle_table_stats_request(ofconn, oh);

    case OFPTYPE_TABLE_DESC_REQUEST:
        return handle_table_desc_request(ofconn, oh);

    case OFPTYPE_PORT_STATS_REQUEST:
        return handle_port_stats_request(ofconn, oh);

    case OFPTYPE_QUEUE_STATS_REQUEST:
        return handle_queue_stats_request(ofconn, oh);

    case OFPTYPE_PORT_DESC_STATS_REQUEST:
        return handle_port_desc_stats_request(ofconn, oh);

    case OFPTYPE_TABLE_FEATURES_STATS_REQUEST:
    case OFPTYPE_FLOW_MONITOR_STATS_REQUEST:
        /* Handled as multipart requests in handle_openflow(). */
        OVS_NOT_REACHED();

    case OFPTYPE_METER_STATS_REQUEST:
    case OFPTYPE_METER_CONFIG_STATS_REQUEST:
        return handle_meter_request(ofconn, oh, type);

    case OFPTYPE_METER_FEATURES_STATS_REQUEST:
        return handle_meter_features_request(ofconn, oh);

    case OFPTYPE_GROUP_STATS_REQUEST:
        return handle_group_stats_request(ofconn, oh);

    case OFPTYPE_GROUP_DESC_STATS_REQUEST:
        return handle_group_desc_stats_request(ofconn, oh);

    case OFPTYPE_GROUP_FEATURES_STATS_REQUEST:
        return handle_group_features_stats_request(ofconn, oh);

    case OFPTYPE_QUEUE_GET_CONFIG_REQUEST:
        return handle_queue_get_config_request(ofconn, oh);

    case OFPTYPE_BUNDLE_CONTROL:
        return handle_bundle_control(ofconn, oh);

    case OFPTYPE_BUNDLE_ADD_MESSAGE:
        return handle_bundle_add(ofconn, oh);

    case OFPTYPE_NXT_TLV_TABLE_MOD:
        return handle_tlv_table_mod(ofconn, oh);

    case OFPTYPE_NXT_TLV_TABLE_REQUEST:
        return handle_tlv_table_request(ofconn, oh);

    case OFPTYPE_IPFIX_BRIDGE_STATS_REQUEST:
        return handle_ipfix_bridge_stats_request(ofconn, oh);

    case OFPTYPE_IPFIX_FLOW_STATS_REQUEST:
        return handle_ipfix_flow_stats_request(ofconn, oh);

    case OFPTYPE_CT_FLUSH_ZONE:
        return handle_nxt_ct_flush_zone(ofconn, oh);

    case OFPTYPE_HELLO:
    case OFPTYPE_ERROR:
    case OFPTYPE_FEATURES_REPLY:
    case OFPTYPE_GET_CONFIG_REPLY:
    case OFPTYPE_PACKET_IN:
    case OFPTYPE_FLOW_REMOVED:
    case OFPTYPE_PORT_STATUS:
    case OFPTYPE_BARRIER_REPLY:
    case OFPTYPE_QUEUE_GET_CONFIG_REPLY:
    case OFPTYPE_DESC_STATS_REPLY:
    case OFPTYPE_FLOW_STATS_REPLY:
    case OFPTYPE_QUEUE_STATS_REPLY:
    case OFPTYPE_PORT_STATS_REPLY:
    case OFPTYPE_TABLE_STATS_REPLY:
    case OFPTYPE_AGGREGATE_STATS_REPLY:
    case OFPTYPE_PORT_DESC_STATS_REPLY:
    case OFPTYPE_ROLE_REPLY:
    case OFPTYPE_FLOW_MONITOR_PAUSED:
    case OFPTYPE_FLOW_MONITOR_RESUMED:
    case OFPTYPE_FLOW_MONITOR_STATS_REPLY:
    case OFPTYPE_GET_ASYNC_REPLY:
    case OFPTYPE_GROUP_STATS_REPLY:
    case OFPTYPE_GROUP_DESC_STATS_REPLY:
    case OFPTYPE_GROUP_FEATURES_STATS_REPLY:
    case OFPTYPE_METER_STATS_REPLY:
    case OFPTYPE_METER_CONFIG_STATS_REPLY:
    case OFPTYPE_METER_FEATURES_STATS_REPLY:
    case OFPTYPE_TABLE_FEATURES_STATS_REPLY:
    case OFPTYPE_TABLE_DESC_REPLY:
    case OFPTYPE_ROLE_STATUS:
    case OFPTYPE_REQUESTFORWARD:
    case OFPTYPE_TABLE_STATUS:
    case OFPTYPE_NXT_TLV_TABLE_REPLY:
    case OFPTYPE_IPFIX_BRIDGE_STATS_REPLY:
    case OFPTYPE_IPFIX_FLOW_STATS_REPLY:
    default:
        if (ofpmsg_is_stat_request(oh)) {
            return OFPERR_OFPBRC_BAD_STAT;
        } else {
            return OFPERR_OFPBRC_BAD_TYPE;
        }
    }
}

static enum ofperr
handle_flow_mod(struct ofconn *ofconn, const struct ofp_header *oh)
    OVS_EXCLUDED(ofproto_mutex)
{
    struct ofproto *ofproto = ofconn_get_ofproto(ofconn);
    struct ofputil_flow_mod fm;
    uint64_t ofpacts_stub[1024 / 8];
    struct ofpbuf ofpacts;
    enum ofperr error;

    error = reject_slave_controller(ofconn);
    if (error) {
        return error;
    }

    ofpbuf_use_stub(&ofpacts, ofpacts_stub, sizeof ofpacts_stub);
    error = ofputil_decode_flow_mod(&fm, oh, ofconn_get_protocol(ofconn),
                                    ofproto_get_tun_tab(ofproto),
                                    &ofproto->vl_mff_map, &ofpacts,
                                    u16_to_ofp(ofproto->max_ports),
                                    ofproto->n_tables);
    if (!error) {
        struct openflow_mod_requester req = { ofconn, oh };
        error = handle_flow_mod__(ofproto, &fm, &req);////////
        minimatch_destroy(&fm.match);
    }

    ofpbuf_uninit(&ofpacts);
    return error;
}

static enum ofperr
handle_flow_mod__(struct ofproto *ofproto, const struct ofputil_flow_mod *fm,
                  const struct openflow_mod_requester *req)
    OVS_EXCLUDED(ofproto_mutex)
{
    struct ofproto_flow_mod ofm;
    enum ofperr error;

    error = ofproto_flow_mod_init(ofproto, &ofm, fm, NULL);
    if (error) {
        return error;
    }

    ovs_mutex_lock(&ofproto_mutex);
    ofm.version = ofproto->tables_version + 1;
    error = ofproto_flow_mod_start(ofproto, &ofm);////////
    if (!error) {
        ofproto_bump_tables_version(ofproto);
        error = ofproto_flow_mod_finish(ofproto, &ofm, req);        
        ofmonitor_flush(ofproto->connmgr);
    }
    ovs_mutex_unlock(&ofproto_mutex);

    return error;
}

static enum ofperr
ofproto_flow_mod_start(struct ofproto *ofproto, struct ofproto_flow_mod *ofm)
    OVS_REQUIRES(ofproto_mutex)
{
    enum ofperr error;

    rule_collection_init(&ofm->old_rules);
    rule_collection_init(&ofm->new_rules);

    switch (ofm->command) {
    case OFPFC_ADD:
        error = add_flow_start(ofproto, ofm);
        break;
    case OFPFC_MODIFY:
        error = modify_flows_start_loose(ofproto, ofm);/////
        break;
    case OFPFC_MODIFY_STRICT:
        error = modify_flow_start_strict(ofproto, ofm);/////
        break;
    case OFPFC_DELETE:
        error = delete_flows_start_loose(ofproto, ofm);
        break;
    case OFPFC_DELETE_STRICT:
        error = delete_flow_start_strict(ofproto, ofm);
        break;
    default:
        OVS_NOT_REACHED();
    }
    /* Release resources not needed after start. */
    ofproto_flow_mod_uninit(ofm);

    if (error) {
        rule_collection_destroy(&ofm->old_rules);
        rule_collection_destroy(&ofm->new_rules);
    }
    return error;
}

static enum ofperr
modify_flows_start__(struct ofproto *ofproto, struct ofproto_flow_mod *ofm)
    OVS_REQUIRES(ofproto_mutex)
{
    struct rule_collection *old_rules = &ofm->old_rules;
    struct rule_collection *new_rules = &ofm->new_rules;
    enum ofperr error;

    if (rule_collection_n(old_rules) > 0) {
        /* Create a new 'modified' rule for each old rule. */
        struct rule *old_rule, *new_rule;
        const struct rule_actions *actions = rule_get_actions(ofm->temp_rule);

        /* Must check actions while holding ofproto_mutex to avoid a race. */
        error = ofproto_check_ofpacts(ofproto, actions->ofpacts,
                                      actions->ofpacts_len);
        if (error) {
            return error;
        }

        /* Use the temp rule as the first new rule, and as the template for
         * the rest. */
        struct rule *temp = ofm->temp_rule;
        ofm->temp_rule = NULL;   /* We consume the template. */

        bool first = true;
        RULE_COLLECTION_FOR_EACH (old_rule, old_rules) {
            if (first) {
                /* The template rule's match is possibly a loose one, so it
                 * must be replaced with the old rule's match so that the new
                 * rule actually replaces the old one. */
                cls_rule_destroy(CONST_CAST(struct cls_rule *, &temp->cr));
                cls_rule_clone(CONST_CAST(struct cls_rule *, &temp->cr),
                               &old_rule->cr);
                if (temp->match_tlv_bitmap != old_rule->match_tlv_bitmap) {
                    mf_vl_mff_unref(&temp->ofproto->vl_mff_map,
                                    temp->match_tlv_bitmap);
                    temp->match_tlv_bitmap = old_rule->match_tlv_bitmap;
                    mf_vl_mff_ref(&temp->ofproto->vl_mff_map,
                                  temp->match_tlv_bitmap);
                }
                *CONST_CAST(uint8_t *, &temp->table_id) = old_rule->table_id;
                rule_collection_add(new_rules, temp);
                first = false;
            } else {
                struct cls_rule cr;
                cls_rule_clone(&cr, &old_rule->cr);
                error = ofproto_rule_create(ofproto, &cr, old_rule->table_id,
                                            temp->flow_cookie,
                                            temp->idle_timeout,
                                            temp->hard_timeout, temp->flags,
                                            temp->importance,
                                            temp->actions->ofpacts,
                                            temp->actions->ofpacts_len,
                                            old_rule->match_tlv_bitmap,
                                            temp->ofpacts_tlv_bitmap,
                                            &new_rule);
                if (!error) {
                    rule_collection_add(new_rules, new_rule);
                } else {
                    /* Return the template rule in place in the error case. */
                    ofm->temp_rule = temp;
                    rule_collection_rules(new_rules)[0] = NULL;

                    rule_collection_unref(new_rules);
                    rule_collection_destroy(new_rules);
                    return error;
                }
            }
        }
        ovs_assert(rule_collection_n(new_rules)
                   == rule_collection_n(old_rules));

        RULE_COLLECTIONS_FOR_EACH (old_rule, new_rule, old_rules, new_rules) {
            replace_rule_start(ofproto, ofm, old_rule, new_rule);///////////
        }
    } else if (ofm->modify_may_add_flow) {
        /* No match, add a new flow, consumes 'temp'. */
        error = add_flow_start(ofproto, ofm);
    } else {
        /* No flow to modify and may not add a flow. */
        ofproto_rule_unref(ofm->temp_rule);
        ofm->temp_rule = NULL;   /* We consume the template. */
        error = 0;
    }

    return error;
}

static void
replace_rule_start(struct ofproto *ofproto, struct ofproto_flow_mod *ofm,
                   struct rule *old_rule, struct rule *new_rule)
{
    struct oftable *table = &ofproto->tables[new_rule->table_id];

    /* 'old_rule' may be either an evicted rule or replaced rule. */
    if (old_rule) {
        /* Copy values from old rule for modify semantics. */
        if (old_rule->removed_reason != OFPRR_EVICTION) {
            bool change_cookie = (ofm->modify_cookie
                                  && new_rule->flow_cookie != OVS_BE64_MAX
                                  && new_rule->flow_cookie != old_rule->flow_cookie);

            ovs_mutex_lock(&new_rule->mutex);
            ovs_mutex_lock(&old_rule->mutex);
            if (ofm->command != OFPFC_ADD) {
                new_rule->idle_timeout = old_rule->idle_timeout;
                new_rule->hard_timeout = old_rule->hard_timeout;
                *CONST_CAST(uint16_t *, &new_rule->importance) = old_rule->importance;
                new_rule->flags = old_rule->flags;
                new_rule->created = old_rule->created;
            }
            if (!change_cookie) {
                *CONST_CAST(ovs_be64 *, &new_rule->flow_cookie)
                    = old_rule->flow_cookie;
            }
            ovs_mutex_unlock(&old_rule->mutex);
            ovs_mutex_unlock(&new_rule->mutex);
        }

        /* Mark the old rule for removal in the next version. */
        cls_rule_make_invisible_in_version(&old_rule->cr, ofm->version);

        /* Remove the old rule from data structures. */
        ofproto_rule_remove__(ofproto, old_rule);
    } else {
        table->n_flows++;
    }
    /* Insert flow to ofproto data structures, so that later flow_mods may
     * relate to it.  This is reversible, in case later errors require this to
     * be reverted. */
    ofproto_rule_insert__(ofproto, new_rule);////////
    /* Make the new rule visible for classifier lookups only from the next
     * version. */
    classifier_insert(&table->cls, &new_rule->cr, ofm->version, ofm->conjs,
                      ofm->n_conjs);
}

/* Inserts 'rule' from the ofproto data structures BEFORE caller has inserted
 * it to the classifier. */
static void
ofproto_rule_insert__(struct ofproto *ofproto, struct rule *rule)
    OVS_REQUIRES(ofproto_mutex)
{
    const struct rule_actions *actions = rule_get_actions(rule);

    /* A rule may not be reinserted. */
    ovs_assert(rule->state != RULE_INSERTED);

    if (rule->hard_timeout || rule->idle_timeout) {
        ovs_list_insert(&ofproto->expirable, &rule->expirable);
    }
    cookies_insert(ofproto, rule);
    eviction_group_add_rule(rule);
    if (actions->has_meter) {
        meter_insert_rule(rule);
    }
    if (actions->has_groups) {
        const struct ofpact_group *a;
        OFPACT_FOR_EACH_TYPE_FLATTENED (a, GROUP, actions->ofpacts,
                                        actions->ofpacts_len) {
            struct ofgroup *group;

            group = ofproto_group_lookup(ofproto, a->group_id, OVS_VERSION_MAX,
                                         false);
            ovs_assert(group != NULL);
            group_add_rule(group, rule);
        }
    }

    rule->state = RULE_INSERTED;
}

--------------ofp-actions.h

#define OFPACT_FIND_TYPE_FLATTENED(A, TYPE, END) \
    ofpact_get_##TYPE##_nullable(                       \
        ofpact_find_type_flattened(A, OFPACT_##TYPE, END))

/* Assigns POS to each ofpact, in turn, in the OFPACTS_LEN bytes of ofpacts
 * starting at OFPACTS.
 *
 * For ofpacts that contain nested ofpacts, this visits each of the inner
 * ofpacts as well. */
#define OFPACT_FOR_EACH_FLATTENED(POS, OFPACTS, OFPACTS_LEN)           \
    for ((POS) = (OFPACTS); (POS) < ofpact_end(OFPACTS, OFPACTS_LEN);  \
         (POS) = ofpact_next_flattened(POS))

#define OFPACT_FOR_EACH_TYPE_FLATTENED(POS, TYPE, OFPACTS, OFPACTS_LEN) \
    for ((POS) = OFPACT_FIND_TYPE_FLATTENED(OFPACTS, TYPE,              \
                                  ofpact_end(OFPACTS, OFPACTS_LEN));    \
         (POS);                                                         \
         (POS) = OFPACT_FIND_TYPE_FLATTENED(                            \
             ofpact_next_flattened(&(POS)->ofpact), TYPE,               \
             ofpact_end(OFPACTS, OFPACTS_LEN)))

--------------ofp-actions.c

这里需要添加新的OFPACT_的action

struct ofpact *
ofpact_next_flattened(const struct ofpact *ofpact)
{
    switch (ofpact->type) {
        /* ... */
        case OFPACT_PROBDROP:
            return ofpact_next(ofpact);
    }
    /* ... */
}

/* ... */

enum ovs_instruction_type
ovs_instruction_type_from_ofpact_type(enum ofpact_type type)
{
    switch (type) {
    /* ... */
    case OFPACT_PROBDROP:
    default:
        return OVSINST_OFPIT11_APPLY_ACTIONS;
    /* ... */
    }
}

/* ... */

static bool
ofpact_outputs_to_port(const struct ofpact *ofpact, ofp_port_t port)
{
    switch (ofpact->type) {
    /* ... */
    case OFPACT_PROBDROP:
    default:
        return false;
    }
}

/* Returns the ofpact following 'ofpact', except that if 'ofpact' contains
 * nested ofpacts it returns the first one. */
struct ofpact *
ofpact_next_flattened(const struct ofpact *ofpact)
{
    switch (ofpact->type) {
    case OFPACT_OUTPUT:
    case OFPACT_GROUP:
    case OFPACT_CONTROLLER:
    case OFPACT_ENQUEUE:
    case OFPACT_OUTPUT_REG:
    case OFPACT_OUTPUT_TRUNC:
    case OFPACT_BUNDLE:
    case OFPACT_SET_FIELD:
    case OFPACT_SET_VLAN_VID:
    case OFPACT_SET_VLAN_PCP:
    case OFPACT_STRIP_VLAN:
    case OFPACT_PUSH_VLAN:
    case OFPACT_SET_ETH_SRC:
    case OFPACT_SET_ETH_DST:
    case OFPACT_SET_IPV4_SRC:
    case OFPACT_SET_IPV4_DST:
    case OFPACT_SET_IP_DSCP:
    case OFPACT_SET_IP_ECN:
    case OFPACT_SET_IP_TTL:
    case OFPACT_SET_L4_SRC_PORT:
    case OFPACT_SET_L4_DST_PORT:
    case OFPACT_REG_MOVE:
    case OFPACT_STACK_PUSH:
    case OFPACT_STACK_POP:
    case OFPACT_DEC_TTL:
    case OFPACT_SET_MPLS_LABEL:
    case OFPACT_SET_MPLS_TC:
    case OFPACT_SET_MPLS_TTL:
    case OFPACT_DEC_MPLS_TTL:
    case OFPACT_PUSH_MPLS:
    case OFPACT_POP_MPLS:
    case OFPACT_SET_TUNNEL:
    case OFPACT_SET_QUEUE:
    case OFPACT_POP_QUEUE:
    case OFPACT_FIN_TIMEOUT:
    case OFPACT_RESUBMIT:
    case OFPACT_LEARN:
    case OFPACT_CONJUNCTION:
    case OFPACT_MULTIPATH:
    case OFPACT_NOTE:
    case OFPACT_EXIT:
    case OFPACT_SAMPLE:
    case OFPACT_UNROLL_XLATE:
    case OFPACT_CT_CLEAR:
    case OFPACT_DEBUG_RECIRC:
    case OFPACT_DEBUG_SLOW:
    case OFPACT_METER:
    case OFPACT_CLEAR_ACTIONS:
    case OFPACT_WRITE_METADATA:
    case OFPACT_GOTO_TABLE:
    case OFPACT_NAT:
    case OFPACT_ENCAP:
    case OFPACT_DECAP:
    case OFPACT_DEC_NSH_TTL:
    case OFPACT_CHECK_PKT_LARGER:
    case OFPACT_DELETE_FIELD:
        return ofpact_next(ofpact);

    case OFPACT_CLONE:
        return ofpact_get_CLONE(ofpact)->actions;

    case OFPACT_CT:
        return ofpact_get_CT(ofpact)->actions;

    case OFPACT_WRITE_ACTIONS:
        return ofpact_get_WRITE_ACTIONS(ofpact)->actions;
    }

    OVS_NOT_REACHED();
}


enum ovs_instruction_type
ovs_instruction_type_from_ofpact_type(enum ofpact_type type,
                                      enum ofp_version version)
{
    switch (type) {
    case OFPACT_METER:
        return (version >= OFP15_VERSION
                ? OVSINST_OFPIT11_APPLY_ACTIONS
                : OVSINST_OFPIT13_METER);
    case OFPACT_CLEAR_ACTIONS:
        return OVSINST_OFPIT11_CLEAR_ACTIONS;
    case OFPACT_WRITE_ACTIONS:
        return OVSINST_OFPIT11_WRITE_ACTIONS;
    case OFPACT_WRITE_METADATA:
        return OVSINST_OFPIT11_WRITE_METADATA;
    case OFPACT_GOTO_TABLE:
        return OVSINST_OFPIT11_GOTO_TABLE;
    case OFPACT_OUTPUT:
    case OFPACT_GROUP:
    case OFPACT_CLONE:
    case OFPACT_CONTROLLER:
    case OFPACT_ENQUEUE:
    case OFPACT_OUTPUT_REG:
    case OFPACT_OUTPUT_TRUNC:
    case OFPACT_BUNDLE:
    case OFPACT_SET_VLAN_VID:
    case OFPACT_SET_VLAN_PCP:
    case OFPACT_STRIP_VLAN:
    case OFPACT_PUSH_VLAN:
    case OFPACT_SET_ETH_SRC:
    case OFPACT_SET_ETH_DST:
    case OFPACT_SET_IPV4_SRC:
    case OFPACT_SET_IPV4_DST:
    case OFPACT_SET_IP_DSCP:
    case OFPACT_SET_IP_ECN:
    case OFPACT_SET_IP_TTL:
    case OFPACT_SET_L4_SRC_PORT:
    case OFPACT_SET_L4_DST_PORT:
    case OFPACT_REG_MOVE:
    case OFPACT_SET_FIELD:
    case OFPACT_STACK_PUSH:
    case OFPACT_STACK_POP:
    case OFPACT_DEC_TTL:
    case OFPACT_SET_MPLS_LABEL:
    case OFPACT_SET_MPLS_TC:
    case OFPACT_SET_MPLS_TTL:
    case OFPACT_DEC_MPLS_TTL:
    case OFPACT_PUSH_MPLS:
    case OFPACT_POP_MPLS:
    case OFPACT_SET_TUNNEL:
    case OFPACT_SET_QUEUE:
    case OFPACT_POP_QUEUE:
    case OFPACT_FIN_TIMEOUT:
    case OFPACT_RESUBMIT:
    case OFPACT_LEARN:
    case OFPACT_CONJUNCTION:
    case OFPACT_MULTIPATH:
    case OFPACT_NOTE:
    case OFPACT_EXIT:
    case OFPACT_UNROLL_XLATE:
    case OFPACT_SAMPLE:
    case OFPACT_DEBUG_RECIRC:
    case OFPACT_DEBUG_SLOW:
    case OFPACT_CT:
    case OFPACT_CT_CLEAR:
    case OFPACT_NAT:
    case OFPACT_ENCAP:
    case OFPACT_DECAP:
    case OFPACT_DEC_NSH_TTL:
    case OFPACT_CHECK_PKT_LARGER:
    case OFPACT_DELETE_FIELD:
    default:
        return OVSINST_OFPIT11_APPLY_ACTIONS;
    }
}

/* Returns true if any action in the 'ofpacts_len' bytes of 'ofpacts' outputs
 * to 'port', false otherwise. */
bool
ofpacts_output_to_port(const struct ofpact *ofpacts, size_t ofpacts_len,
                       ofp_port_t port)
{
    const struct ofpact *a;

    OFPACT_FOR_EACH_FLATTENED (a, ofpacts, ofpacts_len) {
        if (ofpact_outputs_to_port(a, port)) {
            return true;
        }
    }

    return false;
}


/* Returns true if 'action' outputs to 'port', false otherwise. */
static bool
ofpact_outputs_to_port(const struct ofpact *ofpact, ofp_port_t port)
{
    switch (ofpact->type) {
    case OFPACT_OUTPUT:
        return ofpact_get_OUTPUT(ofpact)->port == port;
    case OFPACT_ENQUEUE:
        return ofpact_get_ENQUEUE(ofpact)->port == port;
    case OFPACT_CONTROLLER:
        return port == OFPP_CONTROLLER;

    case OFPACT_OUTPUT_REG:
    case OFPACT_OUTPUT_TRUNC:
    case OFPACT_BUNDLE:
    case OFPACT_SET_VLAN_VID:
    case OFPACT_SET_VLAN_PCP:
    case OFPACT_STRIP_VLAN:
    case OFPACT_PUSH_VLAN:
    case OFPACT_SET_ETH_SRC:
    case OFPACT_SET_ETH_DST:
    case OFPACT_SET_IPV4_SRC:
    case OFPACT_SET_IPV4_DST:
    case OFPACT_SET_IP_DSCP:
    case OFPACT_SET_IP_ECN:
    case OFPACT_SET_IP_TTL:
    case OFPACT_SET_L4_SRC_PORT:
    case OFPACT_SET_L4_DST_PORT:
    case OFPACT_REG_MOVE:
    case OFPACT_SET_FIELD:
    case OFPACT_STACK_PUSH:
    case OFPACT_STACK_POP:
    case OFPACT_DEC_TTL:
    case OFPACT_SET_MPLS_LABEL:
    case OFPACT_SET_MPLS_TC:
    case OFPACT_SET_MPLS_TTL:
    case OFPACT_DEC_MPLS_TTL:
    case OFPACT_SET_TUNNEL:
    case OFPACT_WRITE_METADATA:
    case OFPACT_SET_QUEUE:
    case OFPACT_POP_QUEUE:
    case OFPACT_FIN_TIMEOUT:
    case OFPACT_RESUBMIT:
    case OFPACT_LEARN:
    case OFPACT_CONJUNCTION:
    case OFPACT_MULTIPATH:
    case OFPACT_NOTE:
    case OFPACT_EXIT:
    case OFPACT_UNROLL_XLATE:
    case OFPACT_PUSH_MPLS:
    case OFPACT_POP_MPLS:
    case OFPACT_SAMPLE:
    case OFPACT_CLEAR_ACTIONS:
    case OFPACT_CLONE:
    case OFPACT_WRITE_ACTIONS:
    case OFPACT_GOTO_TABLE:
    case OFPACT_METER:
    case OFPACT_GROUP:
    case OFPACT_DEBUG_RECIRC:
    case OFPACT_DEBUG_SLOW:
    case OFPACT_CT:
    case OFPACT_CT_CLEAR:
    case OFPACT_NAT:
    case OFPACT_ENCAP:
    case OFPACT_DECAP:
    case OFPACT_DEC_NSH_TTL:
    case OFPACT_CHECK_PKT_LARGER:
    case OFPACT_DELETE_FIELD:
    default:
        return false;
    }
}

/* True if an action is allowed in the action set.
 * False otherwise. */
static bool
ofpact_is_allowed_in_actions_set(const struct ofpact *a)
{
    return action_set_classify(a) != ACTION_SLOT_INVALID;
}

enum action_set_class {
    /* Actions that individually can usefully appear only once in an action
     * set.  If they do appear more than once, then only the last instance is
     * honored. */
#define SLOT(OFPACT) ACTION_SLOT_##OFPACT,
    ACTION_SET_ORDER
#undef SLOT

    /* Final actions. */
#define FINAL(OFPACT) ACTION_SLOT_##OFPACT,
    ACTION_SET_FINAL_PRIORITY
#undef FINAL

    /* Actions that can appear in an action set more than once and are executed
     * in order. */
    ACTION_SLOT_SET_OR_MOVE,

    /* Actions that shouldn't appear in the action set at all. */
    ACTION_SLOT_INVALID
};

static enum action_set_class
action_set_classify(const struct ofpact a*)
{
    switch (a->type) {
    /* ... */


    /* NEVER */
    /* ... */
    case OFPACT_PROBDROP:
        return ACTION_SLOT_INVALID;

    /* ... */
    }
}

static enum action_set_class
action_set_classify(const struct ofpact *a)
{
    switch (a->type) {
#define SLOT(OFPACT) case OFPACT: return ACTION_SLOT_##OFPACT;
        ACTION_SET_ORDER
#undef SLOT

#define FINAL(OFPACT) case OFPACT: return ACTION_SLOT_##OFPACT;
        ACTION_SET_FINAL_PRIORITY
#undef FINAL

    case OFPACT_SET_FIELD:
    case OFPACT_REG_MOVE:
    case OFPACT_SET_ETH_DST:
    case OFPACT_SET_ETH_SRC:
    case OFPACT_SET_IP_DSCP:
    case OFPACT_SET_IP_ECN:
    case OFPACT_SET_IP_TTL:
    case OFPACT_SET_IPV4_DST:
    case OFPACT_SET_IPV4_SRC:
    case OFPACT_SET_L4_DST_PORT:
    case OFPACT_SET_L4_SRC_PORT:
    case OFPACT_SET_MPLS_LABEL:
    case OFPACT_SET_MPLS_TC:
    case OFPACT_SET_MPLS_TTL:
    case OFPACT_SET_QUEUE:
    case OFPACT_SET_TUNNEL:
    case OFPACT_SET_VLAN_PCP:
    case OFPACT_SET_VLAN_VID:
        return ACTION_SLOT_SET_OR_MOVE;

    case OFPACT_BUNDLE:
    case OFPACT_CLEAR_ACTIONS:
    case OFPACT_CLONE:
    case OFPACT_NAT:
    case OFPACT_CONTROLLER:
    case OFPACT_ENQUEUE:
    case OFPACT_EXIT:
    case OFPACT_UNROLL_XLATE:
    case OFPACT_FIN_TIMEOUT:
    case OFPACT_GOTO_TABLE:
    case OFPACT_LEARN:
    case OFPACT_CONJUNCTION:
    case OFPACT_METER:
    case OFPACT_MULTIPATH:
    case OFPACT_NOTE:
    case OFPACT_OUTPUT_REG:
    case OFPACT_OUTPUT_TRUNC:
    case OFPACT_POP_QUEUE:
    case OFPACT_SAMPLE:
    case OFPACT_STACK_POP:
    case OFPACT_STACK_PUSH:
    case OFPACT_WRITE_ACTIONS:
    case OFPACT_WRITE_METADATA:
    case OFPACT_DEBUG_RECIRC:
    case OFPACT_DEBUG_SLOW:
    case OFPACT_CHECK_PKT_LARGER:
    case OFPACT_DELETE_FIELD:
        return ACTION_SLOT_INVALID;

    default:
        OVS_NOT_REACHED();
    }
}

/* May modify flow->packet_type, flow->dl_type, flow->nw_proto and
 * flow->vlan_tci, caller must restore them.
 *
 * Modifies some actions, filling in fields that could not be properly set
 * without context. */
static enum ofperr
ofpact_check__(struct ofpact *a, struct ofpact_check_params *cp)
{
    switch (a->type) {
#define OFPACT(ENUM, STRUCT, MEMBER, NAME)                  \
        case OFPACT_##ENUM:                                 \
            return check_##ENUM(ofpact_get_##ENUM(a), cp);
        OFPACTS
#undef OFPACT
    default:
        OVS_NOT_REACHED();
    }
}

///////////////dpctl.c

static int
dpctl_dump_flows(int argc, const char *argv[], struct dpctl_params *dpctl_p)
{
    struct dpif *dpif;
    struct ds ds;

    char *filter = NULL;
    struct flow flow_filter;
    struct flow_wildcards wc_filter;
    char *types_list = NULL;
    struct dump_types dump_types;
    struct dpif_flow_dump_types dpif_dump_types;

    struct dpif_flow_dump_thread *flow_dump_thread;
    struct dpif_flow_dump *flow_dump;
    struct dpif_flow f;
    int pmd_id = PMD_ID_NULL;
    int lastargc = 0;
    int error;

    while (argc > 1 && lastargc != argc) {
        lastargc = argc;
        if (!strncmp(argv[argc - 1], "filter=", 7) && !filter) {
            filter = xstrdup(argv[--argc] + 7);
        } else if (!strncmp(argv[argc - 1], "type=", 5) && !types_list) {
            if (!dpctl_p->is_appctl) {
                dpctl_error(dpctl_p, 0,
                            "Invalid argument 'type'. "
                            "Use 'ovs-appctl dpctl/dump-flows' instead.");
                error = EINVAL;
                goto out_free;
            }
            types_list = xstrdup(argv[--argc] + 5);
        }
    }

    error = opt_dpif_open(argc, argv, dpctl_p, 2, &dpif);
    if (error) {
        goto out_free;
    }

    struct hmap *portno_names = dpctl_get_portno_names(dpif, dpctl_p);

    if (filter) {
        struct ofputil_port_map port_map;
        ofputil_port_map_init(&port_map);

        struct dpif_port_dump port_dump;
        struct dpif_port dpif_port;
        DPIF_PORT_FOR_EACH (&dpif_port, &port_dump, dpif) {
            ofputil_port_map_put(&port_map,
                                 u16_to_ofp(odp_to_u32(dpif_port.port_no)),
                                 dpif_port.name);
        }
        char *err = parse_ofp_exact_flow(&flow_filter, &wc_filter, NULL,
                                         filter, &port_map);
        ofputil_port_map_destroy(&port_map);
        if (err) {
            dpctl_error(dpctl_p, 0, "Failed to parse filter (%s)", err);
            free(err);
            error = EINVAL;
            goto out_dpifclose;
        }
    }

    memset(&dump_types, 0, sizeof dump_types);
    error = populate_dump_types(types_list, &dump_types, dpctl_p);
    if (error) {
        goto out_dpifclose;
    }
    determine_dpif_flow_dump_types(&dump_types, &dpif_dump_types);

    /* Make sure that these values are different. PMD_ID_NULL means that the
     * pmd is unspecified (e.g. because the datapath doesn't have different
     * pmd threads), while NON_PMD_CORE_ID refers to every non pmd threads
     * in the userspace datapath */
    BUILD_ASSERT(PMD_ID_NULL != NON_PMD_CORE_ID);

    ds_init(&ds);
    memset(&f, 0, sizeof f);
    flow_dump = dpif_flow_dump_create(dpif, false, &dpif_dump_types);
    flow_dump_thread = dpif_flow_dump_thread_create(flow_dump);
    while (dpif_flow_dump_next(flow_dump_thread, &f, 1)) {
        if (filter) {
            struct flow flow;
            struct flow_wildcards wc;
            struct match match, match_filter;
            struct minimatch minimatch;

            odp_flow_key_to_flow(f.key, f.key_len, &flow, NULL);
            odp_flow_key_to_mask(f.mask, f.mask_len, &wc, &flow, NULL);
            match_init(&match, &flow, &wc);

            match_init(&match_filter, &flow_filter, &wc);
            match_init(&match_filter, &match_filter.flow, &wc_filter);
            minimatch_init(&minimatch, &match_filter);

            if (!minimatch_matches_flow(&minimatch, &match.flow)) {
                minimatch_destroy(&minimatch);
                continue;
            }
            minimatch_destroy(&minimatch);
        }
        ds_clear(&ds);
        /* If 'pmd_id' is specified, overlapping flows could be dumped from
         * different pmd threads.  So, separates dumps from different pmds
         * by printing a title line. */
        if (pmd_id != f.pmd_id) {
            if (f.pmd_id == NON_PMD_CORE_ID) {
                ds_put_format(&ds, "flow-dump from the main thread:\n");
            } else {
                ds_put_format(&ds, "flow-dump from pmd on cpu core: %d\n",
                              f.pmd_id);
            }
            pmd_id = f.pmd_id;
        }
        if (flow_passes_type_filter(&f, &dump_types)) {
            format_dpif_flow(&ds, &f, portno_names, dpctl_p);
            dpctl_print(dpctl_p, "%s\n", ds_cstr(&ds));
        }
    }
    dpif_flow_dump_thread_destroy(flow_dump_thread);
    error = dpif_flow_dump_destroy(flow_dump);

    if (error) {
        dpctl_error(dpctl_p, error, "Failed to dump flows from datapath");
    }
    ds_destroy(&ds);

out_dpifclose:
    dpctl_free_portno_names(portno_names);
    dpif_close(dpif);
out_free:
    free(filter);
    free(types_list);
    return error;
}

static void
format_dpif_flow(struct ds *ds, const struct dpif_flow *f, struct hmap *ports,
                 struct dpctl_params *dpctl_p)
{
    if (dpctl_p->verbosity && f->ufid_present) {
        odp_format_ufid(&f->ufid, ds);
        ds_put_cstr(ds, ", ");
    }
    odp_flow_format(f->key, f->key_len, f->mask, f->mask_len, ports, ds,
                    dpctl_p->verbosity);
    ds_put_cstr(ds, ", ");

    dpif_flow_stats_format(&f->stats, ds);
    if (dpctl_p->verbosity && f->attrs.offloaded) {
        if (f->attrs.dp_layer && !strcmp(f->attrs.dp_layer, "ovs")) {
            ds_put_cstr(ds, ", offloaded:partial");
        } else {
            ds_put_cstr(ds, ", offloaded:yes");
        }
    }
    if (dpctl_p->verbosity && f->attrs.dp_layer) {
        ds_put_format(ds, ", dp:%s", f->attrs.dp_layer);
    }
    ds_put_cstr(ds, ", actions:");
    format_odp_actions(ds, f->actions, f->actions_len, ports);
    if (dpctl_p->verbosity && f->attrs.dp_extra_info) {
        ds_put_format(ds, ", dp-extra-info:%s", f->attrs.dp_extra_info);
    }
}

-------odp-util.c

void
format_odp_actions(struct ds *ds, const struct nlattr *actions,
                   size_t actions_len, const struct hmap *portno_names)
{
    if (actions_len) {
        const struct nlattr *a;
        unsigned int left;

        NL_ATTR_FOR_EACH (a, left, actions, actions_len) {
            if (a != actions) {
                ds_put_char(ds, ',');
            }
            format_odp_action(ds, a, portno_names);
        }
        if (left) {
            int i;

            if (left == actions_len) {
                ds_put_cstr(ds, "<empty>");
            }
            ds_put_format(ds, ",***%u leftover bytes*** (", left);
            for (i = 0; i < left; i++) {
                ds_put_format(ds, "%02x", ((const uint8_t *) a)[i]);
            }
            ds_put_char(ds, ')');
        }
    } else {
        ds_put_cstr(ds, "drop");
    }
}

static void
format_odp_action(struct ds *ds, const struct nlattr *a,
                  const struct hmap *portno_names)
{
    int expected_len;
    enum ovs_action_attr type = nl_attr_type(a);
    size_t size;

    expected_len = odp_action_len(nl_attr_type(a));
    if (expected_len != ATTR_LEN_VARIABLE &&
        nl_attr_get_size(a) != expected_len) {
        ds_put_format(ds, "bad length %"PRIuSIZE", expected %d for: ",
                      nl_attr_get_size(a), expected_len);
        format_generic_odp_action(ds, a);
        return;
    }

    switch (type) {
    case OVS_ACTION_ATTR_METER:
        ds_put_format(ds, "meter(%"PRIu32")", nl_attr_get_u32(a));
        break;
    case OVS_ACTION_ATTR_OUTPUT:
        odp_portno_name_format(portno_names, nl_attr_get_odp_port(a), ds);
        break;
    case OVS_ACTION_ATTR_LB_OUTPUT:
        ds_put_format(ds, "lb_output(%"PRIu32")", nl_attr_get_u32(a));
        break;
    case OVS_ACTION_ATTR_TRUNC: {
        const struct ovs_action_trunc *trunc =
                       nl_attr_get_unspec(a, sizeof *trunc);

        ds_put_format(ds, "trunc(%"PRIu32")", trunc->max_len);
        break;
    }
    case OVS_ACTION_ATTR_TUNNEL_POP:
        ds_put_cstr(ds, "tnl_pop(");
        odp_portno_name_format(portno_names, nl_attr_get_odp_port(a), ds);
        ds_put_char(ds, ')');
        break;
    case OVS_ACTION_ATTR_TUNNEL_PUSH:
        format_odp_tnl_push_action(ds, a, portno_names);
        break;
    case OVS_ACTION_ATTR_USERSPACE:
        format_odp_userspace_action(ds, a, portno_names);
        break;
    case OVS_ACTION_ATTR_RECIRC:
        format_odp_recirc_action(ds, nl_attr_get_u32(a));
        break;
    case OVS_ACTION_ATTR_HASH:
        format_odp_hash_action(ds, nl_attr_get(a));
        break;
    case OVS_ACTION_ATTR_SET_MASKED:
        a = nl_attr_get(a);
        /* OVS_KEY_ATTR_NSH is nested attribute, so it needs special process */
        if (nl_attr_type(a) == OVS_KEY_ATTR_NSH) {
            format_odp_set_nsh(ds, a);
            break;
        }
        size = nl_attr_get_size(a) / 2;
        ds_put_cstr(ds, "set(");

        /* Masked set action not supported for tunnel key, which is bigger. */
        if (size <= sizeof(struct ovs_key_ipv6)) {
            struct nlattr attr[1 + DIV_ROUND_UP(sizeof(struct ovs_key_ipv6),
                                                sizeof(struct nlattr))];
            struct nlattr mask[1 + DIV_ROUND_UP(sizeof(struct ovs_key_ipv6),
                                                sizeof(struct nlattr))];

            mask->nla_type = attr->nla_type = nl_attr_type(a);
            mask->nla_len = attr->nla_len = NLA_HDRLEN + size;
            memcpy(attr + 1, (char *)(a + 1), size);
            memcpy(mask + 1, (char *)(a + 1) + size, size);
            format_odp_key_attr(attr, mask, NULL, ds, false);
        } else {
            format_odp_key_attr(a, NULL, NULL, ds, false);
        }
        ds_put_cstr(ds, ")");
        break;
    case OVS_ACTION_ATTR_SET:
        ds_put_cstr(ds, "set(");
        format_odp_key_attr(nl_attr_get(a), NULL, NULL, ds, true);
        ds_put_cstr(ds, ")");
        break;
    case OVS_ACTION_ATTR_PUSH_ETH: {
        const struct ovs_action_push_eth *eth = nl_attr_get(a);
        ds_put_format(ds, "push_eth(src="ETH_ADDR_FMT",dst="ETH_ADDR_FMT")",
                      ETH_ADDR_ARGS(eth->addresses.eth_src),
                      ETH_ADDR_ARGS(eth->addresses.eth_dst));
        break;
    }
    case OVS_ACTION_ATTR_POP_ETH:
        ds_put_cstr(ds, "pop_eth");
        break;
    case OVS_ACTION_ATTR_PUSH_VLAN: {
        const struct ovs_action_push_vlan *vlan = nl_attr_get(a);
        ds_put_cstr(ds, "push_vlan(");
        if (vlan->vlan_tpid != htons(ETH_TYPE_VLAN)) {
            ds_put_format(ds, "tpid=0x%04"PRIx16",", ntohs(vlan->vlan_tpid));
        }
        format_vlan_tci(ds, vlan->vlan_tci, OVS_BE16_MAX, false);
        ds_put_char(ds, ')');
        break;
    }
    case OVS_ACTION_ATTR_POP_VLAN:
        ds_put_cstr(ds, "pop_vlan");
        break;
    case OVS_ACTION_ATTR_PUSH_MPLS: {
        const struct ovs_action_push_mpls *mpls = nl_attr_get(a);
        ds_put_cstr(ds, "push_mpls(");
        format_mpls_lse(ds, mpls->mpls_lse);
        ds_put_format(ds, ",eth_type=0x%"PRIx16")", ntohs(mpls->mpls_ethertype));
        break;
    }
    case OVS_ACTION_ATTR_POP_MPLS: {
        ovs_be16 ethertype = nl_attr_get_be16(a);
        ds_put_format(ds, "pop_mpls(eth_type=0x%"PRIx16")", ntohs(ethertype));
        break;
    }
    case OVS_ACTION_ATTR_SAMPLE:
        format_odp_sample_action(ds, a, portno_names);
        break;
    case OVS_ACTION_ATTR_CT:
        format_odp_conntrack_action(ds, a);
        break;
    case OVS_ACTION_ATTR_CT_CLEAR:
        ds_put_cstr(ds, "ct_clear");
        break;
    case OVS_ACTION_ATTR_CLONE:
        format_odp_clone_action(ds, a, portno_names);
        break;
    case OVS_ACTION_ATTR_PUSH_NSH: {
        uint32_t buffer[NSH_HDR_MAX_LEN / 4];
        struct nsh_hdr *nsh_hdr = ALIGNED_CAST(struct nsh_hdr *, buffer);
        nsh_reset_ver_flags_ttl_len(nsh_hdr);
        odp_nsh_hdr_from_attr(nl_attr_get(a), nsh_hdr, NSH_HDR_MAX_LEN);
        format_odp_push_nsh_action(ds, nsh_hdr);
        break;
    }
    case OVS_ACTION_ATTR_POP_NSH:
        ds_put_cstr(ds, "pop_nsh()");
        break;
    case OVS_ACTION_ATTR_CHECK_PKT_LEN:
        format_odp_check_pkt_len_action(ds, a, portno_names);
        break;
    case OVS_ACTION_ATTR_DROP:
        ds_put_cstr(ds, "drop");
        break;
    case OVS_ACTION_ATTR_UNSPEC:
    case __OVS_ACTION_ATTR_MAX:
    default:
        format_generic_odp_action(ds, a);
        break;
    }
}


/* Returns one the following for the action with the given OVS_ACTION_ATTR_*
 * 'type':
 *
 *   - For an action whose argument has a fixed length, returned that
 *     nonnegative length in bytes.
 *
 *   - For an action with a variable-length argument, returns ATTR_LEN_VARIABLE.
 *
 *   - For an invalid 'type', returns ATTR_LEN_INVALID. */
static int
odp_action_len(uint16_t type)
{
    if (type > OVS_ACTION_ATTR_MAX) {
        return -1;
    }

    switch ((enum ovs_action_attr) type) {
    case OVS_ACTION_ATTR_OUTPUT: return sizeof(uint32_t);
    case OVS_ACTION_ATTR_LB_OUTPUT: return sizeof(uint32_t);
    case OVS_ACTION_ATTR_TRUNC: return sizeof(struct ovs_action_trunc);
    case OVS_ACTION_ATTR_TUNNEL_PUSH: return ATTR_LEN_VARIABLE;
    case OVS_ACTION_ATTR_TUNNEL_POP: return sizeof(uint32_t);
    case OVS_ACTION_ATTR_METER: return sizeof(uint32_t);
    case OVS_ACTION_ATTR_USERSPACE: return ATTR_LEN_VARIABLE;
    case OVS_ACTION_ATTR_PUSH_VLAN: return sizeof(struct ovs_action_push_vlan);
    case OVS_ACTION_ATTR_POP_VLAN: return 0;
    case OVS_ACTION_ATTR_PUSH_MPLS: return sizeof(struct ovs_action_push_mpls);
    case OVS_ACTION_ATTR_POP_MPLS: return sizeof(ovs_be16);
    case OVS_ACTION_ATTR_RECIRC: return sizeof(uint32_t);
    case OVS_ACTION_ATTR_HASH: return sizeof(struct ovs_action_hash);
    case OVS_ACTION_ATTR_SET: return ATTR_LEN_VARIABLE;
    case OVS_ACTION_ATTR_SET_MASKED: return ATTR_LEN_VARIABLE;
    case OVS_ACTION_ATTR_SAMPLE: return ATTR_LEN_VARIABLE;
    case OVS_ACTION_ATTR_CT: return ATTR_LEN_VARIABLE;
    case OVS_ACTION_ATTR_CT_CLEAR: return 0;
    case OVS_ACTION_ATTR_PUSH_ETH: return sizeof(struct ovs_action_push_eth);
    case OVS_ACTION_ATTR_POP_ETH: return 0;
    case OVS_ACTION_ATTR_CLONE: return ATTR_LEN_VARIABLE;
    case OVS_ACTION_ATTR_PUSH_NSH: return ATTR_LEN_VARIABLE;
    case OVS_ACTION_ATTR_POP_NSH: return 0;
    case OVS_ACTION_ATTR_CHECK_PKT_LEN: return ATTR_LEN_VARIABLE;
    case OVS_ACTION_ATTR_DROP: return sizeof(uint32_t);

    case OVS_ACTION_ATTR_UNSPEC:
    case __OVS_ACTION_ATTR_MAX:
        return ATTR_LEN_INVALID;
    }

    return ATTR_LEN_INVALID;
}


static void
format_odp_action( /* ... */ )
{
    /* ... */
    switch (type) {
    /* ... */

    case OVS_ACTION_ATTR_PROBDROP: 
        ds_put_format(ds, "pdrop(%"PRIu32")", nl_attr_get_u32(a));
        break;

    /* ... */
    }
}

static int
odp_action_len(uint16_t type)
{
    /* ... */

    switch ((enum ovs_action_attr) type) {
    /* ... */
    case OVS_ACTION_ATTR_PROBDROP: return sizeof(uint32_t);
    }
}